{"0": [0, 30, "MICHALE FEE: OK.\nSo let's go ahead\nand get started.\nSo what is neural computation?\nSo neuroscience used to be\na very descriptive field"], "30": [1, 120, "Who here has seen the famous\npictures-- the old pictures\nof the golgi-stained neurons,\nall those different types\nof neurons, describing what\nthings look like in the brain\nand what parts of the brain\nare important for what\nkinds of behavior based\non lesion studies.\nIt used to be\nextremely descriptive.\nBut things are changing\nin neuroscience,\nand have changed dramatically\nover the past few decades.\nReally, neuroscience now is\nabout understanding the brain,\nhow the brain works, how\nthe brain produces behavior.\nAnd really trying to develop\nengineering-level descriptions\nof brain systems and brain\ncircuits and neurons and ion\nchannels and all the components\nof neurons that make the brain\nwork.\nAnd so, for example,\nthe level of description\nthat my lab works at and\nthat I'm most excited about\nis understanding how neural\ncircuits-- how neurons\nare put together to make\nneural circuits that\nimplement behaviors,\nor to produce\nlet's say object recognition.\nSo this is a figure\nfrom Jim DiCarlo,\nwho is our department head.\nBasically a\ncircuit-level description\nof how the brain goes\nfrom a visual stimulus\nto a recognition of what that\nobject is in the stimulus.\nNow at the same\ntime that there's\nbeen a big push toward\nunderstanding or generating\nan engineering level\ndescriptions of brains\nand circuits and\ncomponents, neurons,\nthere's also been tremendous\nadvances in the technologies\nthat we can use\nto record neurons.\nSo there are now imaging\nsystems and microscopes\nthat can image thousands\nof neurons simultaneously."], "150": [2, 130, "that's basically dreaming.\nAnd let me just show you\nwhat this looks like.\nSo this is a mouse that has\na fluorescent protein that's\nsensitive to neural activity.\nAnd so when neurons in a part\nof the brain become active\nthey become fluorescent\nand light up.\nAnd so here's a top surface\nof the mouse's brain.\nAnd you can see this spontaneous\nactivity flickering around\nas this mouse is just\ndreaming and thinking\nabout whatever it's\nthinking about.\nSo one of the key\nchallenges is to take images\nlike this that represent\nthe activity of thousands\nof neurons or\nmillions of neurons\nand figure out how to relate\nthat to the circuit models that\nare being developed.\nSo here's another example.\nSo there are these new probes\nwhere these are basically\nsilicon probes\nthat have thousands\nof little sensors on\nthem and a computer here\nthat basically reads out\nthe pattern of activity.\nThese are called neuropixels.\nSo those are\nbasically electrodes\nthat can, again, record\nfrom thousands of neurons\nsimultaneously.\nAnd they're quite\nlong and can record\nthroughout the whole brain,\nessentially, all at once.\nSo the key now is you have these\nvery high dimensional data set.\nHow do you relate that\nto the circuit models\nthat you're developing?\nAnd so one of the key\nchallenges in neuroscience\nis to take very\nlarge data sets that\nlook like this that\njust look like a mess\nand figure out what's going\non underneath of there.\nIt turns out that people are\ndiscovering that while you\nmight be recording from\ntens of thousands of neurons\nand it looks really\nmessy that there's\nsome underlying very simple\nstructure underneath of there.\nBut you can't see\nit when you just\nlook at big collections\nof neurons like this."], "280": [3, 50, "how to not only just\nmake those models,\nbut test them by taking\ndata and relating\nthe patterns of activity\nthat you see in these very\nhigh dimensional data sets,\ndo dimensionality reduction--\ncompress that data down into\na simple representation--\nand then relate it to those\nmodels that you developed.\nOne of the things we're going\nto try to do in this class\nis to apply these techniques\nof making models of neurons\nand circuits together\nwith mathematical tools\nfor analyzing data in\nthe context of looking\nat animal behaviors."], "330": [4, 130, "how they learn to produce\ntheir vocalizations.\nSongbirds learn by\nimitating their parents.\nThey listen to their parents.\n[BIRDS SINGING]\nHere, hold on.\nI'm going to skip ahead.\nHow do I do that?\n[BIRDS SINGING]\n[INAUDIBLE] bring up the--\nI was hoping I'd be\nable to skip ahead.\nSo this is just a\nsetup showing how\nwe can record from neurons in\nbirds while they're singing\nand figure out how\nthose circuits work\nto produce the song.\nThis is a little\nmicro-drive that we built.\nIt's motorized so that we\ncan move these electrodes\naround independently in the\nbrain and record from neurons\nwithout the animal knowing that\nwe're moving the electrodes\naround and looking for neurons.\nSo songbirds are really cool.\nThey listen to their parents.\nThey store a memory of\nwhat their parents sing.\nAnd then they begin babbling.\nAnd they practice over and\nover again until they can learn\na good copy of their song.\nSo here's a bird that's\nsinging with the micro-drive\non its head.\nAnd you can hear the\nneuron in the background.\n[STATIC SOUNDS]\nSorry, it's not over\nthe loudspeaker here.\nBut can everyone hear that?\nSo we can record from neurons\nwhile the bird is singing.\n[BIRDS SINGING]\nLook at the activity\nin this network\nand try to figure out\nhow that network actually\nworks to produce the song.\nAnd also we can record\nin very young birds\nand figure out how the\nsong is actually learned.\nAnd there's an example\nof a neuron generating\naction potentials, which is\nthe basic unit of communication\nin the brain.\n[BIRDS SINGING]"], "460": [5, 110, "and figure out how that\nthing actually works\nto produce and learn this song.\nSo these computational\napproaches\nthat I'm talking\nabout are not just\nimportant for dissecting brain\ncircuits related to behavior.\nThe same kinds of\napproaches, the same kind\nof dimensionality reduction\ntechniques we're going to learn\nare also useful in\nmolecular genetic studies,\nlike taking\ntranscriptional profiling\nand doing clustering and looking\nat the different patterns that\nare there.\nIt's also useful for\nmolecular studies.\nAlso, these ideas are very\npowerful in studying cognition.\nSo if you look at the work\nthat Josh Tenenbaum does\nand Josh McDermott, who\ndeveloped mathematical models\nof how our minds work, how we\nlearn to think about things,\nthose are also very model-based\nand very quantitative.\nSo the kinds of tools we're\ngoing to learn in this class\nare very broadly applicable.\nThey're also increasingly\nimportant in medicine.\nSo at some point we're going to\ntake a little bit of a detour\nto look at a particular\ndisease that's caused\nby a defect in an ion channel.\nAnd it turns out\nyou can understand\nexactly how that defect\nin that ion channel\nrelates to the phenotype\nof the disease.\nAnd you can do that by creating\na mathematical model of how\na neuron behaves when it\nhas an ion channel that\nhas this defect in it.\nSo it's very cool.\nAnd once you model\nit, you can really\nunderstand why that happens.\nSo here are some of\nthe course goals."], "570": [6, 60, "on basic biophysics of\nneurons and networks\nand other principles underlying\nbrain and cognitive functions.\nWe're going to develop\nmathematical techniques\nto analyze those models and\nto analyze the behavioral data\nand neural data\nthat you would take\nto study those brain circuits.\nAnd along the way, we're going\nto become proficient at using\nMATLAB to do these things.\nSo how many of you have\nexperience with MATLAB?\nOK, great.\nAnd not?\nSo anybody who doesn't have\nexperience with MATLAB,\nwe're going to really make\nan effort to bring you up\nto speed very quickly.\nDaniel has actually just\ncreated a very nice MATLAB cheat\nsheet that's just amazing.\nSo there will be lots of\nhelp with programming.\nSo let me just mention\nsome of the topics\nthat we'll be covering."], "630": [7, 100, "model of neurons.\nSo let me just explain\nhow this is broken down.\nSo these are topics\nthat we'll be covering.\nAnd these are the\nmathematical tools\nthat go along with\nthose topics that we'll\nbe learning about in parallel.\nSo we'll be studying\nneuronal biophysics.\nAnd we'll be doing some\ndifferential equations\nalong the way for that, just\nfirst-order linear differential\nequations, nothing\nto be scared of.\nWe'll talk about\nneuronal responses\nto stimuli and tuning curves.\nAnd along the way,\nwe'll be learning\nabout spike sorting and\nperistimulus, time histograms,\nand ways of analyzing\nfiring patterns.\nWe talked about neural\ncoding and receptive fields.\nAnd we'll learn about\ncorrelation and convolution\nfor that topic.\nWe'll talk about feed forward\nnetworks and perceptrons.\nAnd then we're going\nto start bringing\na lot of linear algebra,\nwhich is really fun.\nIt's really powerful.\nAnd that linear\nalgebra sets the stage\nfor then doing\ndimensionality, reduction\non data, and principal component\nanalysis, and singular value\ndecomposition, and other things.\nWe'll then take an additional\nextension of neural networks\nfrom feed forward networks.\nWe'll figure out how\nto make them talk back\nto themselves so they\ncan start doing things\nlike remember things\nand make decisions.\nAnd that involves more\nlinear algebra, eigenvalues.\nAnd then I'm not\nsure we're going\nto get time to sensory\nintegration and Bayes' rule.\nSo by the end of\nthe class, there"], "730": [8, 60, "You'll be able to think\nabout a neuron very clearly\nand how its components\nwork together\nto give that neuron\nits properties.\nAnd how neurons themselves\ncan connect together\nto give a neural\ncircuit its properties.\nYou'll be able to write\nMATLAB programs that\nsimulate those models.\nYou'll be able to analyze\ndata using MATLAB.\nYou'll be able to visualize\nhigh dimensional data sets.\nAnd one of my\ngoals in this class\nis that you guys\nshould be able to go\ninto any lab in the\ndepartment and do\ncool things that even the\ngraduate students may not\nknow how to do.\nAnd so you can do really\ngreat stuff as a UROP."], "790": [9, 50, "is problem sets\nbecause that's where\nyou're going to get the hands-on\nexperience to do that data\nanalysis and write programs\nand analyze the data.\nPlease install that.\nIt's really important, if\nyou don't already have that.\nWe use live scripts for\nproblems set submissions.\nAnd Daniel made some\nnice examples on Stellar.\nAnd of course the guidelines\nfor Pset submissions\nare also on Stellar.\nOK, that's it.\nAny questions about that?\nNo?\nAll right, good.\nSo let's go ahead\nand get started then\nwith the first topic."], "840": [10, 10, "OK.\nSo the first thing\nwe're going to do"], "850": [11, 90, "This model is very particular.\nIt uses electrical components\nto describe the neuron.\nNow that may not be surprising\nsince a neuron is basically\nan electrical device.\nIt has components that\nare sensitive to voltages,\nthat generate currents,\nthat control currents.\nAnd so we're going to build our\nmodel using electrical circuit\ncomponents.\nAnd one of the nice\nthings about doing that\nis that every electrical\ncircuit component,\nlike a resistor or\na capacitor, has\na very well-defined mathematical\nrelation between the current\nand the voltage,\nthe current that\nflows through that\ndevice and the voltage\nacross the terminals\nof that device.\nSo you can write down very\nprecisely, mathematically,\nwhat each of those\ncomponents does.\nSo then you can then\ntake all those components\nand construct a set of\nequations or in general a set\nof differential equations that\nallows you to basically evolve\nthat circuit over time\nand plot, let's say,\nthe voltage on the inside of\nthe cell as a function of time.\nAnd you can see that that\nmodel neuron can actually\nvery precisely replicate many\nof the properties of neurons.\nNow neurons are actually\nreally complicated."], "940": [12, 130, "So there are many\ndifferent kinds of neurons.\nEach type of neuron\nhas a different pattern\nof genes that are expressed.\nSo this is a cluster\ndiagram of neuron type based\non a transcriptional\nprofiling of the RNA\nthat I think it was about 13,000\nneurons that were extracted\nfrom a part of the brain.\nYou do a transcriptional\nprofiling.\nIt gives you a map of\nall the different genes\nare expressed in each neuron.\nAnd then you can\ncluster them and you\ncan see that this particular\npart of the brain,\nwhich is in the\nhypothalamus, expresses all\nof these different cell types.\nNow what are those\ndifferent genes?\nMany of those different\ngenes are actually\ndifferent ion channels.\nAnd there are hundreds of\ndifferent kinds of ion channels\nthat control the flow of\ncurrent across the membrane\nof the neuron.\nSo this is just a diagram\nshowing different potassium ion\nchannels, different\ncalcium ion channels.\nYou can see they have families\nand different subtypes.\nAnd all of those\ndifferent ion channels\nhave different\ntimescales on which\nthe current varies as a\nfunction of voltage change.\nThey have different\nvoltage ranges\nthat they're sensitive to.\nThey have different\ninactivation.\nSo many ion channels, when you\nturn them on, they stay on.\nBut other ion\nchannels, they turn on\nand then they slowly decay away.\nThe current slowly decays away.\nAnd that's called inactivation.\nAnd all these\ndifferent ion channels\nhave different combinations\nof those properties.\nAnd it's really\nhard to predict when\nyou think about how\nthis neuron will\nbehave with a different\nkind of ion channel here.\nIt's super hard to just look\nat the properties of an ion\nchannel and just see how that's\ngoing to work in a neuron\nbecause you have all\nthese different parts that\nare working together.\nAnd so it's really important\nto be able to write down\na mathematical model.\nIf you have a neuron that has a\ndifferent kind of ion channel,\nyou can actually predict how\nthe neuron's going to behave.\nNow that's just the\nion channel components.\nNeurons also have\ncomplex morphologies."], "1070": [13, 50, "This is a Purkinje\ncell in the cerebellum.\nThey have these very densely\nelaborated dendrites.\nOther neurons have\nvery long dendrites\nwith just a few branches.\nOther neurons have very\nshort stubby dendrites.\nAnd each of those different\nmorphological patterns\nalso affects how a neuron\nresponds to its inputs,\nbecause now a neuron\ncan have inputs\nout here at the end of\nthe dendrite or up close\nto the soma.\nAnd all of those, the\nspatial structure,\nalso affects how\na neuron responds.\nAnd those produce very\ndifferent firing patterns.\nSo some neurons, if you\nput in a constant current,\nthey just fire regularly up.\nSo it turns out we\ncan really understand"], "1120": [14, 190, "if we build a model like this.\nSo let me just\npoint out a couple\nof other interesting\nthings about this model.\nDifferent parts of\nthis circuit actually\ndo cool different things.\nSo neurons have not\njust one power supply.\nThey've got multiple\npower supplies to power\nup different parts\nof the circuit that\ndo different things.\nNeurons have\ncapacitances that allow\na neuron to accumulate over\ntime, act as an integrator.\nIf you combine a\ncapacitor with a resistor,\nthat circuit now\nlooks like a filter.\nIt smooths its past\ninputs over time.\nAnd these two components\nhere, this sodium current\nand this potassium current,\nmake a spike generator\nthat generates an\naction potential that\nthen talks to other neurons.\nAnd you put that\nwhole thing together,\nand that thing can act\nlike an oscillator.\nIt can act like a\ncoincidence detector.\nIt can do all kinds of\ndifferent cool things.\nAnd all that stuff\nis understandable\nif you just write down a\nsimple model like this.\nAny questions?\nSo what we're going\nto do is we're\ngoing to just start\ndescribing this network.\nWe're going to build it\nup one piece at a time.\nAnd we're going to start\nwith a capacitance.\nBut before we get\nto the capacitor,\nwe need to do one more thing.\nWe need to do one\nthing first, which\nis figure out what the\nwires are in the brain.\nFor an electrical circuit,\nyou need to have wires.\nSo what are the\nwires in the brain?\nWhat do wires do in a circuit?\nThey carry current.\nSo what are the\nwires in a neuron?\nAUDIENCE: Axons?\nMICHALE FEE: What's that?\nAUDIENCE: Axons?\nMICHALE FEE: Axons.\nSo axons carry information.\nThey carry a spike that\ntravels down the axon\nand goes to other neurons.\nBut there is even a\nsimpler answer than that.\nYes?\nAUDIENCE: Ion channels?\nMICHALE FEE: Ion channels\nare these resistors here.\nBut what is it that connects all\nthose components to each other?\nAUDIENCE: Intracellular\nand extracellular.\nMICHALE FEE: Excellent.\nIt's the intracellular and\nextracellular solution.\nAnd so what we're\ngoing to do today\nis to understand how the\nintracellular and extracellular\nsolution acts as a\nwire in our neuron.\nAnd it's not quite as\nsimple as a piece of metal.\nIt's a bit more complicated.\nThere are different\nways you can get\ncurrent flow in intracellular\nand extracellular solution.\nSo we're going to\ngo through that\nand we're going to analyze\nthat in some detail."], "1310": [15, 20, "and extracellular\nsalt solutions.\nAnd you get current\nflow that results\nfrom the movement of ions\nin that aqueous solution.\nSo the solution\nconsists of ions."], "1330": [16, 90, "sodium ions and chloride ions\nthat are dissolved in water.\nWater is a polar solvent.\nThat means that the negative\nparts, the oxygen that's\nslightly negatively charged.\nOxygen is attracted\ntoward positive ions.\nAnd the intracellular\nand extracellular space\nare filled with salt\nsolution at a concentration\nof about 100 millimolar.\nAnd that corresponds\nto having one\nof these ions about\nevery 25 angstroms apart.\nSo at those\nconcentrations, there\nare a lot of ions\nfloating around.\nAnd those ions can move\nunder different conditions\nto produce currents.\nSo currents flow in\nthe brain through two\nprimary different mechanisms.\nDiffusion, which is\ncaused by variations\nin the concentration.\nAnd drifts of particles\nin an electric field.\nSo when you put\nan electric field,\nso if you take a beaker\nfilled with salt solution,\nyou put two metal\nelectrodes in it,\nyou produce an\nelectric field that\ncauses these ions to drift in--\nand that's another\nsource of current\nthat we're going\nto look at today."], "1420": [17, 40, "We're going to understand how\nthe timescales of diffusion\nrelate to the length scales.\nThat's a really\ninteresting story.\nThat's very important.\nWe're going to understand how\nconcentration gradients lead\nto currents.\nThat's known as\nFick's First Law.\nAnd we're going to\nunderstand how charges drift\nin an electric field in a\nway that leads to current,\nand the mathematical\nrelation that\ndescribes voltage differences.\nAnd this is called\nOhm's Law in the brain.\nAnd we're going to learn about\nthe concept of resistivity."], "1460": [18, 200, "if we're going to talk about\ndiffusion, is thermal energy.\nSo every particle\nin the world is\nbeing jostled by other particles\nthat are crashing into it.\nAnd at thermal equilibrium,\nevery degree of freedom,\nevery way that a particle\ncan move, either forward\nand backward, left and right,\nup and down, or rotations,\nthis way or this way,\nor whichever way,\nI didn't show yet,\ncome to equilibrium\nat a particular energy that's\nproportional to temperature.\nIn other words, if\na particle is moving\nin this direction\nin equilibrium,\nit will have a kinetic energy\nin that direction that's\nproportional to the temperature.\nAnd that temperature\nis in units of kelvin\nrelative to absolute zero.\nAnd the proportionality constant\nis the Boltzmann constant,\nwhich has units of\njoules per kelvin.\nSo when you multiply the\nBoltzmann constant k times\ntemperature, what you find is\nthat every degree of freedom\nwill come to equilibrium\nat 4 times 10\nto the minus 21 joules,\nwhich is an amount of energy,\nat room temperature.\nAt zero temperature, you can\nsee that every degree of freedom\nhas zero energy.\nAnd so nothing is moving.\nNothing's rotating, nothing's\nmoving any direction.\nEverything's perfectly still.\nSo let's calculate\nhow fast particles\nmove at thermal equilibrium\nin room temperature.\nSo you may remember from\nyour first physics class\nthat the kinetic\nenergy of a particle\nis proportional to the velocity\nsquared, 1/2 mv squared.\nSo the average velocity\nsquared of a particle\nat thermal equilibrium is just\n1/2 times that much energy.\nThat makes sense?\nNow we [AUDIO OUT] how\nfast a particle is moving--\nfor example, a sodium ion.\nSo you can see that the average\nvelocity squared is just\nkT over m.\nWe just divide both sides by m.\nSo the average velocity\nsquared is kT over m.\nThe mass of a\nsodium ion is this.\nSo the average\nvelocity squared is\n10 to the 5 meter squared\nper second squared.\nJust take the square\nroot that, and you\nget the average velocity\nis 320 meters per second.\nSo that means that the\nair molecules, which\nhave a similar\nmass to sodium ion,\nare whizzing around at\n300 meters per second.\nSo that would cross this room\nin a few hundredths of a second.\nBut of course, that's\nnot what happens.\nParticles don't just go whizzing\nalong at 300 meters per second.\nWhat happens to them?\nAUDIENCE: Bump into each other.\nMICHALE FEE: Into each other.\nThey're all crashing into\neach other constantly."], "1660": [19, 110, "every about 10 to the\n13 times per second.\n10 to the minus 13 seconds\nbetween collisions.\nSo that means the particle is\nmoving a little bit crashing,\nmoving in a different\ndirection, crashing,\nmoving in a different\ndirection and crashing.\nSo if you follow one particle,\nit's just jumping around,\nit's diffusing.\nSo what does that look like?\nDaniel made a little\nvideo that shows to scale.\nThis is position in micron.\nAnd time is in real-time.\nSo this video shows in real-time\nwhat the motion of a particle\nmight look like.\nIn each point, it's moving,\ncolliding, and moving off\nin some random direction.\nYou can actually see this.\nIf you look at a\nvery small particle--\nwho was it, Daniel, who did that\nexperiment looking at pollen?\nIt's Brownian, at Brown.\nAUDIENCE: Yup.\nMICHALE FEE: What\nwas his first name?\nBrown.\nBrownian motion.\nHave you heard of\nBrownian motion?\nSo somebody named\nBrown was looking\nat pollen particles in water and\nnoticing that they jump around,\njust like this.\nAnd he hypothesized that they\nwere being jostled around\nby the water.\nAny questions?\nSo what can we say about this?\nThere's something really\ninteresting about diffusion\nthat's very\nnon-intuitive at first."], "1770": [20, 180, "That a distance that\na particle can diffuse\ndepends very much on\nthe time that you allow.\nAnd it's not just\na simple relation.\nSo let's just look at this.\nSo let's ask how\nmuch time does it\ntake for an ion to\ndiffuse a short distance,\nlike across the\nsoma of a neuron.\nSo an ion can diffuse\nacross the soma of a neuron\nin about a 20th of a second.\nHow about down it at dendrites.\nSo let's start our\nion in the cell body.\nAnd ask, how long\ndoes it take an iron\nto reach the end of a dendrite\nthat can be about a millimeter\naway.\nCan take about 10\nminutes on average.\nThat's how long it\nwill take an iron\nto get that far away\nfrom its starting point.\nSo you can see, 20th\nof a second here.\nAnd here it's like 500 seconds.\nAbout 10 minutes.\nHow long does it take an ion,\nstarting at the cell body,\nto diffuse all the way down--\nso you know there are\nneurons in your body that\nstart in your spinal cord and go\nall the way down to your feet.\nSo motor neurons in your spinal\ncord can have very long axons.\nSo how long does it take\nan ion to get from the soma\nall the way down to the end\nof an axon, a long axon?\nSomebody just take a guess.\nIt's 20th of a second\nhere, 10 minutes here.\nAnybody want to guess?\nAn hour, yup.\n10 years.\nOK.\nWhy is that?\nThat's crazy, right?\nHow is that possible?\nAnd that's an ion.\nSo a cell body is making\nproteins and all kinds of stuff\nthat have to get down\nto build synapses\nat the other end of that axon.\nAnd proteins diffuse a heck\nof a lot slower than ions do.\nSo basically a cell body\ncould make stuff for the axon,\nand it would never get there\nin your entire lifetime.\nAnd that's why cells have to\nactually make little trains.\nThey literally\nmake little trains.\nThey package up stuff\nand put it on the train\nand it just marches down the\naxon until it gets to the end.\nAnd this is the reason why.\nSo what we're going to do is\nI'm going to just walk you\nthrough a very simple\nderivation of why this is true\nand how to think about this.\nSo here's what\nwe're going to do."], "1950": [21, 50, "But it's just much harder\nto analyze things in three\ndimensions..\nSo you can get basically\nthe right answer\njust by analyzing how things\ndiffuse in one dimension.\nSo Daniel made this\nlittle video to show you\nwhat this looks like.\nThis is I think 100 particles\nall lined up near zero.\nAnd we're going to\nturn on the video.\nWe're going to let them all\nstart diffusing at one moment.\nSo you can just watch\nwhat happens to all\nthese different particles.\nSo you can see that\nsome particles end up\nover here on the left.\nOther particles end up\nover here on the right.\nYou can see that the\ndistribution of particles\nspreads out.\nAnd so we're going to figure out\nwhy that is, why that happens.\nSo the first thing I\njust want to tell you"], "2000": [22, 60, "if they all start at\nzero, and they diffuse\nin 1D away from zero, the\ndistribution that you get\nis Gaussian.\nAnd the basic reason is that,\nlet's start at the center,\nand on every time step they\nhave a probability of 1/2\nof going to the right and\n1/2 of going to the left.\nAnd so basically there\nare many more combinations\nof ways a particle can do\nsome lefts and do some rights\nand end up back\nwhere it started.\nIt's very unlikely\nthat the particle\nwill do a whole bunch of\ngoing right all in a row.\nAnd so that's why the\ndensity and the distribution\nis very low down here.\nAnd so you end up\nwith something that's\njust a Gaussian distribution.\nSo let's analyze this\nin a little more detail.\nSo we're going to just make a\nvery simple model of particles"], "2060": [23, 50, "We're going to consider\na particle that\nis moving left or right at a\nfixed velocity vx for some time\ntau before a collision.\nAnd we're going to imagine\nthat each time the particle\ncollides it resets its velocity\nrandomly, either to the left\nor to the right.\nSo on every time step,\nhalf the particles\nwill step right by\na distance delta,\nwhich is the velocity\ntimes the time tau.\nAnd the other half\nof the particles\nwill step left by\nthat same distance.\nSo they're going either to\nthe left or to the right\nby a distance delta."], "2110": [24, 90, "start at position\n0 at time 0, then\nwe can write down the position\nof every particle at time step\nn, the i-th particle\nat time step n.\nAnd we're going to assume that\neach particle is independent,\neach doing their own\nthing, ignoring each other.\nSo now you can see\nthat you can write down\nthe position of the particle\nat time step n is just\nthe position of the particle\nat the previous time\nstep, plus or minus\nthis little delta.\nAny questions about that?\nSo please, if you ever just\nhaven't followed one step\nthat I do, just let me know.\nI'm happy to explain it again.\nI often am watching somebody\nexplaining something really\nsimple, and my brain is\njust in some funny state\nand I just don't get it.\nSo it's totally fine if you want\nme to explain something again.\nYou don't have to be\nembarrassed because happens\nto me all the time.\nSo now what we can do\nis use this expression,\ncompute how that distribution\nevolves over time,\nhow that distribution of\nparticles, this i-th particle"], "2200": [25, 160, "All right, so let's calculate\nwhat the average position\nof the ensemble is.\nSo these brackets mean average.\nSo the bracket with an\ni, that I'm averaging\nthis quantity over i particles.\nAnd so it's just\nthe sum of positions\nfor every particle, divided\nby the number of particles.\nThat's the average position.\nSo again, the position of the\ni-th particle at time step n\nis just the position of that\nparticle at the previous time\nstep, plus or minus delta.\nWe just plug that into\nthere, into there.\nAnd now we calculate the sum.\nBut we have two terms.\nWe have this term and that term.\nLet's break them up\ninto two separate sums.\nSo this is equal to the sum\nover the previous positions,\nplus the sum over how\nmuch the change was\nfrom one time step to the next.\nDoes that makes sense?\nBut what is this sum?\nWe're summing over\nall the particles,\nhow much they changed from\nthe previous time step\nto this time step.\nWell, half of them moved to\nthe right and half of them\nthe left.\nSo that sum is just zero.\nSo you can see that\nthe average position\nof the particles\nat this time step\nis just equal to the average\nposition of the particles\nat the previous time step.\nAnd what that means is that\nthe center of the distribution\nhasn't changed.\nIf you start all the particles\nat zero, they diffuse around.\nThe average position\nis still zero.\nYes?\nAUDIENCE: [INAUDIBLE]\nbracket [INAUDIBLE]..\nMICHALE FEE: Yes.\nSo this here is just this.\nSo this bracket means I'm\naveraging over this quantity i.\nSo you can see that's\nwhat I'm doing here.\nI'm summing over i and dividing\nby the number of particles.\nAUDIENCE: And what is i?\nMICHALE FEE: I is\nthe particle number.\nSo if we have 10 particles,\ni goes from 1 to 10.\nThank you.\nSo that's a little boring.\nBut we used a trick\nhere that we're\ngoing to use now to\nactually calculate\nthe interesting thing, which\nis on average how far do\nthe particles get from\nwhere they started.\nSo what we're going to do is not\ncalculate the average position\nof all the particles.\nWe're going to calculate\nthe average absolute value"], "2360": [26, 150, "Does that makes sense?\nWe're going to ask, on average,\nhow far did they get from where\nthey started, which was zero.\nSo absolute values,\nnobody likes.\nThey're hard to deal with.\nBut this is exactly the same\nas calculating the square root\nof the average square.\nIt's the same as\ncalculating the variance.\nDoes that makes sense?\nSo what we're going\nto do is we're\ngoing to calculate the\nvariance of that distribution.\nAnd the square root\nof that variance\nis just the standard deviation,\nwhich is just how wide it is,\nwhich is just how far on\naverage the particles got\nfrom where they started.\nDoes that makes sense?\nSo let's push on.\nWe're going to calculate\nthe average square distance.\nNow we're just going to take\nthe square of that at the end.\nSo the average of the\nposition squared, we're\ngoing to plug this into here.\nSo we're going to square it.\nSo the position of\nthe particle squared\nis just this quantity squared.\nLet's factor it out.\nSo we have this term\nsquared plus twice\nthat times that here,\nplus that term squared.\nAnd we're going to\nnow plug that average.\nSo the average position\nsquared is just the average.\nThe average position\nsquared at this time step n\nis the average position\nsquared at the previous time\nstep plus some other stuff.\nAnd let's take a look at\nwhat that other stuff is.\nWhat is this?\nThis is plus or\nminus 2 times delta,\nwhich is the step it takes,\nthe size of the step times x.\nSo what is that average?\nHalf of these are positive and\nhalf of these are negative.\nSo the average is zero.\nAnd quantity is the\naverage of delta squared.\nWell, delta squared is\nalways positive, right?\nSo what does this say?\nWhat this says is that the\nvariance at this time step\nis just the variance\nat a previous time step\nis a constant.\nSo let's analyze that."], "2510": [27, 180, "the variance grows\nby some constant.\nDelta is a distance.\nDelta squared is just the units\nof variance of a distribution\nthat's a function of distance.\nSo if the variance\nat time step 0 is 0,\nthat means they're all\nlined up at the origin.\nOne time step later, the\nvariance will be delta squared.\nThe next time step, it\nwill be two delta squared.\nThe next time step,\ndot, dot, dot.\nUp at some time step n, it\nwill be n times delta squared.\nSo you see what's happening?\nThe variance of\nthis distribution\nis growing linearly.\nWe can change from time\nsteps to continuous time.\nSo the step number\nis just time divided\nby tau, which is\nsome interval in time\nlike the interval\nbetween collisions.\nAnd so you can see that\nthe variance is just\ngrowing linearly in time where\nthe variance is just 2 times d\ntimes T, where d is what we\ncall the diffusion coefficient.\nIt's just length\nsquared divided by time.\nWhy is that?\nBecause as time grows, the\nvariance grows linearly.\nSo if we want to take\ntime, multiply it\nby something that\ngives us variance,\nit has to be variance\nper unit time.\nAnd variance, for\nsomething that's\na distribution of position,\nhas to have position squared.\nYes?\nAUDIENCE: But do we like\n[INAUDIBLE],, like that?\nMICHALE FEE: It's built\ninto the definition\nof the diffusion constant, OK?\nAny questions about that?\nAnd now here here's the answer.\nSo the variance is\ngrowing linearly in time.\nWhat that means is that\nthe standard deviation,\nthe average distance\nfrom the starting point,\nis growing as the\nsquare root of time.\nAnd that's key.\nThat I want you to remember.\nThe distance that\na particle diffuses\nfrom its starting\npoint on average grows\nis the square root of time."], "2690": [28, 190, "So for a small molecule,\na typical small molecule,\nthe diffusion constant is 10 to\nthe minus 5 centimeters squared\nper second.\nAnd so now we can just plug\nin some distances in times\nand see how long it\ntakes this particle\nto diffuse some distance.\nSo let's do that.\nLet's plug in a\nlength of 10 microns.\nThat was our soma,\nour cell body.\nIt's 10 to the\nminus 3 centimeters.\nTime is that squared,\nlength squared.\nSo it's 10 to the minus 6\ncentimeters squared divided\nby the diffusion constant.\n2 times the diffusion constant,\n2 times 10 to the minus 5\ncentimeters squared per second.\nYou can see centimeter\nsquareds cancel.\nThat leaves us time.\n50 milliseconds.\nNow let's put in one millimeter.\nThat was the length\nof our dendrite.\nSo that's 10 to the\nminus 1 centimeter.\nSo we plug that into\nour equation for time.\nTime is just L squared--\nI forgot to actually\nwrite that down.\nHere's the equation\nthat I'm solving.\nSo what this equation at\nthe bottom here is saying\nis some distance is equal\nto the square root of 2dT.\nAnd I'm just saying L\nsquared is equal to 2 dT.\nAnd I'm solving for\nT, L squared over 2d.\nThat's the equation I'm solving.\nI'm giving you a length and I'm\ncalculating how long it takes.\nSo if you put in 10\nto the minus 1 here,\nyou get 10 to the minus\n2 divided by 2 times 10\nto the minus 500 seconds,\nwhich is about 10 minutes.\nAnd now if you ask how long\ndoes it take to go a meter,\nthat's 10 to the 2 centimeters.\nThat's 10 to the 4 divided\nby 10 to the minus 5.\nSomebody over here\nfigured it out right away.\nAbout 5 times 10\nto the 8 seconds,\nwhich is about 10 years.\nA year is pi times 10 to\nthe 7 seconds, by the way.\nPlus or minus a few percent.\nAny questions about that?\nCool, right?\nSo neurons and cells\nand biology has\nto go to extraordinary lengths\nto overcome this craziness\nof diffusion, which explains\na lot of the structure you\nsee in cells."], "2880": [29, 150, "So you can see that\ndiffusion causes\nthe movement of ions\nfrom places where\nthey're concentrated to places\nwhere there aren't so many\nions.\nSo let's take a little\nbit slightly more\ndetail look at that idea.\nSo what I'm going to\ntell you about now\nis called Fick's First Law.\nAnd the idea is that\ndiffusion produces\na net flow of particles from\nregions of high concentration\nto regions of lower\nconcentration.\nAnd the flux of\nparticles is proportional\nto the concentration gradient.\nNow this is just\nreally obvious, right?\nIf you have a box, and on the\nleft side of the box you have n\nparticles.\nThen on the right\nside of the box then\nyou're going to have particles\ndiffusing from here to there.\nAnd you're going\nto have particles\ndiffusing from there to there.\nBut because there are\nmore of them over here,\nthey're just going to be\nmore particles going this way\nthan there are that way.\nDoes that makes sense?\nLet's say each\nparticle here might\nhave a 50% chance of\ndiffusing here or staying here\nor diffusing somewhere else.\nParticles here also\nequally have probability\nof going either way.\nBut just because there\nare more of them here,\nthere's going to be more\nparticles going that way.\nYou can just\ncalculate the number\nof particles going this way\nminus the number of particles\ngoing that way.\nAnd that gives\nyou the net number\nof particles going to the right.\nBut what does that look like?\nYou have the number here minus\nthe number some distance away.\nAnd what if you were to\ndivide that by the distance?\nWhat would that look like?\nGood.\nIt looks like a derivative.\nSo if you calculate\nthe flux, it's\nminus the diffusion\nconstant times\n1 over delta, the separation\nbetween these boxes.\nIt's the concentration here\nminus the concentration there.\nAnd that is just a derivative.\nAnd that's Fick's First Law.\nI have a few slides at the\nend of the lecture that\ndo this derivation\nmore completely.\nSo please take a look at\nthat if you have time."], "3030": [30, 180, "This Fick's First Law, the fact\nthat concentration gradients\nproduce a flow of\nions, of particles,\nis so fundamental\nto how neurons work.\nAnd here we're\ngoing to be building\nthat up over the course of\nthe next couple lectures.\nSo imagine that you\nhave a cell that\nhas a lot of potassium\nions inside and very\nfew potassium ions outside.\nNow you can see\nthat you're going\nto have potassium ions\ndiffusing from here.\nSorry, and I forgot\nto say, let's\nsay that your cell\nhas a hole in it.\nSo you're going to have\npotassium ions diffusing\nfrom inside to outside\nthrough the hole.\nYou also have some\npotassium ions out here.\nAnd some of those\nmight diffuse in.\nBut there are just so\nmany more potassium ions\ninside than outside\nconcentration-wise\nthat the probability of one\ngoing out through the hole\nis just much higher than the\nprobability of a potassium ion\ngoing back into the cell.\nSo here I'm just zooming\nin on that channel,\non that pore through\nthe membrane.\nLots of potassium ions here.\nOn average, there's going to\nbe a net flow of potassium\nout through that hole.\nAnd we can plot the\nconcentration gradient\nthrough the hole.\nAnd you can see it's\nhigh here, it decreases,\nand it's low outside.\nAnd so there's a net flow that's\nproportional to the steepness\nof concentration profile.\nSo that's true,\nyou get a net flow,\neven if each particle is\ndiffusing independently.\nThey don't know anything\nabout each other.\nAnd yet that concentration\ngradient produces a current.\nAll concentration\ngradients go away.\nWhy is that?\nBecause calcium ions will flow\nfrom the inside of the cell\nto the outside of the cell until\nthey're the same concentration.\nAnd then you'll\nhave just as many\nflowing back inside as\nyou have flowing outside.\nWhy?\nSo eventually that would\nhappen to all of our cells.\nWhy doesn't that happen?\nAUDIENCE: [INAUDIBLE]\nbecause they're alive.\nMICHALE FEE: Well, that's\nexactly the right answer,\nbut there are a few\nintermediate steps.\nIf you were to not\nbe alive anymore,\nthe potassium ions\nwould just diffuse out.\nAnd that would be the end.\nBut what happens is\nthere are other proteins\nin the membrane that take\nthose potassium ions from here\nand pump them back inside and\nmaintain the concentration\ngradient.\nBut that costs energy.\nThose proteins use ATP.\nAnd that ATP comes from eating."], "3210": [31, 100, "But eventually all\nconcentration gradients go away.\nSo that is how we\nget current flow\nfrom concentration gradients.\nNow the next topic has to do\nwith the diffusion of ions\nin the presence of\nvoltage differences,\nin the presence of\nvoltage gradients.\nThe bottom line here\nthat I want you to know,\nthat I want you to understand,\nis that current flow in neurons\nobeys Ohm's Law.\nNow what does that mean?\nLet's imagine that\nwe have a resistor.\nLet's say across a membrane\nor in the intracellular\nor extracellular\nspace of a neuron.\nThe current flow through\nthat resistive medium\nis proportional to the\nvoltage difference.\nSo that's Ohm's Law.\nThe current is proportional\nto the voltage difference\nacross the two terminals, the\ntwo sides of the resistor.\nAnd the proportionality constant\nis 1 over the resistance.\nSo here current has\nunits of amperes.\nThe voltage difference\nis units of volts.\nAnd the resistance\nhas units of ohms.\nAny questions about that?\nSo let's go through--"], "3310": [32, 150, "and understand why it is that\na voltage difference produces\na current that's\nproportional to voltage.\nSo let's go back to\nour little [AUDIO OUT]\nfilled with salt solution.\nThere are ions in here\ndissolved in the water.\nWe have two metal plates.\nWe've put a battery between\nthe two metal plates that\nholds those two plates at\nsome fixed voltage difference\ndelta v. And we're going\nto ask what happens.\nSo let's zoom in here.\nThere is one plate\nthat's at one potential.\nThere's another plate\nat another potential.\nThere's some voltage\ndifference between those\nthat's delta v. The two plates\nare separated by a distance L.\nAnd that voltage difference\nproduces an electric field\nthat points from the\nhigh voltage region\nto the low voltage region.\nSo an electric field produces\na force on a charge--\nwe have lots of\ncharges in here--\nthat's proportional to the\ncharge and the electric field.\nSo what is that\nforce going to do?\nThat force is just going\nto drag that particle\nthrough the liquid,\nthrough the water.\nSo why is it?\nSo if this were a vacuum in\nhere and we put a charge there\nand metal plates and we\nput a battery across,\nwhat would that particle do?\nIt would move.\nBut what would this force\ndo to that particle?\nAUDIENCE: [INTERPOSING VOICES]\nMICHALE FEE: Exactly.\nSo what would the velocity do?\nAUDIENCE: Increase.\nMICHALE FEE: It would\njust increase linearly.\nSo the particle\nwould start moving.\nAnd it would start moving\nslowly and it'd go--\npoof-- crash into the plate.\nBut that's not\nwhat happens here.\nWhy is that?\nAUDIENCE: [INAUDIBLE]\nMICHALE FEE: Because\nthere's stuff in the way.\nAnd so it accelerates, and it\ngets hit by a water molecule.\nAnd it gets pushed\noff in some direction.\nAnd then it accelerates in\nthis direction, gets hit again.\nBut it's constantly being\naccelerated in one direction\nbefore it collides.\nAnd so here's what happens."], "3460": [33, 70, "So it's diffusing around.\nBut on each step, it has a\nlittle bit of acceleration\nin this direction,\nin the direction\nof the electric field.\nAnd so you can show using\nthe same kind of analysis\nthat we used in calculating\nthe distribution, the change\nin mean and variance,\nyou can show\nthat mean of a\ndistribution of particles\nthat starts at zero shifts--\nof positive particles\nshifts in the electric field\nlinearly in time.\nAnd you can just think about\nthat as the electric field\nreaches in, grabs that\ncharged particle, and pulls it\nin this direction\nagainst viscous drag.\nSo now a force produces\na constant velocity, not\nacceleration."], "3530": [34, 130, "So the force is proportional\nto drift velocity.\nWhat is that little f there?\nAnybody know what that is?\nAUDIENCE: Frictional\ncoefficient.\nMICHALE FEE: It's\nthe coefficient\nof friction of that particle.\nAnd Einstein cleverly\nnoticed that the coefficient\nof friction of a particle\nbeing dragged through a liquid\nis related to what?\nAny guess?\nDiffusion coefficient\nof that particle.\nIs that cool?\nThat just gives me chills.\nThe frictional\ncoefficient is just\nkT over the diffusion constant.\nSo if you actually just go\nthrough that same analysis\nof calculating the mean of the\ndistribution, what you find\nis that v moves\nlinearly in time.\nBut it's also very intuitive.\nIf you're in a swimming pool,\nyou put your hand in the water,\nand you push your hand\nwith a constant force.\nWhat happens?\nWell, let me flip it around.\nYou move your hand through the\nwater at a constant velocity.\nWhat is the force feel like?\nThe force is constant, right?\nSo flip it the other way around.\nIf the force is\nconstant, then you're\ngoing to get a\nconstant velocity.\nYes?\nAUDIENCE: So side\nquestion, but you can also\nlook at that like a\nterminal velocity problem?\nMICHALE FEE: Exactly.\nIt's exactly the same thing.\nSo the drift velocity is\nproportional to the force\nby proportionality constant,\n1 over the coefficient\nof friction, which\nis now d over kT.\nAnd what is this\nforce proportional to?\nAnybody remember?\nThe force was proportional\nto the electric field."], "3660": [35, 90, "So I'm going to argue\nthat the current is\nproportional to the drift\nvelocity times the area.\nNow why is that?\nSo if I have an\nelectric field, it\nmakes these particles, all\nthe particles in this area\nhere drift at a constant\nvelocity in this direction.\nSo there is a certain\namount of current\nthat's flowing in\nthis area right here.\nDoes that makes sense?\nNow if my electrodes are big\nand I also have electric field\nup here, then that\nelectric field\nis causing current\nto flow up here too.\nAnd if there's\nelectric field up here,\nthen there will be current\nflowing up here too.\nAnd so you can see that the\namount of current that's\nflowing between the electrodes\nis proportional to the drift\nvelocity and the cross-sectional\narea between the two\nelectrodes.\nYes?\nSo that's really important.\nNow we figured out\nthat the drift velocity\nis proportional to\nthe electric field.\nSo the current is proportional\nto the electric field\ntimes the area.\nAnd the electric field is\njust the voltage difference\ndivided by the spacing\nbetween the electrodes.\nAnd so the current is\nproportional to voltage"], "3750": [36, 160, "So we have a proportionality.\nCurrent is\nproportional to voltage\ntimes area divided by length.\nAnd now let's plug in what that\nproportionality constant is.\nThis is now like\nOhm's Law, right?\nWe're saying the current\nis proportional to voltage\ndifference.\nThe thing that the\nproportionality constant\nhere is something\ncalled resistivity.\nOtherwise known as conductivity.\nBut we're going to\nuse resistivity.\nSo this is just Ohm's Law.\nIt says current is proportional\nto voltage difference.\nLet's rewrite that a\nlittle bit so that it\nlooks more like Ohm's Law.\nCurrent is proportional\nto voltage difference.\nAnd that thing, that\nthingy right there,\nshould have units of what?\n1 over ohms.\nRight?\nSo that is 1 over resistance.\nLet's just write down\nwhat the resistance is.\nResistance is just resistivity\ntimes length divided by area.\nSo let's just stop\nand take a breath\nand think about why\nthis makes sense.\nResistance is how\nmuch resistance there\nis to flow at a\ngiven voltage, right?\nSo what happens if we\nmake ours really small?\nWhat happens to the resistance?\nAUDIENCE: [INAUDIBLE]\nreally big.\nMICHALE FEE: The\nresistance gets big.\nThe amount of current gets\nsmall because there's less area\nthat the electric field is in.\nAnd so the current goes down.\nThat means the\nresistance is big.\nIf we make our\nplates really big,\nthe resistance gets smaller.\nWhat happens if we pull\nour plates further apart?\nWhat happens to the resistance?\nAUDIENCE: [INAUDIBLE]\nfurther apart.\nMICHALE FEE: Good.\nIf the plates are further\napart, L is bigger,\nand resistance is bigger.\nBut conceptually,\nwhat's going on?\nPhysically, what's going?\nThe plates are further\napart, so what happens?\nAUDIENCE: [INAUDIBLE]\nMICHALE FEE: Right.\nThe voltage difference\nis the same,\nbut the distance is bigger.\nAnd so the electric field,\nwhich is voltage per distance,\nis smaller.\nAnd that smaller electric field\nproduces a drift velocity.\nAnd that's why the\nresistance goes up.\nCool, right?\nOK."], "3910": [37, 210, "So resistivity in the brain\nis really, really lousy.\nThe wires of the\nbrain are just awful.\nSo if you look at the\nresistivity for copper, which\nis which is the wire\nthat's used in electronics,\nthe resistivity is 1.6\nmicroohms times centimeters.\nWhat that means is if I took a\nblock of copper, a centimeter\non a side, and I put\nelectrodes on the side of it,\nand I measured the resistance,\nit would be 1.6 microohms.\nThat means I could run an amp,\nthat thing with 1.6 microvolts.\nNow the resistivity of the\nbrain is 60 ohms centimeters.\nThat means a centimeter of\nblock of saline solution,\nintracellular or\nextracellular solution,\nhas a resistance of 60 ohms\ninstead of 1.6 microohms.\nIt's more than a\nmillion times worse.\nAnd what that means is that\nwhen you try to send current\nthrough brain, you try\nto send some current,\nthe voltage just drops.\nYou need huge voltage drops\nto produce tiny currents.\nThat's why the brain\nhas invented things--\naxons-- because the\nwires are so bad that you\ncan't send a signal from\none part of the brain\nto another part of the\nbrain through the wire.\nYou have to invent this special\ngimmick called an action\npotential to send a signal\nmore than a few microns away.\nIt's pretty cool, right?\nThat's why it's so interesting\nto understand the basic physics\nof something, the basic\nmechanisms by which something\nworks because most\nof what you see\nis a hack to compensate\nfor weird physics, right?\nYes?\nAUDIENCE: Does this [INAUDIBLE]?\nMICHALE FEE: This\nhigh resistivity--\nyou're asking what causes\nthat high resistivity.\nIt basically has to do with\nthings like the mean-free path\nof the particle.\nSo in a metal, particles\ncan go further effectively\nbefore they collide.\nSo the resistivity is lower.\nAUDIENCE: Is that\nslope [INAUDIBLE]??\nMICHALE FEE: It's a little\nbit different inside the cell\nbecause there's more\ngunk inside of a cell\nthan there is outside of a cell.\nAnd so the resistivity\nis a little bit worse.\nIt's 2,000 ohms centimeters,\nor 1,000 or 2,000\ninside the cell and\nmore like 60 outside.\nAUDIENCE: [INAUDIBLE]\nMICHALE FEE: Yes once\nyou're outside the cell,\nit's basically the\nsame everywhere."], "4120": [38, 110, "So that's it.\nSo here's what we\nlearned about today.\nWe understood the relation\nbetween the timescale\nof diffusion and length scales.\nAnd we learned that the distance\nthat a particle can diffuse\ngrows only as the\nsquare root of time.\nWe understood how concentration\ngradients lead to currents.\nAnd we talked about\nFick's First Law\nthat says that concentration\ndifferences lead\nto particle flux.\nThe flux is proportional to\nthe gradient or the derivative\nof the concentration.\nAnd we also talked about how\nthe drift of charged particles\nin an electric field\nleads to currents,\nand how the voltage current\nrelation obeys Ohm's Law.\nAnd we also talked about\nthe concept of resistivity\nand how the resistivity in\nthe brain is really high\nand makes the wires in\nthe brain really bad.\nSo that's all I have.\nI will take any questions.\nYes, Daniel?\nAUDIENCE: I just wanted\nto introduce David.\nMICHALE FEE: OK.\nOur other TA is here.\nAny questions?\nGreat.\nSo we will see you--\nwhen is the first [AUDIO OUT]?\nIs that--\nAUDIENCE: Tomorrow.\nMICHALE FEE: Tomorrow.\nSo I will see you Thursday."]}