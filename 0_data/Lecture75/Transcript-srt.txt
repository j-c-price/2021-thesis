1
00:00:01,640 --> 00:00:04,040
The following content is
provided under a Creative

2
00:00:04,040 --> 00:00:05,610
Commons license.

3
00:00:05,610 --> 00:00:07,880
Your support will help
MIT OpenCourseWare

4
00:00:07,880 --> 00:00:12,270
continue to offer high quality
educational resources for free.

5
00:00:12,270 --> 00:00:14,870
To make a donation or
view additional materials

6
00:00:14,870 --> 00:00:18,830
from hundreds of MIT courses,
visit MIT OpenCourseWare

7
00:00:18,830 --> 00:00:20,000
at ocw.MIT.edu.

8
00:00:22,940 --> 00:00:25,430
RAJESH KASTURIRANGAN: My
name is Rajesh Kasturirangan.

9
00:00:25,430 --> 00:00:28,010
I'm one of the
co-founders of ClimateX,

10
00:00:28,010 --> 00:00:32,870
which is one of the co-sponsors
of this event along with Fossil

11
00:00:32,870 --> 00:00:40,130
Free MIT and many, many other
organizations on the MIT

12
00:00:40,130 --> 00:00:41,310
campus.

13
00:00:41,310 --> 00:00:45,530
We also have non-MIT people
here, several of whom--

14
00:00:45,530 --> 00:00:47,900
some of whom are MIT alums.

15
00:00:47,900 --> 00:00:50,600
So Jeff Warren is
one of our speakers.

16
00:00:50,600 --> 00:00:54,830
Britta Voss, who is on Skype
over there is another speaker.

17
00:00:54,830 --> 00:00:57,660
And then we have Nathan
Phillips and Audrey Schulman.

18
00:00:57,660 --> 00:01:01,250
So we have a really,
really fantastic lineup.

19
00:01:01,250 --> 00:01:05,420
But let me just explain
what we are doing and why.

20
00:01:05,420 --> 00:01:13,460
So ClimateX-- the idea is to
create an open climate learning

21
00:01:13,460 --> 00:01:19,010
platform for the whole world,
but starting with the MIT

22
00:01:19,010 --> 00:01:20,990
community and then
broadening that

23
00:01:20,990 --> 00:01:22,980
to the greater Boston area.

24
00:01:22,980 --> 00:01:27,950
So IAP, as some of you know,
is the Independent Activities

25
00:01:27,950 --> 00:01:29,300
Period at MIT.

26
00:01:29,300 --> 00:01:33,500
And that's the time when we
do all kinds of fun things.

27
00:01:33,500 --> 00:01:36,620
And there are many, many
climate-related courses

28
00:01:36,620 --> 00:01:41,510
being offered, which we
decided why not bring them

29
00:01:41,510 --> 00:01:45,860
under one umbrella and
call it The Climate IAP.

30
00:01:45,860 --> 00:01:51,650
So if you go to
sites.google.com/cliap you will

31
00:01:51,650 --> 00:01:54,680
see all of the courses
that are being organized.

32
00:01:54,680 --> 00:02:00,920
And so that's across
the spectrum, everything

33
00:02:00,920 --> 00:02:08,449
from climate science, to
policy, to energy negotiations

34
00:02:08,449 --> 00:02:09,860
in places like Mexico.

35
00:02:09,860 --> 00:02:13,520
So what we're doing
here is to say

36
00:02:13,520 --> 00:02:18,030
how can citizens
directly take action

37
00:02:18,030 --> 00:02:20,240
which is grounded in science?

38
00:02:20,240 --> 00:02:25,040
And we have actually some
fantastic speakers here today

39
00:02:25,040 --> 00:02:28,670
who have contributed to
that in many different ways.

40
00:02:28,670 --> 00:02:32,390
Our first speaker, who will
be introduced by Britta,

41
00:02:32,390 --> 00:02:34,640
will be Jeff Warren.

42
00:02:34,640 --> 00:02:38,090
And Jeff Warren is one of the
founders of Public Lab, which

43
00:02:38,090 --> 00:02:41,030
does, you could say,
community science

44
00:02:41,030 --> 00:02:45,710
around environmental questions,
both building the hardware that

45
00:02:45,710 --> 00:02:50,180
allows you to sense
environmental variables

46
00:02:50,180 --> 00:02:54,890
and the discussion and
analysis that comes

47
00:02:54,890 --> 00:02:56,810
from collecting that data.

48
00:02:56,810 --> 00:02:59,540
We have Nathan Phillips
and Audrey Schulman,

49
00:02:59,540 --> 00:03:01,760
who have done some
great work together

50
00:03:01,760 --> 00:03:05,420
on gas leaks in the
greater Boston area.

51
00:03:05,420 --> 00:03:10,610
And those gas leaks will be the
focus of not just this session,

52
00:03:10,610 --> 00:03:12,140
but also the next three.

53
00:03:12,140 --> 00:03:14,450
So we have three more
sessions after this one.

54
00:03:14,450 --> 00:03:18,170
There's one on the 23rd,
which is a data hackathon.

55
00:03:18,170 --> 00:03:22,640
So we're going to take a dump
of data from Audrey and Nathan,

56
00:03:22,640 --> 00:03:26,010
and we're going to do really
fantastic things with it.

57
00:03:26,010 --> 00:03:29,210
And then, if you're really
interested in seeing where

58
00:03:29,210 --> 00:03:34,490
these gas leaks are, we're going
to go on a tour on the 30th

59
00:03:34,490 --> 00:03:37,040
across the
Cambridge-Somerville area

60
00:03:37,040 --> 00:03:41,420
and do some gas
sensing on our own.

61
00:03:41,420 --> 00:03:42,900
And once that's
done, we're going

62
00:03:42,900 --> 00:03:45,050
to come back on
the 1st of February

63
00:03:45,050 --> 00:03:52,190
and say, how do we take this
and make that work for us

64
00:03:52,190 --> 00:03:53,930
in the public interest, right?

65
00:03:53,930 --> 00:03:57,560
And so generally,
I think the flow

66
00:03:57,560 --> 00:04:01,490
that we are trying to prototype
here in these four sessions

67
00:04:01,490 --> 00:04:07,370
is that citizens can work with
scientists and policymakers

68
00:04:07,370 --> 00:04:12,980
and others to directly
take charge of the climate

69
00:04:12,980 --> 00:04:16,250
challenges that affect
them wherever they are.

70
00:04:16,250 --> 00:04:22,700
And that by doing so, we can
contribute to climate action,

71
00:04:22,700 --> 00:04:24,800
but climate action that's
grounded in knowledge

72
00:04:24,800 --> 00:04:28,470
and not just pure advocacy.

73
00:04:28,470 --> 00:04:32,510
So I think that's a really
fantastic new opportunity that

74
00:04:32,510 --> 00:04:34,730
did not exist even
a few years ago.

75
00:04:34,730 --> 00:04:38,000
So I'm really, really
happy that we have

76
00:04:38,000 --> 00:04:39,690
a wonderful cast of speakers.

77
00:04:39,690 --> 00:04:41,810
I'm going to turn it
over to Britta Voss

78
00:04:41,810 --> 00:04:44,949
to introduce today's session.

79
00:04:44,949 --> 00:04:45,740
BRITTA VOSS: Great.

80
00:04:45,740 --> 00:04:46,710
All right.

81
00:04:46,710 --> 00:04:47,656
Thanks, Rajesh.

82
00:04:47,656 --> 00:04:48,650
Can everybody hear me?

83
00:04:48,650 --> 00:04:49,796
RAJESH KASTURIRANGAN: Yes.

84
00:04:49,796 --> 00:04:51,050
BRITTA VOSS: OK.

85
00:04:51,050 --> 00:04:53,260
So my name is Britta Voss.

86
00:04:53,260 --> 00:04:55,710
And I'm an MIT alum from 2014.

87
00:04:55,710 --> 00:04:57,840
So I just wanted to
start off with a sort

88
00:04:57,840 --> 00:05:00,570
of a brief overview
of our motivation

89
00:05:00,570 --> 00:05:03,880
and the idea behind
Community Science.

90
00:05:03,880 --> 00:05:05,940
And so we called this
From Community Science

91
00:05:05,940 --> 00:05:07,390
to Community Action.

92
00:05:07,390 --> 00:05:09,810
And that really gets at
sort of a larger motivation

93
00:05:09,810 --> 00:05:13,830
for this series of seminars--
of taking science and putting

94
00:05:13,830 --> 00:05:15,830
it to use for people.

95
00:05:15,830 --> 00:05:19,224
And it gets at
the mission of MIT

96
00:05:19,224 --> 00:05:24,977
as an institution of using
science for [INAUDIBLE]..

97
00:05:24,977 --> 00:05:27,060
I just want to start off
really, really broad here

98
00:05:27,060 --> 00:05:29,500
and ask the question of
what is science even for?

99
00:05:29,500 --> 00:05:32,040
Why do we have science?

100
00:05:32,040 --> 00:05:34,950
And my interpretation
of this is that humans

101
00:05:34,950 --> 00:05:37,055
are naturally
curious, and we want

102
00:05:37,055 --> 00:05:38,490
to understand the
world around us.

103
00:05:38,490 --> 00:05:39,710
And we also have needs.

104
00:05:39,710 --> 00:05:42,640
We need food and shelter
and transportation.

105
00:05:42,640 --> 00:05:46,065
And so science has this
double purpose for humanity.

106
00:05:46,065 --> 00:05:51,230
It feeds our curiosity, but it
also helps us solve problems.

107
00:05:51,230 --> 00:05:53,280
And it gives us a
process and a framework

108
00:05:53,280 --> 00:05:56,570
for addressing both
of those issues.

109
00:05:56,570 --> 00:05:58,230
And we all know
that science is very

110
00:05:58,230 --> 00:05:59,440
important in modern society.

111
00:05:59,440 --> 00:06:01,815
It's pretty much everywhere
you go, from your smartphones

112
00:06:01,815 --> 00:06:04,510
to social networking
to the systems

113
00:06:04,510 --> 00:06:07,560
and the infrastructure to
make modern life possible.

114
00:06:07,560 --> 00:06:10,680
And although we're all
very aware of that,

115
00:06:10,680 --> 00:06:12,787
very few people have
a direct relationship

116
00:06:12,787 --> 00:06:15,120
with science, either by doing
it themselves in their day

117
00:06:15,120 --> 00:06:18,280
to day lives, or even the
other people in their lives.

118
00:06:18,280 --> 00:06:21,170
And so another motivation
for this seminar series

119
00:06:21,170 --> 00:06:23,520
is that we're looking
for an angle that

120
00:06:23,520 --> 00:06:26,760
will help us make science
more relevant to people,

121
00:06:26,760 --> 00:06:29,380
make people care
more about science,

122
00:06:29,380 --> 00:06:32,910
because it has a very
important role in our society.

123
00:06:32,910 --> 00:06:35,340
And despite how
important science is,

124
00:06:35,340 --> 00:06:37,290
we all know that
science is often

125
00:06:37,290 --> 00:06:41,220
misused and mischaracterized
at shockingly high levels

126
00:06:41,220 --> 00:06:43,150
of our leadership.

127
00:06:43,150 --> 00:06:47,520
When you see very prominent
people making comments

128
00:06:47,520 --> 00:06:52,830
about scientifically
false issues,

129
00:06:52,830 --> 00:06:55,369
and even to the point of someone
like a US senator bringing

130
00:06:55,369 --> 00:06:56,910
a snowball to the
floor of the Senate

131
00:06:56,910 --> 00:06:58,640
to prove that climate
change is false.

132
00:06:58,640 --> 00:07:01,260
So there's obviously
a lot that needs

133
00:07:01,260 --> 00:07:04,080
to be done to make
society more aware of

134
00:07:04,080 --> 00:07:07,740
and informed about science.

135
00:07:07,740 --> 00:07:11,060
And so how can community
science address that?

136
00:07:11,060 --> 00:07:12,720
Community science
is a way of making

137
00:07:12,720 --> 00:07:14,700
science speak for communities.

138
00:07:14,700 --> 00:07:18,930
So climate change is probably
the best way, or the best

139
00:07:18,930 --> 00:07:22,710
example, of an area of science
where community involvement

140
00:07:22,710 --> 00:07:23,940
is critical.

141
00:07:23,940 --> 00:07:26,730
Because here, for
example, you can

142
00:07:26,730 --> 00:07:29,460
see the effects of climate
change on agriculture

143
00:07:29,460 --> 00:07:30,790
affect people's livelihoods.

144
00:07:30,790 --> 00:07:33,030
They affect the economy.

145
00:07:33,030 --> 00:07:36,090
And people who depend on
agriculture, which is not just

146
00:07:36,090 --> 00:07:37,770
all of us, the food
we eat, but people

147
00:07:37,770 --> 00:07:40,320
who make their livelihood
off of farming,

148
00:07:40,320 --> 00:07:43,680
need to understand how
climate change is affecting

149
00:07:43,680 --> 00:07:46,830
agricultural productivity
from droughts and wildfires

150
00:07:46,830 --> 00:07:47,920
and all sorts of issues.

151
00:07:47,920 --> 00:07:49,550
And so science can
help them with that

152
00:07:49,550 --> 00:07:54,000
if it is directly
addressing their needs.

153
00:07:54,000 --> 00:07:55,500
And then just a
few more examples--

154
00:07:55,500 --> 00:07:57,375
climate change is
affecting water temperature

155
00:07:57,375 --> 00:08:00,490
in rivers which has effects
on migratory fish populations

156
00:08:00,490 --> 00:08:03,640
that serve as important
cultural and economic basis

157
00:08:03,640 --> 00:08:06,910
for Native American populations.

158
00:08:06,910 --> 00:08:08,730
Nuisance flooding in
cities like Boston,

159
00:08:08,730 --> 00:08:12,390
and especially in South Florida,
is becoming a big problem

160
00:08:12,390 --> 00:08:17,110
for quality of life and economic
vitality in a lot of areas.

161
00:08:17,110 --> 00:08:19,590
Communities in the
Arctic are literally

162
00:08:19,590 --> 00:08:21,410
falling into the sea
in some places because

163
00:08:21,410 --> 00:08:24,100
of thawing permafrost.

164
00:08:24,100 --> 00:08:26,070
And then, of course,
in northern Alberta,

165
00:08:26,070 --> 00:08:28,570
you have tar sands mining
that's wiping out the forests,

166
00:08:28,570 --> 00:08:32,820
and it's dumping lots of
toxins into local rivers.

167
00:08:32,820 --> 00:08:35,530
And these toxins are going
downstream and making

168
00:08:35,530 --> 00:08:37,590
first nations communities sick.

169
00:08:37,590 --> 00:08:41,970
And so by producing independent
science for those groups,

170
00:08:41,970 --> 00:08:44,640
you can help them fight
back against these sorts

171
00:08:44,640 --> 00:08:47,350
of environmental threats.

172
00:08:47,350 --> 00:08:50,260
Communities living downwind
of coal-fired power plants

173
00:08:50,260 --> 00:08:53,490
similarly are at
serious risk of things

174
00:08:53,490 --> 00:08:57,300
like mercury contamination,
articulate aerosols,

175
00:08:57,300 --> 00:08:59,680
and other negative
health effects.

176
00:08:59,680 --> 00:09:03,090
And so if these communities
have tools of science,

177
00:09:03,090 --> 00:09:06,630
they might be able to
file lawsuits or come

178
00:09:06,630 --> 00:09:09,800
to their policy makers
and say that they need

179
00:09:09,800 --> 00:09:13,061
a certain regulation or policy.

180
00:09:13,061 --> 00:09:14,560
And another good
example, of course,

181
00:09:14,560 --> 00:09:16,830
is fracking, where the local
communities, especially

182
00:09:16,830 --> 00:09:18,560
if there's wastewater
injection going on,

183
00:09:18,560 --> 00:09:21,390
might be at risk for ground
water contamination, irregular

184
00:09:21,390 --> 00:09:27,060
seismic activity, and lots
of other environmental risks.

185
00:09:27,060 --> 00:09:30,540
So the motivations
for community science

186
00:09:30,540 --> 00:09:33,690
would be empowering
communities by giving them

187
00:09:33,690 --> 00:09:36,450
ownership of their
data and responding

188
00:09:36,450 --> 00:09:38,280
to their specific needs.

189
00:09:38,280 --> 00:09:39,940
And with respect
to the scientists,

190
00:09:39,940 --> 00:09:41,890
it increases public
awareness and interest

191
00:09:41,890 --> 00:09:45,060
in science, which is
important to making sure

192
00:09:45,060 --> 00:09:47,730
that science is still a
part of decision making

193
00:09:47,730 --> 00:09:50,580
and that science is
supported long term.

194
00:09:50,580 --> 00:09:53,220
And also importantly,
especially in the context

195
00:09:53,220 --> 00:09:55,371
of climate sciences,
making sure that scientists

196
00:09:55,371 --> 00:09:57,870
have access to local knowledge
that they might not otherwise

197
00:09:57,870 --> 00:10:00,152
be aware of.

198
00:10:00,152 --> 00:10:02,190
But of course, there's
also challenges.

199
00:10:02,190 --> 00:10:04,680
So just like with
traditional science,

200
00:10:04,680 --> 00:10:07,100
community science needs to
ensure the data is high quality

201
00:10:07,100 --> 00:10:10,060
and that it can be used for the
purposes of the community that

202
00:10:10,060 --> 00:10:10,560
needs it.

203
00:10:10,560 --> 00:10:13,490
For instance, that it will
hold up in a court of law.

204
00:10:13,490 --> 00:10:16,450
These projects need to
have long term support.

205
00:10:16,450 --> 00:10:19,255
So if you're looking at a
long term monitoring program,

206
00:10:19,255 --> 00:10:21,380
it can be hard to make sure
that that's financially

207
00:10:21,380 --> 00:10:23,202
viable over the long term.

208
00:10:23,202 --> 00:10:26,040
And then, the community's
needs might change over time,

209
00:10:26,040 --> 00:10:27,930
if the environmental
threats change,

210
00:10:27,930 --> 00:10:30,300
or if the make up of
the community changes.

211
00:10:30,300 --> 00:10:34,880
And so research projects need
to be able to respond to that.

212
00:10:34,880 --> 00:10:37,600
And I'm sure Jeff can
talk more about this--

213
00:10:37,600 --> 00:10:40,070
just a few ideas
about what can make

214
00:10:40,070 --> 00:10:42,210
community science successful.

215
00:10:42,210 --> 00:10:46,370
A few key factors are making
data and methods open source

216
00:10:46,370 --> 00:10:49,085
so they're freely available
and open for discussion.

217
00:10:49,085 --> 00:10:50,770
And similarly,
open communication

218
00:10:50,770 --> 00:10:52,770
between the community
members and the scientists

219
00:10:52,770 --> 00:10:55,935
themselves to make sure that
everyone is working together

220
00:10:55,935 --> 00:10:58,174
and not for their own purposes.

221
00:10:58,174 --> 00:10:59,715
And probably the
most important thing

222
00:10:59,715 --> 00:11:01,090
is making sure
that the community

223
00:11:01,090 --> 00:11:02,880
is involved from
the planning stages

224
00:11:02,880 --> 00:11:05,610
and not just
brought in later on.

225
00:11:05,610 --> 00:11:07,290
And that's basically
the key difference

226
00:11:07,290 --> 00:11:09,960
between community science
and what's usually

227
00:11:09,960 --> 00:11:12,510
known as citizen science.

228
00:11:12,510 --> 00:11:15,210
And finally, just in terms
of the appeal of community

229
00:11:15,210 --> 00:11:17,210
science, it's important
to encourage creativity,

230
00:11:17,210 --> 00:11:21,460
both from scientists
and community members.

231
00:11:21,460 --> 00:11:23,989
And I think one of the really
important aspects of community

232
00:11:23,989 --> 00:11:25,905
science is that it can
be a synthesis of tools

233
00:11:25,905 --> 00:11:29,490
and ideas from different fields
that might not happen naturally

234
00:11:29,490 --> 00:11:33,300
in traditional
scientific enterprise.

235
00:11:33,300 --> 00:11:37,212
So just, finally, some
examples-- there's

236
00:11:37,212 --> 00:11:38,420
probably many more out there.

237
00:11:38,420 --> 00:11:40,890
But Public Lab, as
Rajesh mentioned,

238
00:11:40,890 --> 00:11:43,984
you're going to hear from
Jeff about it pretty soon.

239
00:11:43,984 --> 00:11:45,900
And then there's also
the EarthWorks Community

240
00:11:45,900 --> 00:11:49,340
Empowerment Project, which gives
these forward-looking infrared

241
00:11:49,340 --> 00:11:53,550
cameras to communities
that want to monitor

242
00:11:53,550 --> 00:11:56,730
air balloons from local
operations such as fracking.

243
00:11:56,730 --> 00:11:59,670
And then one I just learned
about is Safecast, which

244
00:11:59,670 --> 00:12:03,740
is in response to the Fukushima
nuclear meltdown, which

245
00:12:03,740 --> 00:12:06,570
is getting communities
scientific tools for monitoring

246
00:12:06,570 --> 00:12:09,000
radiation contamination
in their communities.

247
00:12:09,000 --> 00:12:12,760
So with that, I will
turn it over to Jeff

248
00:12:12,760 --> 00:12:17,070
to tell you about some more
specific tools for community

249
00:12:17,070 --> 00:12:17,750
science.

250
00:12:17,750 --> 00:12:24,330
[APPLAUSE]

251
00:12:24,330 --> 00:12:28,180
JEFF WARREN: You know, as Britta
said-- thank you, Britta--

252
00:12:28,180 --> 00:12:30,607
I'm one of the
founders of Public Lab.

253
00:12:30,607 --> 00:12:31,690
There were seven founders.

254
00:12:31,690 --> 00:12:34,296
And I'll get into a
little bit about where

255
00:12:34,296 --> 00:12:35,170
Public Lab came from.

256
00:12:35,170 --> 00:12:40,062
But I really wanted
to talk about

257
00:12:40,062 --> 00:12:41,770
what makes Public Lab
different, and what

258
00:12:41,770 --> 00:12:43,660
that has to do with
some of the topics

259
00:12:43,660 --> 00:12:47,690
that we're going to dive
into in this course.

260
00:12:47,690 --> 00:12:49,810
I titled the talk
Renegotiating Expertise.

261
00:12:49,810 --> 00:12:52,510
Because I think there's
kind of this moment

262
00:12:52,510 --> 00:12:55,270
we're in now where
people are beginning

263
00:12:55,270 --> 00:13:00,520
to be more aware of the
mechanisms of expertise

264
00:13:00,520 --> 00:13:05,570
and where they are working and
where they need improvement.

265
00:13:05,570 --> 00:13:09,180
And so I had some thoughts
on this, and these are--

266
00:13:09,180 --> 00:13:10,390
yeah, they're preliminary.

267
00:13:10,390 --> 00:13:12,460
So I'm eager for the
discussion portion

268
00:13:12,460 --> 00:13:15,930
of the talk to just sort of dive
into some of these questions.

269
00:13:15,930 --> 00:13:21,970
And also, they're not
necessarily right.

270
00:13:21,970 --> 00:13:23,470
But I'm going to
put them out there.

271
00:13:23,470 --> 00:13:26,540
And I'm eager to
hear your thoughts.

272
00:13:26,540 --> 00:13:30,640
So Public Lab does what
we call community science.

273
00:13:30,640 --> 00:13:36,080
And this involves supporting
community knowledge production,

274
00:13:36,080 --> 00:13:38,680
which means creating
bridges and shared spaces

275
00:13:38,680 --> 00:13:42,500
between formal expertise
and community needs.

276
00:13:42,500 --> 00:13:44,770
So in the picture
above, you can see

277
00:13:44,770 --> 00:13:47,080
a group that is on the Gowanus
Canal in Brooklyn, which

278
00:13:47,080 --> 00:13:48,880
is a Superfund site.

279
00:13:48,880 --> 00:13:52,030
It's heavily contaminated
with polyaromatic hydrocarbons

280
00:13:52,030 --> 00:13:53,770
and raw sewage.

281
00:13:53,770 --> 00:13:56,500
I think somewhere in the
order of 300 million gallons

282
00:13:56,500 --> 00:13:58,690
of raw sewage go into
the canal every year.

283
00:13:58,690 --> 00:14:01,090
And that's actually
part of how the New York

284
00:14:01,090 --> 00:14:02,080
sanitary system works.

285
00:14:04,780 --> 00:14:08,790
I don't think there are any
current plans to change that.

286
00:14:08,790 --> 00:14:11,200
That's it, functioning properly.

287
00:14:11,200 --> 00:14:14,770
But this picture is actually
the day after Hurricane Sandy.

288
00:14:14,770 --> 00:14:18,250
And folks in the
Brooklyn sort of chapter,

289
00:14:18,250 --> 00:14:20,970
or sort of local
group of Public Lab--

290
00:14:20,970 --> 00:14:23,230
Public Lab's an open
community, so anyone can join--

291
00:14:23,230 --> 00:14:25,870
went out in canoes, as they had
done many times before in part

292
00:14:25,870 --> 00:14:27,880
of their monitoring
of the cleanup,

293
00:14:27,880 --> 00:14:31,150
and took a bunch of remarkable
images of lots of stuff

294
00:14:31,150 --> 00:14:33,072
having been washed
into the canal as well

295
00:14:33,072 --> 00:14:34,780
as also some of the
infrastructure that's

296
00:14:34,780 --> 00:14:37,030
been put in place,
like these booms,

297
00:14:37,030 --> 00:14:39,640
to prevent pollution
from entering the canal.

298
00:14:39,640 --> 00:14:41,890
This is next to what
is now a Whole Foods.

299
00:14:41,890 --> 00:14:44,980
So this boom was actually
added in response

300
00:14:44,980 --> 00:14:48,730
to previous monitoring by that
group of the construction site.

301
00:14:51,370 --> 00:14:54,179
And I think folks
sometimes misunderstand

302
00:14:54,179 --> 00:14:54,970
what Public Lab is.

303
00:14:54,970 --> 00:14:57,220
Like a friend once
told me that it's great

304
00:14:57,220 --> 00:14:59,890
that we're helping the
public to understand science.

305
00:14:59,890 --> 00:15:01,940
And I think that is part of it.

306
00:15:01,940 --> 00:15:05,410
But that's really not the core
function or the core purpose

307
00:15:05,410 --> 00:15:06,760
of Public Lab.

308
00:15:06,760 --> 00:15:09,760
I think Public Lab is
different because we

309
00:15:09,760 --> 00:15:14,500
focus a lot on the
question of who above what.

310
00:15:14,500 --> 00:15:17,440
We're not necessarily
teaching people about science

311
00:15:17,440 --> 00:15:18,120
exclusively.

312
00:15:18,120 --> 00:15:20,620
We're trying to negotiate a new
relationship between science

313
00:15:20,620 --> 00:15:24,100
practice and the public, perhaps
a more equitable or mutually

314
00:15:24,100 --> 00:15:25,990
beneficial relationship.

315
00:15:25,990 --> 00:15:31,990
And that involves a lot
of obviously big issues.

316
00:15:31,990 --> 00:15:34,510
But I think just
through our work,

317
00:15:34,510 --> 00:15:37,460
and in trying to support
communities facing pollution,

318
00:15:37,460 --> 00:15:40,310
the question of how
our expertise works,

319
00:15:40,310 --> 00:15:42,700
how it functions,
comes up a great deal.

320
00:15:42,700 --> 00:15:45,664
And that's something we've been
sort of receptive to coming

321
00:15:45,664 --> 00:15:47,080
from communities
we've worked with

322
00:15:47,080 --> 00:15:49,280
and tried to understand deeply.

323
00:15:49,280 --> 00:15:52,570
These questions like
who builds knowledge?

324
00:15:52,570 --> 00:15:54,160
Who is it for?

325
00:15:54,160 --> 00:15:55,750
Who asks the questions?

326
00:15:55,750 --> 00:15:58,310
And who understands the answers?

327
00:15:58,310 --> 00:16:00,250
These are pretty deep questions.

328
00:16:00,250 --> 00:16:02,800
And I doubt we'd be able to
unwrap them all in this session

329
00:16:02,800 --> 00:16:03,300
today.

330
00:16:03,300 --> 00:16:06,220
But they're pretty fundamental
to some of the issues

331
00:16:06,220 --> 00:16:09,200
that we're going to
talk about later.

332
00:16:09,200 --> 00:16:11,800
I think what's key
is that we're really

333
00:16:11,800 --> 00:16:14,860
trying not only to seek to make
science findings accessible--

334
00:16:14,860 --> 00:16:16,780
I think that is
important-- but also,

335
00:16:16,780 --> 00:16:21,520
its methods, its tools, its
structure of participation,

336
00:16:21,520 --> 00:16:23,920
and the depth of
participation that people

337
00:16:23,920 --> 00:16:27,820
have in how science functions.

338
00:16:27,820 --> 00:16:30,340
This means both making
more accessible on ramps

339
00:16:30,340 --> 00:16:32,690
to make it--

340
00:16:32,690 --> 00:16:34,510
I won't necessarily say easier--

341
00:16:34,510 --> 00:16:37,060
but I think accessible is
a slightly different shade

342
00:16:37,060 --> 00:16:38,200
than easier.

343
00:16:38,200 --> 00:16:39,940
But it also means
challenging what's

344
00:16:39,940 --> 00:16:44,050
possible in science practice
by leveraging things

345
00:16:44,050 --> 00:16:46,450
like peer production,
open source

346
00:16:46,450 --> 00:16:49,540
as Britta mentioned, and things
like the maker community, which

347
00:16:49,540 --> 00:16:53,980
I think is changing our
understanding of what

348
00:16:53,980 --> 00:17:00,640
technology development can
do and how it can function.

349
00:17:00,640 --> 00:17:04,119
So just for some
concretes, you may

350
00:17:04,119 --> 00:17:06,740
have heard of Public Lab's
balloon mapping project.

351
00:17:06,740 --> 00:17:08,819
This is our oldest project.

352
00:17:08,819 --> 00:17:11,319
And we developed this technique
with a number of communities

353
00:17:11,319 --> 00:17:14,457
in the Gulf Coast to
monitor the BP oil spill,

354
00:17:14,457 --> 00:17:16,540
to take aerial photographs
in very high resolution

355
00:17:16,540 --> 00:17:21,560
of spill-affected sites before,
during, and after the spill.

356
00:17:21,560 --> 00:17:24,937
And basically, you just
attach a camera to a balloon.

357
00:17:24,937 --> 00:17:26,520
I mean, it's easy
to say it like that.

358
00:17:26,520 --> 00:17:27,950
But there's a lot of
little things about it--

359
00:17:27,950 --> 00:17:30,366
in how you connect things up
with string and rubber bands,

360
00:17:30,366 --> 00:17:32,750
in how you archive the
data and interpret it.

361
00:17:32,750 --> 00:17:37,774
And it really is this whole
embodied research project

362
00:17:37,774 --> 00:17:39,440
in a community that
is primarily made up

363
00:17:39,440 --> 00:17:42,530
of nonscientists or
nonprofessional scientists,

364
00:17:42,530 --> 00:17:43,342
we'll say.

365
00:17:43,342 --> 00:17:44,300
This is a good example.

366
00:17:44,300 --> 00:17:46,490
There's a group, two
people in a canoe,

367
00:17:46,490 --> 00:17:48,890
again on the Gowanus
Canal, this time

368
00:17:48,890 --> 00:17:50,576
in the middle of the winter.

369
00:17:50,576 --> 00:17:51,950
In the box-- and
it's hard to see

370
00:17:51,950 --> 00:17:53,690
with the color on the
projector, but this

371
00:17:53,690 --> 00:17:56,830
is a large plume of raw
sewage that's on the Canal.

372
00:17:56,830 --> 00:17:58,580
As I mentioned, this
happens all the time.

373
00:17:58,580 --> 00:18:00,038
So people who live
there are really

374
00:18:00,038 --> 00:18:03,010
familiar with when and
where it happens, how often,

375
00:18:03,010 --> 00:18:05,010
and what volumes.

376
00:18:05,010 --> 00:18:06,886
And they've structured
their research project

377
00:18:06,886 --> 00:18:08,968
based on their understanding,
their deep knowledge

378
00:18:08,968 --> 00:18:10,010
of this particular site.

379
00:18:10,010 --> 00:18:11,820
And one thing that
they discovered-- oh,

380
00:18:11,820 --> 00:18:14,040
it's not in this picture--

381
00:18:14,040 --> 00:18:16,850
later slide-- teaser.

382
00:18:16,850 --> 00:18:20,330
So we also focus on
making your own tools.

383
00:18:20,330 --> 00:18:23,300
Now I wouldn't say this is a
prerequisite or an absolutely

384
00:18:23,300 --> 00:18:24,770
necessary portion of our work.

385
00:18:24,770 --> 00:18:28,320
But it has been a really
important part of it.

386
00:18:28,320 --> 00:18:31,520
We've managed to engage
pretty large numbers of people

387
00:18:31,520 --> 00:18:36,710
in constructing tools
and experimental setups.

388
00:18:36,710 --> 00:18:39,830
For example, paper
craft spectrometers--

389
00:18:39,830 --> 00:18:42,980
optical range spectrometers
built around a webcam,

390
00:18:42,980 --> 00:18:47,180
and doing comparative work using
different sample preparations,

391
00:18:47,180 --> 00:18:51,080
and in some cases, ultraviolet
light to induce fluorescence.

392
00:18:51,080 --> 00:18:54,770
And so this is just a graph of
how many people have actually

393
00:18:54,770 --> 00:18:57,110
built and uploaded data
using a spectrometer

394
00:18:57,110 --> 00:18:58,820
that they built themselves.

395
00:18:58,820 --> 00:19:00,870
This graph is, I think,
the past 52 weeks.

396
00:19:00,870 --> 00:19:03,140
But overall, almost 10,000
people, which I think

397
00:19:03,140 --> 00:19:09,810
is an interesting
project for us.

398
00:19:09,810 --> 00:19:12,380
So all in all, people
come to PublicLab.org,

399
00:19:12,380 --> 00:19:15,090
they post their work to
share it with others,

400
00:19:15,090 --> 00:19:17,660
but also to ask for help.

401
00:19:17,660 --> 00:19:19,200
These people might
be scientists.

402
00:19:19,200 --> 00:19:20,510
Many of them are.

403
00:19:20,510 --> 00:19:23,544
But they're just as likely to
be educators, to be hobbyists.

404
00:19:23,544 --> 00:19:25,460
And the group we're most
interested in serving

405
00:19:25,460 --> 00:19:27,980
are those community
groups who experience

406
00:19:27,980 --> 00:19:32,240
environmental
problems firsthand.

407
00:19:32,240 --> 00:19:34,090
So I guess it's a big question.

408
00:19:34,090 --> 00:19:37,120
Why do it yourself?

409
00:19:37,120 --> 00:19:40,570
Why go beyond simply
dissemination of science

410
00:19:40,570 --> 00:19:41,705
knowledge to the public?

411
00:19:41,705 --> 00:19:44,080
And I think there's a bunch
of different reasons to this.

412
00:19:44,080 --> 00:19:45,970
But this is sort of the crux.

413
00:19:45,970 --> 00:19:47,826
In some ways, it's
because experts, I think,

414
00:19:47,826 --> 00:19:50,200
often have a pretty narrow
conception of where the public

415
00:19:50,200 --> 00:19:52,717
could become involved.

416
00:19:52,717 --> 00:19:54,550
For example, public
dissemination of science

417
00:19:54,550 --> 00:19:56,292
is part of most federal grants.

418
00:19:56,292 --> 00:19:58,000
There's some portion
of it where you have

419
00:19:58,000 --> 00:19:59,600
to communicate your findings.

420
00:19:59,600 --> 00:20:01,300
This is an area that
people, I think,

421
00:20:01,300 --> 00:20:03,010
are making good progress on.

422
00:20:03,010 --> 00:20:07,840
But involvement in the
design of experiments,

423
00:20:07,840 --> 00:20:10,550
in the formulation of
research questions,

424
00:20:10,550 --> 00:20:13,270
in the interpretation and
application of those findings

425
00:20:13,270 --> 00:20:15,940
to real world scenarios--
those are often

426
00:20:15,940 --> 00:20:18,100
considered outside
the scope, sometimes

427
00:20:18,100 --> 00:20:21,310
even of science practitioners,
but certainly outside the scope

428
00:20:21,310 --> 00:20:23,800
of a partnership with
a community group

429
00:20:23,800 --> 00:20:27,410
facing a challenge or a problem.

430
00:20:27,410 --> 00:20:30,190
Of course, I think with
the do it yourself kits

431
00:20:30,190 --> 00:20:33,250
and so forth, the cost barrier
is definitely a factor for us.

432
00:20:33,250 --> 00:20:35,890
It's hard to get
more people involved

433
00:20:35,890 --> 00:20:39,700
in performing science, doing
science, and understanding

434
00:20:39,700 --> 00:20:40,240
science--

435
00:20:40,240 --> 00:20:43,125
any of those-- unless there's
cheaper instrumentation.

436
00:20:43,125 --> 00:20:45,250
This is not true for all
fields, but it's certainly

437
00:20:45,250 --> 00:20:47,080
true for some.

438
00:20:47,080 --> 00:20:49,851
But I think really to answer
this question more thoroughly,

439
00:20:49,851 --> 00:20:51,850
I think we need to take
a few steps back and try

440
00:20:51,850 --> 00:20:55,189
to better understand how
shared knowledge is produced--

441
00:20:55,189 --> 00:20:57,730
the key word there being shared
knowledge, not just knowledge

442
00:20:57,730 --> 00:21:00,550
that's held by
scientists, but knowledge

443
00:21:00,550 --> 00:21:03,730
that is commonly held,
which I hope is the goal--

444
00:21:03,730 --> 00:21:06,820
and how expertise works.

445
00:21:06,820 --> 00:21:08,770
So a depressing slide, I know.

446
00:21:08,770 --> 00:21:12,400
But this is The New York
Times' up shots sort

447
00:21:12,400 --> 00:21:14,530
of meta poll of polls.

448
00:21:14,530 --> 00:21:16,960
So they're listing all of the
projections of the outcome

449
00:21:16,960 --> 00:21:19,090
of the November 8th election.

450
00:21:19,090 --> 00:21:25,120
Obviously, the data
didn't fit the outcome.

451
00:21:25,120 --> 00:21:27,700
But I do think it's
an interesting case.

452
00:21:27,700 --> 00:21:32,760
In part because it
has a lot to do with--

453
00:21:32,760 --> 00:21:35,600
in my eyes, it has
a lot to do with how

454
00:21:35,600 --> 00:21:38,580
expertise is represented today
and how it's communicated.

455
00:21:38,580 --> 00:21:41,060
How are our projections
or predictions made?

456
00:21:41,060 --> 00:21:44,840
This isn't representative of
that many forms of science,

457
00:21:44,840 --> 00:21:47,410
but I think it's a
relevant data point.

458
00:21:47,410 --> 00:21:50,360
And specifically, why
and when people trust

459
00:21:50,360 --> 00:21:52,410
these kinds of projections--

460
00:21:52,410 --> 00:21:56,180
and I'm not necessarily
calling these wrong.

461
00:21:56,180 --> 00:22:00,050
I think there's
something really--

462
00:22:00,050 --> 00:22:02,570
I'll get into this
in a moment, sorry.

463
00:22:02,570 --> 00:22:04,730
So data and its
interpretation increasingly

464
00:22:04,730 --> 00:22:06,852
drives decision
making in our society.

465
00:22:06,852 --> 00:22:08,810
And this is something
that happens a little bit

466
00:22:08,810 --> 00:22:10,518
outside of the scope
of what we typically

467
00:22:10,518 --> 00:22:12,470
understand as science
practice, but it

468
00:22:12,470 --> 00:22:15,200
is an important ramification.

469
00:22:15,200 --> 00:22:17,270
And I just want to suggest this.

470
00:22:17,270 --> 00:22:21,230
I think you can see how this
might become a problem, not

471
00:22:21,230 --> 00:22:25,880
in itself, but where it
displaces, where it happens

472
00:22:25,880 --> 00:22:32,360
at the cost of a more discursive
mode of debate in a democracy.

473
00:22:32,360 --> 00:22:36,470
And I really am not saying
that we should use democracy

474
00:22:36,470 --> 00:22:37,670
to do science.

475
00:22:37,670 --> 00:22:40,520
What I'm saying is that there is
a relationship between the two

476
00:22:40,520 --> 00:22:42,740
that we need to
better understand.

477
00:22:42,740 --> 00:22:48,320
And I think this could present
challenges not only because

478
00:22:48,320 --> 00:22:49,310
of possible biases--

479
00:22:49,310 --> 00:22:52,160
I mean, there's clear
problems with science

480
00:22:52,160 --> 00:22:55,220
being paid for in
certain spheres as well

481
00:22:55,220 --> 00:22:57,770
as ideological issues
and their relationship

482
00:22:57,770 --> 00:23:02,930
with science in Congress
as was mentioned earlier.

483
00:23:02,930 --> 00:23:05,540
But I think also it has to
do with some of the areas

484
00:23:05,540 --> 00:23:07,790
that Public Lab is
focusing on, which

485
00:23:07,790 --> 00:23:10,400
may be the most objective
parts of science--

486
00:23:10,400 --> 00:23:15,230
the selection of problems
and questions to pursue,

487
00:23:15,230 --> 00:23:17,760
and of course, the application
of science is findings.

488
00:23:17,760 --> 00:23:20,564
These are sometimes
outside the scope, please.

489
00:23:20,564 --> 00:23:22,273
AUDIENCE: I don't want
to derail us but--

490
00:23:22,273 --> 00:23:23,272
JEFF WARREN: No, please.

491
00:23:23,272 --> 00:23:25,544
AUDIENCE: Did you say that
data and its interpretation

492
00:23:25,544 --> 00:23:29,968
increasingly drives decision
making in our society?

493
00:23:29,968 --> 00:23:35,944
I think there's a common
belief that, sadly, opposite

494
00:23:35,944 --> 00:23:36,940
is now true.

495
00:23:36,940 --> 00:23:38,580
JEFF WARREN: Oh, timescales--

496
00:23:38,580 --> 00:23:40,440
I mean, the last
200 or 300 years.

497
00:23:40,440 --> 00:23:41,505
[LAUGHTER]

498
00:23:41,505 --> 00:23:42,296
JEFF WARREN: Sorry.

499
00:23:42,296 --> 00:23:43,549
Very-- yeah.

500
00:23:43,549 --> 00:23:44,507
AUDIENCE: But there's--

501
00:23:44,507 --> 00:23:45,965
I mean, one of the
reasons I'm here

502
00:23:45,965 --> 00:23:48,536
is because I have great
concern that we've

503
00:23:48,536 --> 00:23:53,400
lost this notion of truth and
falsehood in public discourse.

504
00:23:53,400 --> 00:23:55,230
JEFF WARREN: Absolutely.

505
00:23:55,230 --> 00:23:57,395
I desperately want
to talk about that.

506
00:23:57,395 --> 00:24:00,171
I'm being a little round
about, so I apologize.

507
00:24:00,171 --> 00:24:00,670
Yeah.

508
00:24:00,670 --> 00:24:02,294
So I mean, as you
said, it's concerning

509
00:24:02,294 --> 00:24:03,480
when people lose trust.

510
00:24:03,480 --> 00:24:06,240
This is a graph of the 48
hours surrounding the election,

511
00:24:06,240 --> 00:24:10,260
and the projections of
the election's outcome.

512
00:24:10,260 --> 00:24:13,300
And it's a really depressing
graph to look at for me.

513
00:24:13,300 --> 00:24:14,620
I found it really interesting.

514
00:24:14,620 --> 00:24:16,257
This is The New
York Times upshot.

515
00:24:16,257 --> 00:24:18,090
But I found it very
interesting the language

516
00:24:18,090 --> 00:24:21,360
that fivethirtyeight.com
used, and a lot

517
00:24:21,360 --> 00:24:23,610
of other data driven
analysts are increasingly

518
00:24:23,610 --> 00:24:28,740
using, to tune how they
communicate certainty.

519
00:24:28,740 --> 00:24:31,380
And this is something
where, in the days following

520
00:24:31,380 --> 00:24:35,130
the election, you heard some
analysts talking about, well,

521
00:24:35,130 --> 00:24:38,460
we said it was 70 something
percent or whatever.

522
00:24:38,460 --> 00:24:41,310
And that's not-- that's
actually not very certain.

523
00:24:41,310 --> 00:24:45,900
You know, there's something
hidden in that or something

524
00:24:45,900 --> 00:24:49,610
that needs to be unwrapped about
the communication of certainty.

525
00:24:49,610 --> 00:24:51,360
And I think it's
a real challenge.

526
00:24:51,360 --> 00:24:53,276
I don't know that people
have answers to this,

527
00:24:53,276 --> 00:24:55,530
but it's something
I'm interested in.

528
00:24:55,530 --> 00:24:59,160
I know they sometimes would
say things, like, more probable

529
00:24:59,160 --> 00:25:00,540
than making a field goal.

530
00:25:00,540 --> 00:25:01,800
That didn't help me, because
I don't know anything

531
00:25:01,800 --> 00:25:02,425
about football.

532
00:25:02,425 --> 00:25:04,860
But they're trying
to communicate

533
00:25:04,860 --> 00:25:06,259
what the graphs mean.

534
00:25:06,259 --> 00:25:08,550
You know, it's easy to just
look and see all blue dots.

535
00:25:08,550 --> 00:25:10,950
But it's a very different
thing to understand

536
00:25:10,950 --> 00:25:14,970
what the ramifications are
for how reality plays out.

537
00:25:14,970 --> 00:25:16,200
And then, of course, yeah--

538
00:25:16,200 --> 00:25:17,780
this is the big thing.

539
00:25:17,780 --> 00:25:20,950
That sort of scenario plays out
on a lot of other narratives,

540
00:25:20,950 --> 00:25:21,450
right?

541
00:25:21,450 --> 00:25:25,612
Adjacent displays and
communications of data--

542
00:25:25,612 --> 00:25:27,570
many of you may have seen
this Bloomberg thing.

543
00:25:27,570 --> 00:25:31,560
It's very interactive,
extremely data dense.

544
00:25:31,560 --> 00:25:34,350
Like, there's so many
studies and so many data

545
00:25:34,350 --> 00:25:37,560
points that have been summarized
and metasummarized to create

546
00:25:37,560 --> 00:25:40,200
something which communicates,
I think, very effectively

547
00:25:40,200 --> 00:25:42,810
about warming trends.

548
00:25:42,810 --> 00:25:44,670
If you haven't used it,
go and play with it.

549
00:25:44,670 --> 00:25:47,320
It's really, really interesting.

550
00:25:47,320 --> 00:25:53,460
And so, you sort of have to
ask why isn't it persuasive

551
00:25:53,460 --> 00:25:55,370
to everybody, you know?

552
00:25:55,370 --> 00:25:57,390
Because it's pretty good.

553
00:25:57,390 --> 00:26:00,690
And I think it's easy
to demonize experts

554
00:26:00,690 --> 00:26:03,870
for not being good communicators
when things go wrong.

555
00:26:03,870 --> 00:26:05,370
I think a lot of
complex knowledge

556
00:26:05,370 --> 00:26:08,440
is communicated in pretty rich
and pretty interactive ways.

557
00:26:08,440 --> 00:26:11,250
It's not just learn
this by rote, you know?

558
00:26:11,250 --> 00:26:14,130
AUDIENCE: Is that the name of
the tool, compare and contrast?

559
00:26:14,130 --> 00:26:18,250
JEFF WARREN: It's Bloomberg.com
What's Warming the World?

560
00:26:18,250 --> 00:26:20,970
And I think it's pretty great.

561
00:26:23,960 --> 00:26:26,270
So I think, yeah,
with such a wealth

562
00:26:26,270 --> 00:26:30,710
of data and such persuasive
communication of that data,

563
00:26:30,710 --> 00:26:32,440
with all the tools
we have today,

564
00:26:32,440 --> 00:26:37,370
what is-- or is-- something
broken about expertise?

565
00:26:37,370 --> 00:26:39,290
And I think that, in
some cases, people

566
00:26:39,290 --> 00:26:41,540
are very much afraid that
there is something broken,

567
00:26:41,540 --> 00:26:43,920
maybe not about all expertise,
but about some portions.

568
00:26:43,920 --> 00:26:45,004
You have a thought?

569
00:26:45,004 --> 00:26:47,022
AUDIENCE: --comment again.

570
00:26:47,022 --> 00:26:48,906
I don't think
expertise is broken.

571
00:26:48,906 --> 00:26:51,732
But I think there's a
feeling among experts

572
00:26:51,732 --> 00:26:56,420
that no one has the patience
or wherewithal to listen.

573
00:26:56,420 --> 00:26:57,170
JEFF WARREN: Yeah.

574
00:26:57,170 --> 00:26:59,950
AUDIENCE: And when you
add that to the conflation

575
00:26:59,950 --> 00:27:02,480
And obfuscation
of fact by people

576
00:27:02,480 --> 00:27:09,841
who really are pure
advocates, and kind of have--

577
00:27:09,841 --> 00:27:11,813
whatever the interest
may be, whether it's

578
00:27:11,813 --> 00:27:15,902
to show up to their party,
whether it's to curry favor

579
00:27:15,902 --> 00:27:17,415
for any position--

580
00:27:17,415 --> 00:27:18,290
JEFF WARREN: Funding.

581
00:27:18,290 --> 00:27:20,210
[LAUGHS] Yeah.

582
00:27:20,210 --> 00:27:23,012
AUDIENCE: --that seems
to have overwhelmed

583
00:27:23,012 --> 00:27:26,489
the voice of reason and
fact-- it's just my opinion.

584
00:27:26,489 --> 00:27:27,780
JEFF WARREN: I agree with that.

585
00:27:27,780 --> 00:27:30,860
I think the way that I'm
using the term expertise here

586
00:27:30,860 --> 00:27:37,190
is potentially trying to
understand it in a wider scope.

587
00:27:37,190 --> 00:27:39,290
Which is to say
expertise could be

588
00:27:39,290 --> 00:27:42,950
defined as a body of
knowledge which is contained

589
00:27:42,950 --> 00:27:45,440
or known or collected.

590
00:27:45,440 --> 00:27:48,220
But what I mean, broke--

591
00:27:48,220 --> 00:27:50,630
when I'm using
the term here, I'm

592
00:27:50,630 --> 00:27:52,880
talking about it as a set
of relationships as well.

593
00:27:52,880 --> 00:27:53,796
AUDIENCE: [INAUDIBLE].

594
00:27:53,796 --> 00:27:56,240
JEFF WARREN: Expertise-- yeah.

595
00:27:56,240 --> 00:28:00,130
And relationships with experts--

596
00:28:00,130 --> 00:28:03,090
and who are experts,
how are they identified,

597
00:28:03,090 --> 00:28:05,690
how do we trust what they say?

598
00:28:05,690 --> 00:28:08,270
How do we, if we are
experts, communicate

599
00:28:08,270 --> 00:28:10,760
in a trustful manner to people.

600
00:28:10,760 --> 00:28:12,110
There's a whole set of issues.

601
00:28:12,110 --> 00:28:12,752
AUDIENCE: The scientific
method was supposed

602
00:28:12,752 --> 00:28:13,877
to be the solution to that.

603
00:28:13,877 --> 00:28:15,970
But I think
everyone's just too--

604
00:28:15,970 --> 00:28:18,257
JEFF WARREN: Well, let's
not give up on it yet.

605
00:28:18,257 --> 00:28:20,340
AUDIENCE: But we can't
push a button [INAUDIBLE]..

606
00:28:20,340 --> 00:28:20,930
JEFF WARREN: Yeah.

607
00:28:20,930 --> 00:28:21,260
It's true.

608
00:28:21,260 --> 00:28:21,650
AUDIENCE: --wayside.

609
00:28:21,650 --> 00:28:22,040
Forgive me.

610
00:28:22,040 --> 00:28:22,820
I'll [INAUDIBLE].

611
00:28:22,820 --> 00:28:24,153
JEFF WARREN: No, no, no, please.

612
00:28:24,153 --> 00:28:25,130
And thank you, no.

613
00:28:25,130 --> 00:28:26,300
I'm glad you're engaging.

614
00:28:26,300 --> 00:28:28,670
Because it's something I
think about a great deal

615
00:28:28,670 --> 00:28:31,070
and have thought about,
especially recently.

616
00:28:31,070 --> 00:28:36,080
So Harry Collins is not
popular in all fields.

617
00:28:36,080 --> 00:28:40,610
But he does do a very close
and careful examination

618
00:28:40,610 --> 00:28:42,322
of different kinds of expertise.

619
00:28:42,322 --> 00:28:44,030
And I think it's a
very interesting thing

620
00:28:44,030 --> 00:28:46,432
to think about
what distinguishes

621
00:28:46,432 --> 00:28:47,640
different kinds of expertise.

622
00:28:47,640 --> 00:28:52,080
And one in particular that he
talks about is meta expertise.

623
00:28:52,080 --> 00:28:54,950
And it's the ability to
distinguish expertises,

624
00:28:54,950 --> 00:28:58,910
the ability to compare and to
choose an expert among several

625
00:28:58,910 --> 00:29:00,980
who are purporting
to be experts.

626
00:29:00,980 --> 00:29:03,650
And he says, you
know, and I think

627
00:29:03,650 --> 00:29:05,290
this is a persuasive
point of his,

628
00:29:05,290 --> 00:29:07,980
that it's a particularly
difficult one,

629
00:29:07,980 --> 00:29:11,340
but it's one which many people
are called upon to have.

630
00:29:11,340 --> 00:29:15,460
It's one that is often based
on long term reputation.

631
00:29:15,460 --> 00:29:18,740
It's based on, in some
cases, relationships,

632
00:29:18,740 --> 00:29:24,290
personal relationships,
and it can sometimes

633
00:29:24,290 --> 00:29:27,040
be affected by a different kind
of expertise, which he calls--

634
00:29:27,040 --> 00:29:29,540
I think he calls it downward
discrimination expertise, which

635
00:29:29,540 --> 00:29:35,990
is essentially the
ignoring of one expert

636
00:29:35,990 --> 00:29:38,450
because you perceive
a different expert

637
00:29:38,450 --> 00:29:41,120
to be of a greater authority.

638
00:29:41,120 --> 00:29:44,030
So I don't know about every
observation he's made.

639
00:29:44,030 --> 00:29:47,000
But I do appreciate the
taxonomy he's created

640
00:29:47,000 --> 00:29:48,650
and the attempt
to understand what

641
00:29:48,650 --> 00:29:51,950
are the mechanisms
that allow expertise

642
00:29:51,950 --> 00:29:52,955
to occur in our society.

643
00:29:55,500 --> 00:30:00,380
And I think the question for
Public Lab and for some of us

644
00:30:00,380 --> 00:30:03,350
is what do we do about
the widening gap?

645
00:30:03,350 --> 00:30:05,870
Because although
there is a tendency

646
00:30:05,870 --> 00:30:09,860
to think that the ability
to question expertise

647
00:30:09,860 --> 00:30:15,560
is driving a wedge,
the democratization

648
00:30:15,560 --> 00:30:21,180
of knowledge production is
an assault on expertise.

649
00:30:21,180 --> 00:30:23,570
But I actually think
maybe it's like there's

650
00:30:23,570 --> 00:30:25,046
a few other dimensions to that.

651
00:30:25,046 --> 00:30:26,420
And although I'm
not going to say

652
00:30:26,420 --> 00:30:29,607
that's not true in
some ways, I think

653
00:30:29,607 --> 00:30:31,940
that there are other ways we
can think about it as well.

654
00:30:31,940 --> 00:30:34,190
So what Public
Lab tries to do is

655
00:30:34,190 --> 00:30:35,760
to focus on problem definition.

656
00:30:35,760 --> 00:30:38,150
So this is the earliest
stage in the sort of sequence

657
00:30:38,150 --> 00:30:41,300
that might encompass
scientific inquiry.

658
00:30:41,300 --> 00:30:43,510
And staying close to
real world problems--

659
00:30:43,510 --> 00:30:47,900
Britta mentioned
communicating with people

660
00:30:47,900 --> 00:30:51,530
as early as possible, building
products in collaboration

661
00:30:51,530 --> 00:30:54,800
with groups that face problems,
engaging them in the problem

662
00:30:54,800 --> 00:30:57,950
selection in the formulation of
questions, and in some cases,

663
00:30:57,950 --> 00:31:00,440
in research design.

664
00:31:00,440 --> 00:31:05,060
There are specific
expertises and capacities

665
00:31:05,060 --> 00:31:06,860
to formulate an experiment.

666
00:31:06,860 --> 00:31:10,070
But those may be, in
some cases, the places

667
00:31:10,070 --> 00:31:12,770
where it's most likely that
you would learn something

668
00:31:12,770 --> 00:31:14,690
from a group that has
deep understanding

669
00:31:14,690 --> 00:31:17,480
of a particular problem,
first hand knowledge.

670
00:31:17,480 --> 00:31:21,720
So I'm really interested
in that potential, and in,

671
00:31:21,720 --> 00:31:24,900
really, collaborating as
much in asking questions

672
00:31:24,900 --> 00:31:26,580
as in answering them.

673
00:31:26,580 --> 00:31:29,719
But what are the
sources of mistrust?

674
00:31:29,719 --> 00:31:31,260
I think there are
many, but I'm going

675
00:31:31,260 --> 00:31:33,130
to try to dig into
a few of them.

676
00:31:33,130 --> 00:31:36,720
I think one of them is limited
ability to evaluate or test.

677
00:31:36,720 --> 00:31:39,279
So this affects,
perhaps, climate science

678
00:31:39,279 --> 00:31:41,070
more than almost any
other type of science,

679
00:31:41,070 --> 00:31:44,530
although I guess the
LHC is another example.

680
00:31:44,530 --> 00:31:52,100
But how can people
evaluate empirically

681
00:31:52,100 --> 00:31:55,740
what climate science is saying?

682
00:31:55,740 --> 00:31:56,820
It's not very possible.

683
00:31:56,820 --> 00:31:59,970
You can observationally
do it in some cases.

684
00:31:59,970 --> 00:32:02,670
But understanding that in
a context is difficult.

685
00:32:02,670 --> 00:32:05,757
And I mention this
one mainly because it

686
00:32:05,757 --> 00:32:07,590
underlies a lot of what
we do at Public Lab.

687
00:32:07,590 --> 00:32:09,839
Public Lab's not primarily
interested or not primarily

688
00:32:09,839 --> 00:32:11,560
engaged in climate research.

689
00:32:11,560 --> 00:32:14,580
We're primarily engaged
in pollution research.

690
00:32:14,580 --> 00:32:17,700
But we take it as
a powerful thing

691
00:32:17,700 --> 00:32:19,740
to be able to empirically
verify something.

692
00:32:19,740 --> 00:32:21,406
And that's why we're
focused on low cost

693
00:32:21,406 --> 00:32:25,240
tools and democratization
of the technologies.

694
00:32:25,240 --> 00:32:27,240
But this is linked in
climate to the following--

695
00:32:27,240 --> 00:32:31,680
when processes are too big to
see feedback loop personally.

696
00:32:31,680 --> 00:32:33,970
When you go and
you do something,

697
00:32:33,970 --> 00:32:36,480
it's one of the
longest feedback loops

698
00:32:36,480 --> 00:32:40,457
that we are confronted
with in research.

699
00:32:40,457 --> 00:32:41,290
But yeah, oh, sorry.

700
00:32:41,290 --> 00:32:42,331
I already mentioned this.

701
00:32:42,331 --> 00:32:44,790
But basically, we do
focus on testability

702
00:32:44,790 --> 00:32:48,780
at Public Lab on the question--
can you also build this?

703
00:32:48,780 --> 00:32:50,470
Do you also get the same result?

704
00:32:50,470 --> 00:32:53,400
And this is a picture of one
of our spectrometer prototypes.

705
00:32:53,400 --> 00:32:59,100
Someone literally, like, tweeted
a picture and a link to plans.

706
00:32:59,100 --> 00:33:02,790
And someone else built one
and tweeted that they had,

707
00:33:02,790 --> 00:33:04,440
as close as possible,
reproduced this.

708
00:33:04,440 --> 00:33:07,380
Harry Collins talks a lot
about the infinite regress.

709
00:33:10,650 --> 00:33:12,130
What's the-- anyway, whatever--

710
00:33:12,130 --> 00:33:13,290
I'll get back to it later.

711
00:33:13,290 --> 00:33:13,956
AUDIENCE: Sorry.

712
00:33:13,956 --> 00:33:15,180
Is that name Harry Collins?

713
00:33:15,180 --> 00:33:15,870
JEFF WARREN: Harry Collins?

714
00:33:15,870 --> 00:33:16,230
Yeah.

715
00:33:16,230 --> 00:33:16,600
Yeah.

716
00:33:16,600 --> 00:33:18,474
I'll talk a little more
about him later, too.

717
00:33:18,474 --> 00:33:22,060
I should probably start
moving a little faster.

718
00:33:22,060 --> 00:33:23,790
A couple of others--
environmental issues

719
00:33:23,790 --> 00:33:24,660
affect someone else.

720
00:33:24,660 --> 00:33:26,970
I think this is one where
it's not just about--

721
00:33:32,005 --> 00:33:33,630
I think there's many
sides to that one.

722
00:33:33,630 --> 00:33:34,770
It's a tough one.

723
00:33:34,770 --> 00:33:36,870
But I think
increasingly people are

724
00:33:36,870 --> 00:33:38,700
understating
environmental problems

725
00:33:38,700 --> 00:33:41,880
as ones which affect people.

726
00:33:41,880 --> 00:33:43,957
That's a major step forward.

727
00:33:43,957 --> 00:33:45,540
I think the environmental
movement had

728
00:33:45,540 --> 00:33:48,860
been very closely associated
with conservation,

729
00:33:48,860 --> 00:33:50,710
and I think
conservation is great.

730
00:33:50,710 --> 00:33:53,760
But I do think it is
important for people

731
00:33:53,760 --> 00:33:56,850
to recognize that there
are justice issues at stake

732
00:33:56,850 --> 00:33:58,650
with communities that
are facing pollution

733
00:33:58,650 --> 00:34:01,950
and don't have a way to
respond to it, or sometimes,

734
00:34:01,950 --> 00:34:04,650
even, to understand it.

735
00:34:04,650 --> 00:34:07,856
But increasingly, pollution
is affecting everybody,

736
00:34:07,856 --> 00:34:09,480
and the climate is
affecting everybody.

737
00:34:09,480 --> 00:34:12,989
And I think this is an
opportunity for common cause.

738
00:34:12,989 --> 00:34:16,560
The other one is one that
affects poor communities

739
00:34:16,560 --> 00:34:18,510
perhaps more than others.

740
00:34:18,510 --> 00:34:23,370
And that's that they
have very limited ability

741
00:34:23,370 --> 00:34:27,060
to respond, and in many
cases, to question.

742
00:34:27,060 --> 00:34:29,340
And therefore, they
already have the experience

743
00:34:29,340 --> 00:34:32,639
of having been lied to and hurt
by industries, and sometimes

744
00:34:32,639 --> 00:34:35,850
by the scientists that
those industries employ.

745
00:34:35,850 --> 00:34:38,699
I know this is a difficult
one for all of us.

746
00:34:38,699 --> 00:34:41,670
But I think that if
you talk to communities

747
00:34:41,670 --> 00:34:44,175
who face pollution
firsthand, this

748
00:34:44,175 --> 00:34:45,750
is a very common experience.

749
00:34:45,750 --> 00:34:47,219
And it's unfortunate.

750
00:34:47,219 --> 00:34:49,050
Harry Collins actually
mentions that he

751
00:34:49,050 --> 00:34:53,120
feels that the fact that we are
upset when we see that there

752
00:34:53,120 --> 00:34:55,199
has been an exchange
of money which

753
00:34:55,199 --> 00:34:58,620
has influenced the findings
of a research project--

754
00:34:58,620 --> 00:35:02,160
we are upset because we
know that that's wrong.

755
00:35:02,160 --> 00:35:04,500
Because there's something
essential and fundamental

756
00:35:04,500 --> 00:35:08,370
about science which is being
broken when that happens--

757
00:35:08,370 --> 00:35:11,170
so complex, but interesting.

758
00:35:11,170 --> 00:35:14,640
So OK, so what can I do as a
scientist or a technologist?

759
00:35:14,640 --> 00:35:16,980
These aren't the same
thing, but the question

760
00:35:16,980 --> 00:35:19,650
might be relevant to both.

761
00:35:19,650 --> 00:35:22,360
Tough-- we're going to
try to get into this.

762
00:35:22,360 --> 00:35:25,740
I have some ideas,
four broad ideas.

763
00:35:25,740 --> 00:35:31,200
This is an article which
I found very interesting.

764
00:35:31,200 --> 00:35:33,930
It recaps a lot of ideas which
Public Lab has championed

765
00:35:33,930 --> 00:35:35,160
over the last six years.

766
00:35:38,040 --> 00:35:41,790
But it also shows
how difficult it

767
00:35:41,790 --> 00:35:43,830
is to have an
articulate conversation

768
00:35:43,830 --> 00:35:48,060
about these things,
because it is very complex.

769
00:35:48,060 --> 00:35:51,469
The subtitle is maybe
more important--

770
00:35:51,469 --> 00:35:53,010
experts need to
listen to the public.

771
00:35:53,010 --> 00:35:54,840
I went into the
comments, all right?

772
00:35:54,840 --> 00:35:58,050
I know that's not always
a productive place to find

773
00:35:58,050 --> 00:35:58,550
things.

774
00:35:58,550 --> 00:36:01,230
But for once, I
actually thought it

775
00:36:01,230 --> 00:36:04,900
was really, really educational.

776
00:36:04,900 --> 00:36:05,610
Yeah.

777
00:36:05,610 --> 00:36:07,110
So I'll just read it.

778
00:36:07,110 --> 00:36:10,132
"No, scientists need to do
science, not run a PR campaign

779
00:36:10,132 --> 00:36:11,340
and become marketing experts.

780
00:36:11,340 --> 00:36:12,631
They aren't trained to do that.

781
00:36:12,631 --> 00:36:14,200
And it's silly to
expect them to.

782
00:36:14,200 --> 00:36:16,050
What the rest of us
need to do is invest in

783
00:36:16,050 --> 00:36:17,290
the school system"--

784
00:36:17,290 --> 00:36:19,290
well, that's interesting--
what the rest of us--

785
00:36:19,290 --> 00:36:22,444
so this gentleman does not
identify as a scientist--

786
00:36:22,444 --> 00:36:24,860
--"is invest in the school
system that we've basically let

787
00:36:24,860 --> 00:36:27,110
rot in many places so that
our citizenry has knowledge

788
00:36:27,110 --> 00:36:29,444
of the scientific method
beyond the third grade level.

789
00:36:29,444 --> 00:36:30,860
If they understand
what science is

790
00:36:30,860 --> 00:36:32,290
and what it has
accomplished, then they'll

791
00:36:32,290 --> 00:36:33,224
appreciate its value.

792
00:36:33,224 --> 00:36:34,640
It's the job of
the public schools

793
00:36:34,640 --> 00:36:38,030
to teach this, not
career scientists."

794
00:36:38,030 --> 00:36:41,090
There's almost too much in that
statement for me to peel apart.

795
00:36:41,090 --> 00:36:44,309
But we'll try to get to some
of these questions as we go.

796
00:36:44,309 --> 00:36:46,850
And I'm not putting it up here
because I think this person is

797
00:36:46,850 --> 00:36:47,614
completely wrong.

798
00:36:47,614 --> 00:36:50,030
I'm putting it up here because
it's a series of statements

799
00:36:50,030 --> 00:36:53,180
that have some value.

800
00:36:53,180 --> 00:36:55,040
I think that it is
overlooking other things,

801
00:36:55,040 --> 00:36:57,537
but the next two
are even better.

802
00:36:57,537 --> 00:36:59,120
"This boils down to
wanting scientists

803
00:36:59,120 --> 00:37:00,620
to basically add
some responsibilities

804
00:37:00,620 --> 00:37:02,630
to the number of things
they have to do already,

805
00:37:02,630 --> 00:37:04,046
yet it doesn't
seem to dangle much

806
00:37:04,046 --> 00:37:06,670
in the way of tangible
money for that extra work."

807
00:37:06,670 --> 00:37:11,150
True-- TLDR-- less
science, more photo ops.

808
00:37:11,150 --> 00:37:12,920
I think that wasn't
a helpful comment.

809
00:37:12,920 --> 00:37:16,915
But I think it's reductive in
a way that is helpful for us

810
00:37:16,915 --> 00:37:18,290
as we're looking
at this problem.

811
00:37:21,850 --> 00:37:23,251
So educate yourself.

812
00:37:23,251 --> 00:37:25,000
That's what the first
commenter is saying.

813
00:37:25,000 --> 00:37:27,520
But actually, I want to say
it to everybody, including

814
00:37:27,520 --> 00:37:30,380
scientists and technologists.

815
00:37:30,380 --> 00:37:31,630
I think it's really important.

816
00:37:31,630 --> 00:37:34,520
Because we tend to think, and
we're taught science, often,

817
00:37:34,520 --> 00:37:38,922
in the public schools
somewhat historically.

818
00:37:38,922 --> 00:37:39,880
Where did it come from?

819
00:37:39,880 --> 00:37:41,320
How long has it been around?

820
00:37:41,320 --> 00:37:43,510
Why does it work this way?

821
00:37:43,510 --> 00:37:46,630
And how did it develop
into what it is today?

822
00:37:50,060 --> 00:37:51,130
I mean science studies--

823
00:37:51,130 --> 00:37:53,230
MIT has a great department
of science, technology,

824
00:37:53,230 --> 00:37:55,370
and society.

825
00:37:55,370 --> 00:37:57,580
You know, basically,
I think it's important

826
00:37:57,580 --> 00:37:58,880
not to be naive about this.

827
00:37:58,880 --> 00:38:02,350
Understand how the field
works empirically as well

828
00:38:02,350 --> 00:38:03,580
as theoretically.

829
00:38:03,580 --> 00:38:06,040
As in, you know,
how do we aspire

830
00:38:06,040 --> 00:38:09,190
for it to work versus
empirically, how can we measure

831
00:38:09,190 --> 00:38:14,200
it to be working or not or in
what ways, who it's benefited

832
00:38:14,200 --> 00:38:16,000
and how it developed over time.

833
00:38:16,000 --> 00:38:18,340
This is one thing that
I really respect folks

834
00:38:18,340 --> 00:38:22,540
like Harry Collins for
trying to understand, apart

835
00:38:22,540 --> 00:38:25,900
from the different ways
that people have actually

836
00:38:25,900 --> 00:38:27,400
come up with to understand it.

837
00:38:27,400 --> 00:38:30,880
I mean, Harry Collins
is just one perspective.

838
00:38:30,880 --> 00:38:32,480
Part of this, I
think, is vocabulary.

839
00:38:32,480 --> 00:38:34,210
And just about this
particular topic

840
00:38:34,210 --> 00:38:36,480
that Public Lab
is engaged in, you

841
00:38:36,480 --> 00:38:38,609
might have seen three
different phrases.

842
00:38:38,609 --> 00:38:40,150
You'd come across
these three phrases

843
00:38:40,150 --> 00:38:44,044
to describe closely
related ideas.

844
00:38:44,044 --> 00:38:45,460
Public Lab uses
community science.

845
00:38:45,460 --> 00:38:47,630
It's a term that we've
helped to define.

846
00:38:47,630 --> 00:38:50,770
In part, we've used it
because there's actually

847
00:38:50,770 --> 00:38:53,500
two definitions of citizen
science, which are competing

848
00:38:53,500 --> 00:38:55,140
and quite confusing.

849
00:38:55,140 --> 00:39:00,940
There's the 1995, Alan Irwin's
definition of citizen science.

850
00:39:00,940 --> 00:39:03,130
Rick Bonney describes
it as a methodology

851
00:39:03,130 --> 00:39:05,530
for engaging a large
group of people outside

852
00:39:05,530 --> 00:39:10,360
of science practice in
performing data collection.

853
00:39:10,360 --> 00:39:13,690
For example, doing bird
counts, submitting data,

854
00:39:13,690 --> 00:39:15,610
being an extension
of science's ability

855
00:39:15,610 --> 00:39:16,705
to interrogate the world.

856
00:39:16,705 --> 00:39:18,080
And this is a very
powerful thing

857
00:39:18,080 --> 00:39:20,590
that I think that
Public Lab uses as well.

858
00:39:20,590 --> 00:39:22,480
But actually, I think
Public Lab is perhaps

859
00:39:22,480 --> 00:39:26,470
more inspired by the older
definition of citizen science

860
00:39:26,470 --> 00:39:27,610
by Irwin.

861
00:39:27,610 --> 00:39:34,030
And Irwin described the
work of HIV activists

862
00:39:34,030 --> 00:39:43,560
in the '90s and earlier
who included AIDS patients,

863
00:39:43,560 --> 00:39:51,160
and who were involved in
drug trials in early AIDS

864
00:39:51,160 --> 00:39:52,180
treatments.

865
00:39:52,180 --> 00:39:55,090
And they organized.

866
00:39:55,090 --> 00:39:55,800
They protested.

867
00:39:55,800 --> 00:40:00,220
They did die ins at the
National Institutes of Health.

868
00:40:00,220 --> 00:40:06,000
And ultimately,
they gained what--

869
00:40:06,000 --> 00:40:09,700
and again, I'm over
reference term by Collins--

870
00:40:09,700 --> 00:40:12,220
interactional
expertise, which is

871
00:40:12,220 --> 00:40:16,900
that they could read
and debate papers

872
00:40:16,900 --> 00:40:19,240
and peer-reviewed research.

873
00:40:19,240 --> 00:40:24,640
They could challenge the
structure of drug trials,

874
00:40:24,640 --> 00:40:27,240
and they successfully
did so, persuading

875
00:40:27,240 --> 00:40:30,460
those who ran the trials
to modify how they worked.

876
00:40:30,460 --> 00:40:33,760
And in some cases, they did so
in an extremely disruptive way

877
00:40:33,760 --> 00:40:34,780
to the researchers.

878
00:40:34,780 --> 00:40:38,830
Which is to say they
sometimes exchanged

879
00:40:38,830 --> 00:40:41,170
the drugs they
were given in order

880
00:40:41,170 --> 00:40:44,200
to intentionally mix
placebos with nonplacebos

881
00:40:44,200 --> 00:40:47,890
because they found it
to be unethical to do

882
00:40:47,890 --> 00:40:50,560
double blind research on
people who are suffering.

883
00:40:50,560 --> 00:40:53,620
So it's a complicated
story, many sides,

884
00:40:53,620 --> 00:40:59,350
many, many important
aspects of this.

885
00:40:59,350 --> 00:41:04,060
But what happened was not
that scientists, per se,

886
00:41:04,060 --> 00:41:06,130
decided to include
people in their research,

887
00:41:06,130 --> 00:41:08,230
but that they were
persuaded to do so.

888
00:41:08,230 --> 00:41:11,950
And they eventually did so,
some of them, voluntarily.

889
00:41:11,950 --> 00:41:15,380
And collaborated with
activists, in some cases,

890
00:41:15,380 --> 00:41:17,110
in order to recruit
for new trials.

891
00:41:17,110 --> 00:41:19,360
So there were constructive
collaborations that led out

892
00:41:19,360 --> 00:41:21,190
of this sequence of events.

893
00:41:21,190 --> 00:41:24,400
And it's a fascinating history.

894
00:41:24,400 --> 00:41:29,040
It's a fascinating set
of new organizations

895
00:41:29,040 --> 00:41:33,880
or new relationships between
people who did not originally

896
00:41:33,880 --> 00:41:36,610
have almost any
kind of expertise

897
00:41:36,610 --> 00:41:41,290
besides the immediate expertise
of being a victim or a patient

898
00:41:41,290 --> 00:41:45,070
and people who had
expertise of the kind

899
00:41:45,070 --> 00:41:46,450
that we are more familiar with.

900
00:41:46,450 --> 00:41:49,750
So OK, fascinating,
and difficult

901
00:41:49,750 --> 00:41:52,150
to distinguish the two now
that the terminology has

902
00:41:52,150 --> 00:41:55,430
been overwritten.

903
00:41:55,430 --> 00:41:58,510
So Harry Collins--
also Sandra Harding,

904
00:41:58,510 --> 00:42:00,400
another controversial
figure, but one

905
00:42:00,400 --> 00:42:02,020
who I really appreciate.

906
00:42:02,020 --> 00:42:04,840
She wrote Whose Science
and Whose Knowledge?

907
00:42:04,840 --> 00:42:06,460
And she talks about
the relationship

908
00:42:06,460 --> 00:42:11,570
of feminist epistemology
with scientific research.

909
00:42:11,570 --> 00:42:14,530
And she just has so much to say.

910
00:42:14,530 --> 00:42:15,876
It's amazing.

911
00:42:15,876 --> 00:42:17,500
But one thing that
I really appreciated

912
00:42:17,500 --> 00:42:22,640
was her focus on the
selection of problematics,

913
00:42:22,640 --> 00:42:28,470
the choosing of scientific
questions as an area which,

914
00:42:28,470 --> 00:42:30,970
well, as she was writing in
the '80s, was understudied,

915
00:42:30,970 --> 00:42:34,230
she felt. So she has a
lot to say about that.

916
00:42:34,230 --> 00:42:36,180
Harry Collins has a book--

917
00:42:36,180 --> 00:42:38,920
Are We All Scientific
Experts Now?

918
00:42:38,920 --> 00:42:40,230
Spoiler alert, no.

919
00:42:40,230 --> 00:42:43,390
[LAUGHS] Definitively,
he says no.

920
00:42:43,390 --> 00:42:46,550
And I'm persuaded by
a lot of what he says,

921
00:42:46,550 --> 00:42:49,180
but not by all of it.

922
00:42:49,180 --> 00:42:53,530
Collins also did a
really interesting sort

923
00:42:53,530 --> 00:42:58,660
of retrospective of
this set of studies

924
00:42:58,660 --> 00:43:01,990
from after the
Chernobyl disaster.

925
00:43:01,990 --> 00:43:05,170
He wrote a piece in the
early 2000s looking over

926
00:43:05,170 --> 00:43:07,780
that work called The
Science of the Lambs.

927
00:43:07,780 --> 00:43:11,860
He's part of a group of
scholars who are very punny.

928
00:43:11,860 --> 00:43:16,180
But he looked at how the
studies of radiation's

929
00:43:16,180 --> 00:43:20,560
effects on sheep in Cumbria
and other parts of the UK.

930
00:43:23,610 --> 00:43:27,100
He worked with
Trevor Pinch as well.

931
00:43:27,100 --> 00:43:30,000
Basically, it's, like,
it's complicated.

932
00:43:30,000 --> 00:43:35,560
But he looked at how researchers
trying to map out and quantify

933
00:43:35,560 --> 00:43:39,970
radiation did and did not
succeed in working with farmers

934
00:43:39,970 --> 00:43:44,920
and building bridges between
the farmers' knowledge of water

935
00:43:44,920 --> 00:43:49,000
flow, of exposure,
of site conditions,

936
00:43:49,000 --> 00:43:52,600
and the farming practices,
and their own expertise

937
00:43:52,600 --> 00:43:54,012
to rich conclusions.

938
00:43:54,012 --> 00:43:55,720
Tough one, but a really
interesting read,

939
00:43:55,720 --> 00:43:58,160
and a fairly short one?

940
00:43:58,160 --> 00:44:00,294
So Sandra Harding,
as I mentioned,

941
00:44:00,294 --> 00:44:02,710
who asked the questions which
science attempts to answer--

942
00:44:02,710 --> 00:44:04,810
I think it's a
really important one.

943
00:44:04,810 --> 00:44:06,360
I don't know.

944
00:44:06,360 --> 00:44:11,030
I mean, I know, but
got to dig into that.

945
00:44:11,030 --> 00:44:14,950
So OK, some tough ones here.

946
00:44:14,950 --> 00:44:18,790
The possibility that
scientists' practice today does

947
00:44:18,790 --> 00:44:22,030
have blind spots,
and specifically

948
00:44:22,030 --> 00:44:25,780
when it comes to other forms
of knowledge production.

949
00:44:25,780 --> 00:44:28,450
Not to say it's not
interested, but there

950
00:44:28,450 --> 00:44:30,250
are new forms of
knowledge- well,

951
00:44:30,250 --> 00:44:33,010
new-ish forms of knowledge
production emerging.

952
00:44:33,010 --> 00:44:34,430
And I really want to be clear.

953
00:44:34,430 --> 00:44:36,520
I'm absolutely not
saying we should try

954
00:44:36,520 --> 00:44:38,250
to recognize climate denial.

955
00:44:38,250 --> 00:44:40,410
No.

956
00:44:40,410 --> 00:44:42,810
That's not the kind of blind
spot I'm talking about.

957
00:44:42,810 --> 00:44:45,090
[LAUGHING] I think
that's really part

958
00:44:45,090 --> 00:44:47,640
of a parallel discussion
about the influence of money

959
00:44:47,640 --> 00:44:49,630
in politics and science.

960
00:44:49,630 --> 00:44:53,190
And it's one I'm not even going
to try to broach necessarily

961
00:44:53,190 --> 00:44:54,240
in this session.

962
00:44:54,240 --> 00:44:56,821
I'm talking about
the lived experience

963
00:44:56,821 --> 00:44:58,820
of those who suffer from
environmental problems.

964
00:44:58,820 --> 00:45:01,830
And to some degree, this sort
of humble recognition of our own

965
00:45:01,830 --> 00:45:04,650
limits and unknowns.

966
00:45:04,650 --> 00:45:06,940
And especially on questions,
critical questions

967
00:45:06,940 --> 00:45:09,490
of environmental harm.

968
00:45:09,490 --> 00:45:13,620
So number two-- in terms of--

969
00:45:13,620 --> 00:45:15,510
I wanted to tell the
story of this picture.

970
00:45:15,510 --> 00:45:17,430
That's a sunken
boat, so ignore it.

971
00:45:17,430 --> 00:45:21,020
This is-- I wrote it
over with letters, oops.

972
00:45:21,020 --> 00:45:24,840
But there's a darker
thing here, right?

973
00:45:24,840 --> 00:45:29,950
And that's actually melted ice
as water came out of a pipe

974
00:45:29,950 --> 00:45:31,110
on the side of this canal.

975
00:45:31,110 --> 00:45:33,735
And that wasn't on the
original engineering surveys.

976
00:45:33,735 --> 00:45:38,670
And it wasn't in the
EPA's data on this site.

977
00:45:38,670 --> 00:45:40,140
But it's an active inflow.

978
00:45:40,140 --> 00:45:43,710
There's water and whatever
else coming out of it,

979
00:45:43,710 --> 00:45:45,060
off of a construction site.

980
00:45:45,060 --> 00:45:47,640
And it's just a good example.

981
00:45:47,640 --> 00:45:49,590
There's a group who lives there.

982
00:45:49,590 --> 00:45:51,930
They go by that site every day.

983
00:45:51,930 --> 00:45:54,486
And they can do kinds
of observations.

984
00:45:54,486 --> 00:45:55,860
This is data
collection in a way.

985
00:45:55,860 --> 00:45:59,250
But they did it not because they
were contributing to science

986
00:45:59,250 --> 00:46:03,030
in a sort of a noble way,
but because they're engaged

987
00:46:03,030 --> 00:46:04,110
in the problem, you know?

988
00:46:04,110 --> 00:46:07,619
And they're critically
monitoring this site.

989
00:46:07,619 --> 00:46:08,910
They're watchdogging this site.

990
00:46:08,910 --> 00:46:13,590
And they're trying to hold
the abutters, the construction

991
00:46:13,590 --> 00:46:15,810
sites, and the potential
polluters-- they're

992
00:46:15,810 --> 00:46:17,435
trying to hold their
feet to the flame.

993
00:46:19,440 --> 00:46:21,780
They're not objective.

994
00:46:21,780 --> 00:46:24,870
But they were able to
submit data, including

995
00:46:24,870 --> 00:46:26,910
this photograph and
others, that updated

996
00:46:26,910 --> 00:46:31,170
the understanding of the site
and influenced the cleanup.

997
00:46:31,170 --> 00:46:36,171
OK, interesting, and
specifically, it's

998
00:46:36,171 --> 00:46:37,670
easy to take for
granted when you're

999
00:46:37,670 --> 00:46:40,200
speaking with your colleagues
where your expertise comes

1000
00:46:40,200 --> 00:46:45,210
from, what kind of certainty
you're communicating.

1001
00:46:45,210 --> 00:46:47,040
And this is something
that, you know,

1002
00:46:47,040 --> 00:46:52,590
when people read the so-called
climate gate e-mails, insider

1003
00:46:52,590 --> 00:46:54,690
talk is structured
in a certain way.

1004
00:46:54,690 --> 00:46:55,410
It's hard.

1005
00:46:55,410 --> 00:46:57,690
It's not designed to
communicate to all audiences.

1006
00:46:57,690 --> 00:46:59,620
But when you are
communicating with people,

1007
00:46:59,620 --> 00:47:02,790
especially outside of the group
that you work with immediately,

1008
00:47:02,790 --> 00:47:06,990
how do people know where
your expertise comes from?

1009
00:47:06,990 --> 00:47:09,060
I mean, you know,
I think titles,

1010
00:47:09,060 --> 00:47:12,150
degrees, credentials help here.

1011
00:47:12,150 --> 00:47:14,660
But they're not the whole story.

1012
00:47:14,660 --> 00:47:19,400
And there's this really
interesting sidebar.

1013
00:47:19,400 --> 00:47:22,320
The Quechua language
group in Peru

1014
00:47:22,320 --> 00:47:23,910
has this fascinating quality.

1015
00:47:23,910 --> 00:47:26,970
Which is that it has a
suffix which indicates

1016
00:47:26,970 --> 00:47:28,770
the source of your knowledge.

1017
00:47:28,770 --> 00:47:31,955
So you can say the same thing
and indicate grammatically

1018
00:47:31,955 --> 00:47:34,080
whether you heard it from
someone else, whether you

1019
00:47:34,080 --> 00:47:36,960
experienced it firsthand,
and several other forms

1020
00:47:36,960 --> 00:47:43,040
of empirical context.

1021
00:47:43,040 --> 00:47:46,080
And I often wish that I
did a better job at that.

1022
00:47:46,080 --> 00:47:48,180
Full disclosure, in
terms of communicating

1023
00:47:48,180 --> 00:47:50,062
how you get your
expertise, I'm not

1024
00:47:50,062 --> 00:47:51,270
a scholar of science studies.

1025
00:47:51,270 --> 00:47:53,550
Although I'm a fan of
it, as you can tell.

1026
00:47:53,550 --> 00:47:55,770
I also have no formal
science training.

1027
00:47:55,770 --> 00:47:58,840
I just have some thoughts.

1028
00:47:58,840 --> 00:48:01,980
I think interactional expertise
is what Collins talks about,

1029
00:48:01,980 --> 00:48:04,710
the ability to speak the
language of science, which

1030
00:48:04,710 --> 00:48:10,230
is on the way to being able to
perform at science, to actually

1031
00:48:10,230 --> 00:48:12,180
do science.

1032
00:48:12,180 --> 00:48:13,090
It's hard to develop.

1033
00:48:13,090 --> 00:48:15,660
He notes that AIDS
activists were able to do so

1034
00:48:15,660 --> 00:48:16,990
with a lot of hard work.

1035
00:48:16,990 --> 00:48:20,070
He also ran this
interesting experiment,

1036
00:48:20,070 --> 00:48:21,430
hard to know what to make of it.

1037
00:48:21,430 --> 00:48:25,140
But where he did a quiz
along with a number

1038
00:48:25,140 --> 00:48:29,070
of gravitational
wave researchers,

1039
00:48:29,070 --> 00:48:32,220
and then showed the
answers, his answers--

1040
00:48:32,220 --> 00:48:35,890
he studied the community
for over a decade.

1041
00:48:35,890 --> 00:48:38,580
But he doesn't do
gravitational wave science.

1042
00:48:38,580 --> 00:48:43,410
And actually, I think,
seven out of nine of a panel

1043
00:48:43,410 --> 00:48:45,090
were unable to
distinguish his answers

1044
00:48:45,090 --> 00:48:49,840
from those of practicing
gravitational wave scientists.

1045
00:48:49,840 --> 00:48:51,840
And that wasn't to say
that he thinks it's easy.

1046
00:48:51,840 --> 00:48:53,167
He did this for decades.

1047
00:48:53,167 --> 00:48:54,750
He worked with these
folks for decades

1048
00:48:54,750 --> 00:48:56,792
to acquire that level of
interactional expertise.

1049
00:48:56,792 --> 00:48:58,499
But what he's trying
to say is that there

1050
00:48:58,499 --> 00:49:01,380
is a fine line of distinction
between be able to communicate

1051
00:49:01,380 --> 00:49:06,960
and critique and interact with
people in a field of expertise

1052
00:49:06,960 --> 00:49:11,309
versus being able to design
and perform experiments.

1053
00:49:11,309 --> 00:49:13,350
And I don't think it's a
matter of dumbing things

1054
00:49:13,350 --> 00:49:19,170
down when we talk about
inviting other people into work.

1055
00:49:19,170 --> 00:49:21,259
I think, as the commenter
said, that scientists

1056
00:49:21,259 --> 00:49:23,550
aren't necessarily the best
at communicating knowledge.

1057
00:49:23,550 --> 00:49:24,750
But that doesn't mean
that they're off the hook

1058
00:49:24,750 --> 00:49:27,407
necessarily or that the
burden is on, exclusively,

1059
00:49:27,407 --> 00:49:27,990
everyone else.

1060
00:49:27,990 --> 00:49:30,320
I think that there has
to be some teamwork here.

1061
00:49:30,320 --> 00:49:32,070
I'm going to move
forward, because I think

1062
00:49:32,070 --> 00:49:33,622
we're running out of time here.

1063
00:49:33,622 --> 00:49:35,040
[TAPS PODIUM]

1064
00:49:35,040 --> 00:49:38,150
I did want to say--

1065
00:49:38,150 --> 00:49:42,900
let's see, OK.

1066
00:49:42,900 --> 00:49:46,580
I know that we often talk
about mass communication

1067
00:49:46,580 --> 00:49:48,990
and so forth.

1068
00:49:48,990 --> 00:49:52,260
But when outsider
groups are more

1069
00:49:52,260 --> 00:49:57,420
able to challenge
expertise, we're

1070
00:49:57,420 --> 00:50:00,970
living in an interesting time.

1071
00:50:00,970 --> 00:50:03,690
I think there are positive and
negative ramifications of this.

1072
00:50:03,690 --> 00:50:07,010
I think that the limitations
of science practice,

1073
00:50:07,010 --> 00:50:08,760
that capacity, budgets,
some of the things

1074
00:50:08,760 --> 00:50:12,510
these commenters very
clearly articulated,

1075
00:50:12,510 --> 00:50:15,440
the fact that science isn't
suited for every problem we

1076
00:50:15,440 --> 00:50:16,440
have on Earth, you know?

1077
00:50:16,440 --> 00:50:21,330
It's not the end all, and it
cannot contain all knowledge.

1078
00:50:21,330 --> 00:50:25,980
But I do think that there are
alliances that may be formed.

1079
00:50:25,980 --> 00:50:28,230
I mentioned the maker
community, the hacker community.

1080
00:50:28,230 --> 00:50:30,210
But also, environmental
justice groups

1081
00:50:30,210 --> 00:50:35,130
who have worked for
decades to do science,

1082
00:50:35,130 --> 00:50:38,580
but to do it to answer
questions about threats

1083
00:50:38,580 --> 00:50:44,190
to their own health, to find
relationships between knowledge

1084
00:50:44,190 --> 00:50:48,140
production and justice,
social justice,

1085
00:50:48,140 --> 00:50:50,390
and who have been doing their
own monitoring and watch

1086
00:50:50,390 --> 00:50:52,697
dogging, often with
very good relationships

1087
00:50:52,697 --> 00:50:54,780
with the researchers who
choose to work with them.

1088
00:50:57,290 --> 00:51:00,210
Yeah, again, I
think you can look

1089
00:51:00,210 --> 00:51:03,420
at groups who use aerial
photography as Public Lab does

1090
00:51:03,420 --> 00:51:07,920
or Google Street View to
investigate pollution issues.

1091
00:51:07,920 --> 00:51:12,060
There are more empirical
means at our disposal today.

1092
00:51:12,060 --> 00:51:16,890
And I wanted to mention, sort
of wrapping things up here,

1093
00:51:16,890 --> 00:51:19,440
that Public Lab's participating
in the Environmental Data

1094
00:51:19,440 --> 00:51:20,630
Governance Initiative.

1095
00:51:20,630 --> 00:51:22,890
So Public Lab began
as an effort to create

1096
00:51:22,890 --> 00:51:28,690
an independent record of the
BP spill, a separate data set.

1097
00:51:28,690 --> 00:51:31,110
But with the
transition happening,

1098
00:51:31,110 --> 00:51:33,840
the presidential
transition, EDGI

1099
00:51:33,840 --> 00:51:35,400
is an effort to
download and archive

1100
00:51:35,400 --> 00:51:37,560
EPA data before the
transition potentially

1101
00:51:37,560 --> 00:51:40,330
cuts off access
or destroys data,

1102
00:51:40,330 --> 00:51:42,420
as actually has happened
in previous presidential

1103
00:51:42,420 --> 00:51:43,890
transitions.

1104
00:51:43,890 --> 00:51:45,600
It's sort of a
breakneck effort that's

1105
00:51:45,600 --> 00:51:48,150
been put together
over the past 10 weeks

1106
00:51:48,150 --> 00:51:53,910
to literally, like, scrape
and download everything

1107
00:51:53,910 --> 00:51:57,270
that the government
has online currently.

1108
00:51:57,270 --> 00:52:01,590
Anyway, I mostly-- you
know, I don't have any where

1109
00:52:01,590 --> 00:52:02,810
near all the answers here.

1110
00:52:02,810 --> 00:52:04,309
But I'm trying to
ask hard questions

1111
00:52:04,309 --> 00:52:06,450
and propose ways forward.

1112
00:52:06,450 --> 00:52:09,300
I really am trying to find
places to build bridges

1113
00:52:09,300 --> 00:52:12,480
and to build alliances
and not walls.

1114
00:52:12,480 --> 00:52:15,570
And I think that
getting closer to people

1115
00:52:15,570 --> 00:52:17,880
personally, getting to
know people personally

1116
00:52:17,880 --> 00:52:21,660
who are outside of
your particular circle,

1117
00:52:21,660 --> 00:52:23,190
is really powerful.

1118
00:52:23,190 --> 00:52:25,800
To learn what people
know, what they need,

1119
00:52:25,800 --> 00:52:30,420
even if you don't always
agree, and primarily

1120
00:52:30,420 --> 00:52:34,090
to not assume that information
flows only one direction.

1121
00:52:34,090 --> 00:52:36,120
So OK, I'll put the
hardest question up.

1122
00:52:36,120 --> 00:52:39,840
Is bad science, like science
that doesn't serve the public,

1123
00:52:39,840 --> 00:52:43,530
or that is misleading,
is it science gone wrong

1124
00:52:43,530 --> 00:52:44,700
or is it science as usual?

1125
00:52:44,700 --> 00:52:46,992
Is there something
fundamental about the way

1126
00:52:46,992 --> 00:52:48,450
that we're doing
science today that

1127
00:52:48,450 --> 00:52:49,824
needs to be reformed
in some way,

1128
00:52:49,824 --> 00:52:51,540
or are there a
number of bad actors

1129
00:52:51,540 --> 00:52:53,040
who are taking
advantage of science?

1130
00:52:53,040 --> 00:52:57,490
And really, those are sort of
two sides of the same coin.

1131
00:52:57,490 --> 00:52:59,997
I mean, in the sense that
if there are bad actors,

1132
00:52:59,997 --> 00:53:01,830
we could reform science
to try to stop them.

1133
00:53:06,580 --> 00:53:08,340
And Collins says that--

1134
00:53:08,340 --> 00:53:11,670
well, I mentioned this sort
of idea of when we abhor--

1135
00:53:11,670 --> 00:53:14,010
when there are bad actors,
when we can recognize

1136
00:53:14,010 --> 00:53:15,960
when it is going wrong.

1137
00:53:15,960 --> 00:53:18,479
And then, really, these
are things that I'm

1138
00:53:18,479 --> 00:53:19,770
sure people have thought about.

1139
00:53:19,770 --> 00:53:22,470
But you know, is science more
inclusive as a profession?

1140
00:53:22,470 --> 00:53:24,430
Is it more inclusive
in its conclusions?

1141
00:53:24,430 --> 00:53:29,100
And I guess is the broader
direction of science,

1142
00:53:29,100 --> 00:53:32,040
and specifically, its questions
more than its answers,

1143
00:53:32,040 --> 00:53:33,950
simply what we make of it?

1144
00:53:33,950 --> 00:53:35,880
And I'm very clear
in that distinction.

1145
00:53:35,880 --> 00:53:38,550
Because I don't mean that its
answers are what we make of it.

1146
00:53:38,550 --> 00:53:42,471
But I do mean that we can
choose to pursue inquiry

1147
00:53:42,471 --> 00:53:43,470
in different directions.

1148
00:53:43,470 --> 00:53:49,080
And we can choose to
structure what we ask,

1149
00:53:49,080 --> 00:53:52,608
even if we can't choose to
structure what we find out.

1150
00:53:52,608 --> 00:53:53,560
Thank you.

1151
00:53:53,560 --> 00:53:58,810
[APPLAUSE]

1152
00:53:58,810 --> 00:54:01,541
AUDIENCE: I've been involved
with data collection

1153
00:54:01,541 --> 00:54:05,400
in numerous ways that have
been citizen called for.

1154
00:54:05,400 --> 00:54:08,620
One was with lead in
the soil, and the other

1155
00:54:08,620 --> 00:54:12,370
was monitoring the
river out here.

1156
00:54:12,370 --> 00:54:19,035
But now I see a really,
really important area

1157
00:54:19,035 --> 00:54:24,090
for citizens in our
communities in having

1158
00:54:24,090 --> 00:54:27,750
the skill to, you
might say, cross

1159
00:54:27,750 --> 00:54:33,973
examine the experts, especially
around infrastructure projects.

1160
00:54:33,973 --> 00:54:36,970
And I'm thinking
of the gas projects

1161
00:54:36,970 --> 00:54:40,350
in Massachusetts, where
there've been a lot of hearings

1162
00:54:40,350 --> 00:54:44,430
and the scientists,
or I would say,

1163
00:54:44,430 --> 00:54:48,730
the utility representatives
have a lot of expertise.

1164
00:54:48,730 --> 00:54:50,728
JEFF WARREN: Yeah.

1165
00:54:50,728 --> 00:54:56,432
AUDIENCE: And so there
you have a great deal

1166
00:54:56,432 --> 00:54:59,084
of information on their part.

1167
00:54:59,084 --> 00:55:02,670
And then you have these limited
opportunities for citizens

1168
00:55:02,670 --> 00:55:04,780
to raise their hand,
like, wait a minute,

1169
00:55:04,780 --> 00:55:08,210
aren't we getting too
overdependent on gas.

1170
00:55:08,210 --> 00:55:13,450
And what we don't have
is equivalent ability

1171
00:55:13,450 --> 00:55:18,116
to question the basis for
how do you make decisions

1172
00:55:18,116 --> 00:55:20,950
about these things and
being able to influence

1173
00:55:20,950 --> 00:55:22,506
the decisions that are made.

1174
00:55:22,506 --> 00:55:31,440
So I see a gap there with
whatever community ability we

1175
00:55:31,440 --> 00:55:32,910
can --

1176
00:55:32,910 --> 00:55:34,610
We need help in that vein.

1177
00:55:34,610 --> 00:55:35,360
JEFF WARREN: Yeah.

1178
00:55:35,360 --> 00:55:37,826
There's certainly
an asymmetry to it.

1179
00:55:37,826 --> 00:55:39,200
And it's very
difficult to have--

1180
00:55:43,070 --> 00:55:45,380
I mean, for example,
self-reporting is

1181
00:55:45,380 --> 00:55:50,000
a common mechanism in
terms of regulations

1182
00:55:50,000 --> 00:55:52,880
for producing knowledge
about emissions

1183
00:55:52,880 --> 00:55:55,040
or about potential pollution.

1184
00:55:55,040 --> 00:55:58,742
But self-reporting is
not blind, you know?

1185
00:55:58,742 --> 00:56:01,970
It's telling people
what you did.

1186
00:56:01,970 --> 00:56:05,120
And often, like in
Louisiana, a lot

1187
00:56:05,120 --> 00:56:08,505
of, say, smokestack emissions
are based on estimates.

1188
00:56:08,505 --> 00:56:10,880
They're not even actually
based on empirical measurements

1189
00:56:10,880 --> 00:56:13,790
that you perform yourself
as an operator of a gas

1190
00:56:13,790 --> 00:56:17,000
facility or a refinery.

1191
00:56:17,000 --> 00:56:19,320
So it's very alarming, because
the standard of evidence

1192
00:56:19,320 --> 00:56:21,320
is almost meaningless.

1193
00:56:21,320 --> 00:56:25,280
It's like, I think
we probably, maybe,

1194
00:56:25,280 --> 00:56:28,680
emitted this much
lead last night.

1195
00:56:28,680 --> 00:56:32,030
We're next to a community,
like a residential community.

1196
00:56:32,030 --> 00:56:34,260
So it's very troubling.

1197
00:56:34,260 --> 00:56:36,440
I mean, part of
this is asymmetry is

1198
00:56:36,440 --> 00:56:39,660
cost as well as expertise.

1199
00:56:39,660 --> 00:56:43,430
And I think the equipment to
measure gas, if it's cheaper,

1200
00:56:43,430 --> 00:56:45,480
it makes a lot of this easier.

1201
00:56:45,480 --> 00:56:48,860
But it's not the whole
equation, for sure.

1202
00:56:48,860 --> 00:56:54,107
One example I wanted to share
actually that I forgot was--

1203
00:56:54,107 --> 00:56:55,690
so a lot of the
community groups we've

1204
00:56:55,690 --> 00:56:59,960
worked with in places
affected by oil and gas

1205
00:56:59,960 --> 00:57:02,870
will grab sample measurements.

1206
00:57:02,870 --> 00:57:06,710
So they take a bucket,
and they use a vacuum,

1207
00:57:06,710 --> 00:57:11,259
and they suck air into a
gas bag inside the bucket.

1208
00:57:11,259 --> 00:57:12,800
And then they mail
that entire bucket

1209
00:57:12,800 --> 00:57:15,730
to a lab to get a
certified test done

1210
00:57:15,730 --> 00:57:18,570
of analysis of the contents.

1211
00:57:18,570 --> 00:57:21,800
And what is nice about this is
that it allows these community

1212
00:57:21,800 --> 00:57:24,410
groups to choose, based
on their deep knowledge

1213
00:57:24,410 --> 00:57:27,020
of the patterns-- like, do
the facilities typically emit

1214
00:57:27,020 --> 00:57:27,520
at night?

1215
00:57:27,520 --> 00:57:30,690
Do they emit at certain times,
certain days of the week?

1216
00:57:30,690 --> 00:57:31,580
Are there signals?

1217
00:57:31,580 --> 00:57:34,940
Like, is there a flare up that
you see, or is there an alarm,

1218
00:57:34,940 --> 00:57:36,320
stuff like that
that enables them

1219
00:57:36,320 --> 00:57:42,440
to structure when they take the
samples in order to sort of,

1220
00:57:42,440 --> 00:57:45,952
like, catch the emission
at the right moment.

1221
00:57:45,952 --> 00:57:48,410
What's nice about it also is
that it's a standardized test.

1222
00:57:48,410 --> 00:57:50,750
So they can send it
to different labs.

1223
00:57:50,750 --> 00:57:53,460
They're sort of, in a
sense, made it a service

1224
00:57:53,460 --> 00:57:59,960
that these labs provide,
as opposed to the people

1225
00:57:59,960 --> 00:58:02,360
collecting the sample being
the service part of it.

1226
00:58:02,360 --> 00:58:03,900
So it's sort of inverting
that in a nice way.

1227
00:58:03,900 --> 00:58:05,330
And the thing that was
really remarkable to me

1228
00:58:05,330 --> 00:58:07,288
is that several of these
communities that we've

1229
00:58:07,288 --> 00:58:13,620
spoken with and worked with
will actually not trust labs--

1230
00:58:13,620 --> 00:58:15,540
one of them didn't
trust in state labs.

1231
00:58:15,540 --> 00:58:17,540
And one of them just
doesn't trust a lot of labs

1232
00:58:17,540 --> 00:58:19,790
in general, because
they feel that there

1233
00:58:19,790 --> 00:58:22,580
may be some of these
labs do work for

1234
00:58:22,580 --> 00:58:26,220
and accept money from
oil and gas companies.

1235
00:58:26,220 --> 00:58:29,960
And so what they did, which
was really remarkable to me,

1236
00:58:29,960 --> 00:58:31,441
is they faked samples.

1237
00:58:31,441 --> 00:58:33,440
They made positive and
negative control samples.

1238
00:58:33,440 --> 00:58:35,190
And then they sent
those to labs at a cost

1239
00:58:35,190 --> 00:58:36,860
of hundreds of
dollars per sample,

1240
00:58:36,860 --> 00:58:39,470
in order to test the labs.

1241
00:58:39,470 --> 00:58:43,490
And only after confirming that
these labs would correctly

1242
00:58:43,490 --> 00:58:47,180
report different levels of
preprepared positive and

1243
00:58:47,180 --> 00:58:49,640
negative samples, did
they then use that lab

1244
00:58:49,640 --> 00:58:52,170
for their own real sampling.

1245
00:58:52,170 --> 00:58:54,170
And you can imagine that
if community groups are

1246
00:58:54,170 --> 00:58:59,060
already under resourced and
find it difficult to marshal

1247
00:58:59,060 --> 00:59:02,150
their resources to
do testing at all,

1248
00:59:02,150 --> 00:59:07,480
it's not trivial to spend all
that money to establish trust.

1249
00:59:07,480 --> 00:59:10,550
But I thought it was a really
interesting example of science

1250
00:59:10,550 --> 00:59:12,320
being done on
scientists, you know?

1251
00:59:12,320 --> 00:59:14,910
And I think it's a positive--
it's actually a positive thing,

1252
00:59:14,910 --> 00:59:16,520
you know?