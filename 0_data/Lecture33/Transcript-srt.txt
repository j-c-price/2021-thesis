1
00:00:01,640 --> 00:00:04,040
The following content is
provided under a Creative

2
00:00:04,040 --> 00:00:05,580
Commons license.

3
00:00:05,580 --> 00:00:07,880
Your support will help
MIT OpenCourseWare

4
00:00:07,880 --> 00:00:12,270
continue to offer high quality
educational resources for free.

5
00:00:12,270 --> 00:00:14,870
To make a donation or
view additional materials

6
00:00:14,870 --> 00:00:18,830
from hundreds of MIT courses,
visit MIT OpenCourseWare

7
00:00:18,830 --> 00:00:21,770
at osw.mit.edu.

8
00:00:21,770 --> 00:00:23,270
LARRY ABBOTT: So I
put this slide up

9
00:00:23,270 --> 00:00:25,550
so you could walk in and
say, I came to this course

10
00:00:25,550 --> 00:00:28,340
to learn about high level
cognition machines that

11
00:00:28,340 --> 00:00:29,450
do amazing things.

12
00:00:29,450 --> 00:00:33,870
Surely this guy's not
going to talk about a fly.

13
00:00:33,870 --> 00:00:36,110
But I am going to
talk about a fly.

14
00:00:36,110 --> 00:00:39,290
And I will try in the beginning
to explain to you why.

15
00:00:39,290 --> 00:00:42,050
And hopefully, by
the end, we'll see.

16
00:00:42,050 --> 00:00:45,470
I won't declare victory at
all, and you can tell me

17
00:00:45,470 --> 00:00:48,740
if it applies or whatever.

18
00:00:48,740 --> 00:00:52,430
The reason I'm talking about
the fly is this quote, really.

19
00:00:52,430 --> 00:00:56,511
Flies are in all sorts
of mushroom bodies.

20
00:00:56,511 --> 00:00:58,760
I'm going to talk about a
part of the fly brain called

21
00:00:58,760 --> 00:00:59,900
the mushroom body.

22
00:00:59,900 --> 00:01:03,750
And mushroom bodies are
in all sorts of insects.

23
00:01:03,750 --> 00:01:05,600
And I kind of like this quote.

24
00:01:05,600 --> 00:01:09,980
We more like to say the mushroom
body is the soul of the fly.

25
00:01:09,980 --> 00:01:15,230
But what I want to point out
here is this part of the quote.

26
00:01:15,230 --> 00:01:18,020
Flies are not as
intelligent as you,

27
00:01:18,020 --> 00:01:20,062
but they're
intelligence, much of it,

28
00:01:20,062 --> 00:01:22,520
comes from this small part of
the brain called the mushroom

29
00:01:22,520 --> 00:01:24,500
body.

30
00:01:24,500 --> 00:01:27,440
If you have free will,
they have free will.

31
00:01:27,440 --> 00:01:33,500
But unlike you, we can here
point to a part of the brain

32
00:01:33,500 --> 00:01:35,580
and say, that's where it is.

33
00:01:35,580 --> 00:01:38,680
And I'll try to convince
you of that as we go on.

34
00:01:38,680 --> 00:01:41,150
And so that's why I'm
talking about a fly.

35
00:01:41,150 --> 00:01:44,019
You can really say there's this
small part of the brain called

36
00:01:44,019 --> 00:01:44,810
the mushroom body--

37
00:01:44,810 --> 00:01:46,760
I'll show it to
you in a second--

38
00:01:46,760 --> 00:01:50,540
where maybe not uniquely,
but certainly is

39
00:01:50,540 --> 00:01:54,680
a point at which
intelligent behavior arises,

40
00:01:54,680 --> 00:01:57,470
in which something like
free will, whatever

41
00:01:57,470 --> 00:02:00,020
makes different flies
do different things

42
00:02:00,020 --> 00:02:02,360
on different occasions arises.

43
00:02:02,360 --> 00:02:05,150
Now, not only that,
again, compared

44
00:02:05,150 --> 00:02:08,240
to what you might
know in a mammal,

45
00:02:08,240 --> 00:02:10,550
this is a region of the
brain where all the cell

46
00:02:10,550 --> 00:02:12,050
types are known.

47
00:02:12,050 --> 00:02:15,780
There's genetic control
over all the cell types.

48
00:02:15,780 --> 00:02:18,800
There is a very good
optical level anatomy.

49
00:02:18,800 --> 00:02:21,800
And very soon, there'll
be an EM level anatomy.

50
00:02:21,800 --> 00:02:25,800
So it's a region of the
brain that has all of that.

51
00:02:25,800 --> 00:02:29,900
And so I thought it would
be a good example of where

52
00:02:29,900 --> 00:02:34,010
the limits of knowledge
of neuroscience

53
00:02:34,010 --> 00:02:35,944
are really extended out.

54
00:02:35,944 --> 00:02:37,610
You have to put up
with it's only a fly.

55
00:02:37,610 --> 00:02:39,860
Sure, it's kind of
a stupid animal.

56
00:02:39,860 --> 00:02:43,340
But I'll show you some behaviors
and what this thing can do,

57
00:02:43,340 --> 00:02:44,900
and we'll see how it will go.

58
00:02:44,900 --> 00:02:47,240
And maybe just some
machine learning.

59
00:02:47,240 --> 00:02:49,860
So these are the
people involved.

60
00:02:49,860 --> 00:02:53,930
This is a talk in which the
fraction of the work that I did

61
00:02:53,930 --> 00:02:57,990
is not zero, but it's
very, very small.

62
00:02:57,990 --> 00:03:01,040
And so much of it is
done in collaboration

63
00:03:01,040 --> 00:03:04,670
with Richard Axel and members
of his lab, of whom all

64
00:03:04,670 --> 00:03:06,080
of these-- you
can see the names.

65
00:03:06,080 --> 00:03:08,900
Ann is a theory student
who worked with me.

66
00:03:08,900 --> 00:03:11,660
But an awful lot of the
work is done at Janelia

67
00:03:11,660 --> 00:03:15,960
in a collaboration with
Jerry Rubin's group,

68
00:03:15,960 --> 00:03:19,910
and in particular, Yoshi Aso
did a huge amount of work here.

69
00:03:19,910 --> 00:03:24,170
So I feel just fortunate to
be able to kind of correct

70
00:03:24,170 --> 00:03:26,090
the commas on the paper.

71
00:03:26,090 --> 00:03:28,200
That was my role
in this project.

72
00:03:28,200 --> 00:03:30,200
So that's the people.

73
00:03:30,200 --> 00:03:33,080
OK, so what is the
mushroom body all about?

74
00:03:33,080 --> 00:03:35,181
This is a diagram of
the olfactory system.

75
00:03:35,181 --> 00:03:36,680
I should have said
at the beginning,

76
00:03:36,680 --> 00:03:39,050
not only is it flies,
it's olfaction.

77
00:03:39,050 --> 00:03:40,100
Two of the most--

78
00:03:40,100 --> 00:03:43,340
can you pick a more boring sense
and a more boring creature?

79
00:03:43,340 --> 00:03:45,240
So anyway, let's give it a try.

80
00:03:45,240 --> 00:03:49,990
So flies have receptors
along their antenna.

81
00:03:49,990 --> 00:03:51,410
The don't have a
nose, but that's

82
00:03:51,410 --> 00:03:53,810
where the olfactory
receptors are.

83
00:03:53,810 --> 00:03:57,240
I'll show you in a schematic
a little bit later.

84
00:03:57,240 --> 00:03:59,670
There are neurons that
receive the odors,

85
00:03:59,670 --> 00:04:02,010
then send a signal
to this structure.

86
00:04:02,010 --> 00:04:04,430
This is called
the antennal lobe.

87
00:04:04,430 --> 00:04:07,220
And at that point,
it gets relayed

88
00:04:07,220 --> 00:04:09,650
from these set of neurons
to a set of neurons

89
00:04:09,650 --> 00:04:11,240
called projection neurons.

90
00:04:11,240 --> 00:04:14,356
Those go up here, and
they send their signal

91
00:04:14,356 --> 00:04:15,230
to the mushroom body.

92
00:04:15,230 --> 00:04:18,829
And the mushroom body is
this kind of L-shaped thing

93
00:04:18,829 --> 00:04:21,829
here that I'll describe
in more detail.

94
00:04:21,829 --> 00:04:25,340
And then they also send axons
to another region of the brain

95
00:04:25,340 --> 00:04:26,930
called the lateral horn.

96
00:04:26,930 --> 00:04:28,340
I'll come back to that.

97
00:04:28,340 --> 00:04:30,500
I think I'll come back to that.

98
00:04:30,500 --> 00:04:33,110
Maybe I should say it
now so I don't forget.

99
00:04:33,110 --> 00:04:35,600
So as you'll see,
the mushroom body

100
00:04:35,600 --> 00:04:38,240
is going to be responsible
for learned behaviors,

101
00:04:38,240 --> 00:04:41,720
is responsible for learned
behaviors in the fly.

102
00:04:41,720 --> 00:04:43,700
And the lateral
horn is responsible

103
00:04:43,700 --> 00:04:44,804
for innate behaviors.

104
00:04:44,804 --> 00:04:46,220
You'll see at the
end of the talk,

105
00:04:46,220 --> 00:04:47,810
actually, evidence of that.

106
00:04:47,810 --> 00:04:50,650
So there's a division which
actually occurs in your brain

107
00:04:50,650 --> 00:04:53,300
too of the olfactory
pathway to an innate

108
00:04:53,300 --> 00:04:56,690
pathway and a more
flexible learned pathway.

109
00:05:00,320 --> 00:05:01,550
So this is a diagram.

110
00:05:01,550 --> 00:05:03,510
This is, again, from
the Janelia work

111
00:05:03,510 --> 00:05:06,260
of real pictures of the stuff.

112
00:05:06,260 --> 00:05:08,570
It's overlaid on a fly brain.

113
00:05:08,570 --> 00:05:10,500
You don't see the
periphery here,

114
00:05:10,500 --> 00:05:12,200
but these are the
antennal lobes.

115
00:05:12,200 --> 00:05:15,380
So this is this relay
station in the fly brain.

116
00:05:15,380 --> 00:05:17,990
Here is one of the projection
neurons you see here.

117
00:05:17,990 --> 00:05:19,160
This is the mushroom body.

118
00:05:19,160 --> 00:05:21,110
Again, this L-shaped thing.

119
00:05:21,110 --> 00:05:22,460
And then it goes backwards.

120
00:05:22,460 --> 00:05:25,910
So that purple are the cell
bodies of the mushroom body.

121
00:05:25,910 --> 00:05:28,520
And here you can see it, again,
going to the lateral horn.

122
00:05:28,520 --> 00:05:34,770
This is the optic part of the
fly brain for doing olfaction.

123
00:05:34,770 --> 00:05:37,880
This is obviously a
schematic of the stages

124
00:05:37,880 --> 00:05:41,220
of olfaction in the fly.

125
00:05:41,220 --> 00:05:43,060
These are supposed
to be the receptors,

126
00:05:43,060 --> 00:05:44,810
so let me start with them.

127
00:05:44,810 --> 00:05:47,150
They're called olfactory
receptor neurons.

128
00:05:47,150 --> 00:05:48,980
There are about 1,000 of them.

129
00:05:48,980 --> 00:05:51,630
They come in around 50 types.

130
00:05:51,630 --> 00:05:55,250
And here the types have
been drawn in colors.

131
00:05:55,250 --> 00:05:59,120
And what a type means
is a cell that expresses

132
00:05:59,120 --> 00:06:02,150
a single receptor molecule.

133
00:06:02,150 --> 00:06:05,300
So it will bind to a
set of odors, whatever

134
00:06:05,300 --> 00:06:07,430
that particular molecule does.

135
00:06:07,430 --> 00:06:09,410
And so all of these
red guys are virtually

136
00:06:09,410 --> 00:06:11,330
identical in their responses.

137
00:06:11,330 --> 00:06:14,540
All of the green guys
are identical, et cetera.

138
00:06:14,540 --> 00:06:15,750
And there are 50 types.

139
00:06:15,750 --> 00:06:18,290
And I'll show you
in a second, they

140
00:06:18,290 --> 00:06:21,440
form about a 30-dimensional
representation

141
00:06:21,440 --> 00:06:23,060
of olfactory space.

142
00:06:23,060 --> 00:06:25,670
Not as high as in your nose.

143
00:06:25,670 --> 00:06:29,090
Not nearly as high
as in a mouse's nose.

144
00:06:29,090 --> 00:06:31,740
But that's what you get.

145
00:06:31,740 --> 00:06:33,930
OK, as I mentioned,
these project

146
00:06:33,930 --> 00:06:35,930
to this structure, which
is the antennal lobe

147
00:06:35,930 --> 00:06:37,370
in my little diagram.

148
00:06:37,370 --> 00:06:38,870
And they have the
property that all

149
00:06:38,870 --> 00:06:42,500
of the cells of a certain
type, in other words expressing

150
00:06:42,500 --> 00:06:46,400
a particular receptor, project
to the same site, which

151
00:06:46,400 --> 00:06:47,990
is called a glomerulus.

152
00:06:47,990 --> 00:06:50,480
So you can see all the red
guys go to the red one.

153
00:06:50,480 --> 00:06:52,880
All the purple guys to
the purple one, et cetera.

154
00:06:52,880 --> 00:06:55,760
So this is an incredibly
precise wiring

155
00:06:55,760 --> 00:07:00,590
getting these 50 olfactory
signals from the 50 types

156
00:07:00,590 --> 00:07:04,640
to a point in space,
or a region in space.

157
00:07:04,640 --> 00:07:07,890
And that's the point at
which the next cells--

158
00:07:07,890 --> 00:07:09,620
so this is obviously
the input layer.

159
00:07:09,620 --> 00:07:14,630
I'm sort of over here,
giving you computer language,

160
00:07:14,630 --> 00:07:16,200
if you want, for all this.

161
00:07:16,200 --> 00:07:19,910
So at this point, you have
the projection neurons

162
00:07:19,910 --> 00:07:21,290
pick up the signal.

163
00:07:21,290 --> 00:07:22,970
There are about
200 of them, again,

164
00:07:22,970 --> 00:07:25,740
in the exact same 50
types, because there

165
00:07:25,740 --> 00:07:27,860
are a few projection
neurons for each

166
00:07:27,860 --> 00:07:30,380
of these different glomeruli.

167
00:07:30,380 --> 00:07:32,919
And they send the signal
onto the mushroom body,

168
00:07:32,919 --> 00:07:34,460
and as I mentioned,
the lateral horn,

169
00:07:34,460 --> 00:07:38,240
although we won't talk about
that whole lot until the end.

170
00:07:38,240 --> 00:07:40,940
And this is a
one-to-one connection.

171
00:07:40,940 --> 00:07:43,310
So every projection neuron--

172
00:07:43,310 --> 00:07:46,130
let's say there are
red type projection

173
00:07:46,130 --> 00:07:49,362
neurons that just pick up the
red signal, send it onward.

174
00:07:49,362 --> 00:07:51,320
There are purple type
guys-- they're not really

175
00:07:51,320 --> 00:07:56,570
called this-- but they accept
these 50 signals, maintain them

176
00:07:56,570 --> 00:07:58,910
as separate pathways.

177
00:07:58,910 --> 00:08:02,510
So what's this thing doing
from a sort of computer science

178
00:08:02,510 --> 00:08:03,410
point of view?

179
00:08:03,410 --> 00:08:05,030
Obviously, it's pooling.

180
00:08:05,030 --> 00:08:10,040
So these 1,000 cells are
pooling their resources

181
00:08:10,040 --> 00:08:11,850
into 50 glomeruli.

182
00:08:11,850 --> 00:08:15,800
So you're averaging and
you're reducing noise.

183
00:08:15,800 --> 00:08:19,160
And there's also a normalization
process that goes on here.

184
00:08:19,160 --> 00:08:21,170
There are lateral
connections here

185
00:08:21,170 --> 00:08:25,220
that try to even out
the responses so that--

186
00:08:25,220 --> 00:08:28,010
let's say at a fixed
concentration, one odor that

187
00:08:28,010 --> 00:08:31,100
causes a lot of responses
in the receptors

188
00:08:31,100 --> 00:08:35,390
and another odor that gives
much less response kind of get

189
00:08:35,390 --> 00:08:39,620
equaled out here, so that
the strong odor doesn't

190
00:08:39,620 --> 00:08:43,789
overwhelm the weaker odor.

191
00:08:43,789 --> 00:08:46,310
OK, so that's this stage.

192
00:08:46,310 --> 00:08:50,340
And I thought I'd show you
some of these responses.

193
00:08:50,340 --> 00:08:52,610
So here are the 50.

194
00:08:52,610 --> 00:08:54,030
This is not all data.

195
00:08:54,030 --> 00:08:55,850
This is data plus extrapolation.

196
00:08:55,850 --> 00:08:57,650
But the data comes
from a beautiful study

197
00:08:57,650 --> 00:08:59,120
of Hallem and Carlson.

198
00:08:59,120 --> 00:09:03,480
These would be the 50 ORNs,
types, so one of each type.

199
00:09:03,480 --> 00:09:06,710
And here are 110 orders
that were tested.

200
00:09:06,710 --> 00:09:10,700
And the responses in firing rate
color kind of look like this.

201
00:09:10,700 --> 00:09:13,660
You can see they've
been graded here.

202
00:09:13,660 --> 00:09:17,000
The responses get stronger as
you move from left to right.

203
00:09:17,000 --> 00:09:18,870
That's just the way
they ordered them.

204
00:09:18,870 --> 00:09:21,140
And you can see
they're quite uneven.

205
00:09:21,140 --> 00:09:23,780
So here is a kind of
weak responding odors

206
00:09:23,780 --> 00:09:26,600
and here are much
stronger responding odors.

207
00:09:26,600 --> 00:09:28,520
So that's what's coming in.

208
00:09:28,520 --> 00:09:32,570
Now, if you look at the PN
level-- now, this is not data.

209
00:09:32,570 --> 00:09:34,470
This is a model.

210
00:09:34,470 --> 00:09:37,880
It's a model really due to
Rachel Wilson and members

211
00:09:37,880 --> 00:09:41,150
of her lab, but also
constructed by Sean Luo

212
00:09:41,150 --> 00:09:44,370
and Ann Kennedy in my group.

213
00:09:44,370 --> 00:09:46,310
And you can see the argument.

214
00:09:46,310 --> 00:09:48,860
So basically, what's
happened is these inputs

215
00:09:48,860 --> 00:09:52,370
come in and have gone through
a model that reproduces what

216
00:09:52,370 --> 00:09:54,290
we think the PNs are doing.

217
00:09:54,290 --> 00:09:57,080
PNs have not been tested with
this whole panel of odors.

218
00:09:57,080 --> 00:09:59,120
But you can see the
normalization effect.

219
00:09:59,120 --> 00:10:01,920
You notice that the activity
is spread much more equally

220
00:10:01,920 --> 00:10:04,320
across these odors
than these odors.

221
00:10:04,320 --> 00:10:07,050
And that's reflected in the
fact that if you measure

222
00:10:07,050 --> 00:10:10,110
by various ways the dimension
of this representation,

223
00:10:10,110 --> 00:10:11,220
you get about 30.

224
00:10:11,220 --> 00:10:13,800
And here it goes up
a little bit to 35

225
00:10:13,800 --> 00:10:16,440
because of this kind
of equalization effect,

226
00:10:16,440 --> 00:10:18,840
and also some decorrelation
effect that goes on.

227
00:10:21,960 --> 00:10:26,880
So there is that.

228
00:10:26,880 --> 00:10:29,580
So what I've described here
is sort of the front end

229
00:10:29,580 --> 00:10:31,230
of this olfactory system.

230
00:10:31,230 --> 00:10:35,430
And it is completely
stereotyped.

231
00:10:35,430 --> 00:10:37,680
It's a precise wiring.

232
00:10:37,680 --> 00:10:39,120
I've described it to you.

233
00:10:39,120 --> 00:10:41,070
It's the same in every fly.

234
00:10:41,070 --> 00:10:43,950
If you look at two
neurons of the same type,

235
00:10:43,950 --> 00:10:45,820
they look virtually identical.

236
00:10:45,820 --> 00:10:48,570
So this is a hard-wired system.

237
00:10:48,570 --> 00:10:51,750
And you would not say
there's any free will

238
00:10:51,750 --> 00:10:53,280
or intelligence in this system.

239
00:10:53,280 --> 00:10:55,590
It's just getting the signal in.

240
00:10:55,590 --> 00:10:59,820
And you'll see a little
bit more of that later.

241
00:10:59,820 --> 00:11:02,050
OK, so what about
the next level?

242
00:11:02,050 --> 00:11:03,850
The next level is
the mushroom body.

243
00:11:03,850 --> 00:11:07,380
So these yellow things are
the mushroom body neurons.

244
00:11:07,380 --> 00:11:09,060
They're called Kenyon cells.

245
00:11:09,060 --> 00:11:10,920
There are about 2,000 of them.

246
00:11:10,920 --> 00:11:12,990
They come in only seven types.

247
00:11:12,990 --> 00:11:15,850
So already, we sense
something's happening here.

248
00:11:15,850 --> 00:11:18,420
There's something changing
about the representation.

249
00:11:18,420 --> 00:11:21,180
The representation is getting
much higher dimensional.

250
00:11:21,180 --> 00:11:23,430
It's something like
1,000 dimensional.

251
00:11:23,430 --> 00:11:27,180
So there's a projection
out to a high dimensional

252
00:11:27,180 --> 00:11:28,620
representation.

253
00:11:28,620 --> 00:11:32,190
And this is where the
free will comes in.

254
00:11:32,190 --> 00:11:35,730
And in anatomical terms, the
reason it does is because--

255
00:11:35,730 --> 00:11:37,770
I'll try to persuade
you with the data--

256
00:11:37,770 --> 00:11:40,770
that this acts exactly like
a random, high dimensional,

257
00:11:40,770 --> 00:11:44,800
hidden layer in a
machine learning system.

258
00:11:44,800 --> 00:11:48,090
So this guy is
suddenly a new beast.

259
00:11:48,090 --> 00:11:50,580
Within one synapse,
the system's gone

260
00:11:50,580 --> 00:11:54,570
from completely stereotyped
to, you know, crazy.

261
00:11:54,570 --> 00:11:56,040
Completely random.

262
00:11:56,040 --> 00:11:58,140
I would say there's
lots of evidence

263
00:11:58,140 --> 00:12:00,120
that it's different
in every fly,

264
00:12:00,120 --> 00:12:02,910
that every one of these
neurons is different.

265
00:12:02,910 --> 00:12:06,060
And you've completely
given up the stereotypy.

266
00:12:06,060 --> 00:12:08,340
So now, how do you
get back to sense?

267
00:12:08,340 --> 00:12:10,740
Because you've built
this beautiful olfactory

268
00:12:10,740 --> 00:12:13,860
representation here, and it's
as if you've thrown it out.

269
00:12:13,860 --> 00:12:16,290
You've just gone crazy.

270
00:12:16,290 --> 00:12:20,430
And so now, I put the box
around here just to remind us,

271
00:12:20,430 --> 00:12:22,800
this is a different
beast all of a sudden.

272
00:12:22,800 --> 00:12:26,400
And it's a very unusual
beast in the fly brain.

273
00:12:26,400 --> 00:12:27,380
I'll come back to that.

274
00:12:27,380 --> 00:12:30,440
But now you have output.

275
00:12:30,440 --> 00:12:32,280
So these yellow
neurons, as you'll see,

276
00:12:32,280 --> 00:12:34,080
do not leave the mushroom body.

277
00:12:34,080 --> 00:12:35,610
They don't send any signal out.

278
00:12:35,610 --> 00:12:37,920
They're completely intrinsic
to the mushroom body.

279
00:12:37,920 --> 00:12:41,370
But there are neurons called
mushroom body output neurons

280
00:12:41,370 --> 00:12:43,770
that do send the signal out.

281
00:12:43,770 --> 00:12:47,430
And again, now it's
a new ballgame.

282
00:12:47,430 --> 00:12:48,960
First of all, look
at the numbers.

283
00:12:48,960 --> 00:12:53,760
You've gone from 2,000 neurons
to 34 neurons of 21 types.

284
00:12:53,760 --> 00:12:56,310
You've got about a
20-dimensional representation.

285
00:12:56,310 --> 00:12:59,770
There's been a collapse
of the representation.

286
00:12:59,770 --> 00:13:03,360
So I would argue you can just
see right away from this slide

287
00:13:03,360 --> 00:13:05,910
that this is an
olfactory representation.

288
00:13:05,910 --> 00:13:08,070
This is an olfactory
representation cleaned up

289
00:13:08,070 --> 00:13:08,670
a bit.

290
00:13:08,670 --> 00:13:11,410
This is a crazy, random
olfactory representation.

291
00:13:11,410 --> 00:13:13,680
This is not an olfactory
representation.

292
00:13:13,680 --> 00:13:16,280
The dimension is lower
than what you started with,

293
00:13:16,280 --> 00:13:20,130
so there's no way you can
represent the full thing.

294
00:13:20,130 --> 00:13:24,330
This is already, somehow, making
a decision about olfaction.

295
00:13:24,330 --> 00:13:27,180
It's well on the
way to a behavior.

296
00:13:27,180 --> 00:13:31,050
And again, the great
thing about the fly

297
00:13:31,050 --> 00:13:35,220
here is that you get
there very quickly.

298
00:13:35,220 --> 00:13:37,350
If you went to Jim's
talk today, I'm

299
00:13:37,350 --> 00:13:40,590
sure he talked to you
about the long pathway

300
00:13:40,590 --> 00:13:44,550
in the visual
systems of monkeys,

301
00:13:44,550 --> 00:13:49,210
in which these stages take up
a good fraction of your brain.

302
00:13:49,210 --> 00:13:51,990
These more complicated
stages do it.

303
00:13:51,990 --> 00:13:54,150
And then it's very
difficult to see

304
00:13:54,150 --> 00:13:57,860
where this transition is to
decisions and things like that.

305
00:13:57,860 --> 00:14:01,680
Here, the transition from
orderly input representation,

306
00:14:01,680 --> 00:14:05,400
sort of retinal-like,
to IT-like,

307
00:14:05,400 --> 00:14:08,580
if you want, in the visual
system occurs in one synapse.

308
00:14:08,580 --> 00:14:12,510
And then the return to
a decision, a behavior,

309
00:14:12,510 --> 00:14:13,590
in another synapse.

310
00:14:13,590 --> 00:14:14,910
It's very quick.

311
00:14:14,910 --> 00:14:18,240
And I would think of that
in computer science terms

312
00:14:18,240 --> 00:14:19,294
as a readout layer.

313
00:14:19,294 --> 00:14:21,210
As you'll see, it's
actually a layered system,

314
00:14:21,210 --> 00:14:22,710
but it's the readout.

315
00:14:22,710 --> 00:14:26,640
OK, and this system
here, it goes back

316
00:14:26,640 --> 00:14:29,500
to being completely stereotyped.

317
00:14:29,500 --> 00:14:34,300
There are very few neurons
per type, if you notice.

318
00:14:34,300 --> 00:14:37,680
There are almost as many cell
types as there are neurons.

319
00:14:37,680 --> 00:14:40,350
And they're the same
in every animal.

320
00:14:40,350 --> 00:14:43,020
So you've gone from
stereotypy at the input

321
00:14:43,020 --> 00:14:46,470
stage, a wild and crazy
random thing in the middle,

322
00:14:46,470 --> 00:14:49,560
and then back to stereotypic
to get to the output.

323
00:14:49,560 --> 00:14:51,630
Which of course, you
have to do, right?

324
00:14:51,630 --> 00:14:53,800
Your motor neurons have to
go to the right muscles.

325
00:14:53,800 --> 00:14:56,250
You can't randomly wire
your motor neurons.

326
00:14:56,250 --> 00:14:58,064
And thinking occurs
between those.

327
00:14:58,064 --> 00:14:59,230
Same thing with your retina.

328
00:14:59,230 --> 00:15:02,140
It has to be wired to give
you the basic visual signal.

329
00:15:02,140 --> 00:15:03,910
But between those
two extremes, that's

330
00:15:03,910 --> 00:15:05,350
where we do our thinking.

331
00:15:05,350 --> 00:15:08,500
And as I say, that
you can see here,

332
00:15:08,500 --> 00:15:11,710
but it's in this one layer, OK?

333
00:15:11,710 --> 00:15:18,610
All right, and the key is going
to be exactly as in a machine

334
00:15:18,610 --> 00:15:19,810
learning system.

335
00:15:19,810 --> 00:15:22,480
As you'll see, the key
to the whole system

336
00:15:22,480 --> 00:15:25,000
is the plasticity and
modulation that occurs

337
00:15:25,000 --> 00:15:26,860
at that set of connections.

338
00:15:26,860 --> 00:15:30,130
There's no evidence that these
connections, these connections,

339
00:15:30,130 --> 00:15:32,530
and these connections are
at least very plastic.

340
00:15:32,530 --> 00:15:34,510
They may be modulated
a little bit,

341
00:15:34,510 --> 00:15:36,430
but the business
end of this thing,

342
00:15:36,430 --> 00:15:40,600
just as in many machine
learning networks,

343
00:15:40,600 --> 00:15:43,990
is that the readout
unit's being adjusted.

344
00:15:43,990 --> 00:15:46,280
And I will come back to that.

345
00:15:46,280 --> 00:15:48,010
All right, so here,
the mushroom body,

346
00:15:48,010 --> 00:15:50,590
it started out as
it was in the fly.

347
00:15:50,590 --> 00:15:54,070
And as it turns, you'll see why
it's called the mushroom body.

348
00:15:54,070 --> 00:15:56,050
Yeah, now it looks
like a mushroom.

349
00:15:56,050 --> 00:15:59,880
So these are the cell bodies.

350
00:15:59,880 --> 00:16:03,010
They receive-- you can't
really see very well here,

351
00:16:03,010 --> 00:16:07,570
but they receive their input
right under the mushroom.

352
00:16:07,570 --> 00:16:09,580
And then they send axons down.

353
00:16:09,580 --> 00:16:11,570
And these axons form the load.

354
00:16:11,570 --> 00:16:14,170
So this whole thing is
made out of Kenyon cells.

355
00:16:14,170 --> 00:16:17,240
That's the Kenyon cells
all together forming

356
00:16:17,240 --> 00:16:18,010
this structure.

357
00:16:18,010 --> 00:16:19,810
How many cells?

358
00:16:19,810 --> 00:16:21,870
A couple of thousand.

359
00:16:21,870 --> 00:16:25,960
OK, now here you can see one
of the projection neurons.

360
00:16:25,960 --> 00:16:28,720
Here's where it gets its
input from the antenna lobe,

361
00:16:28,720 --> 00:16:31,510
goes up to the mushroom body,
goes over to the lateral horn.

362
00:16:31,510 --> 00:16:34,830
And here you can see-- it's
sort of hard to distinguish

363
00:16:34,830 --> 00:16:36,760
that neuropil from
the cell bodies here,

364
00:16:36,760 --> 00:16:39,610
but here you can see that sort
of under this layer of cell

365
00:16:39,610 --> 00:16:42,820
bodies, it's making
its connections.

366
00:16:42,820 --> 00:16:46,240
And what I want to
stress here is this idea

367
00:16:46,240 --> 00:16:49,750
that the projection
neurons occur

368
00:16:49,750 --> 00:16:51,940
very few cells per cell type.

369
00:16:51,940 --> 00:16:53,020
Now, these cells types--

370
00:16:53,020 --> 00:16:55,970
I guess I'm going to get
ahead of myself a little bit.

371
00:16:55,970 --> 00:17:00,220
But through work at
Janelia Farm in particular,

372
00:17:00,220 --> 00:17:02,800
there have been these
intersectional strategies

373
00:17:02,800 --> 00:17:06,790
for expressing various
markers in these cells.

374
00:17:06,790 --> 00:17:09,160
And they've been
supremely successful.

375
00:17:09,160 --> 00:17:13,720
So typically, when you get a
cell type in this business,

376
00:17:13,720 --> 00:17:16,839
it's often two cells, one
on each side of the fly.

377
00:17:16,839 --> 00:17:19,339
They're perfect mirror
images of each other.

378
00:17:19,339 --> 00:17:20,800
And they're identical
in all flies.

379
00:17:20,800 --> 00:17:23,319
So that's what you
mean by a cell type.

380
00:17:23,319 --> 00:17:29,080
And in much of the fly, there
are very few of them per--

381
00:17:29,080 --> 00:17:30,550
this is per side.

382
00:17:30,550 --> 00:17:32,980
There will always
be an even number.

383
00:17:32,980 --> 00:17:36,460
And you can see, there are 50
types, a couple hundred cells.

384
00:17:36,460 --> 00:17:38,990
That's part of the
specific wiring.

385
00:17:38,990 --> 00:17:43,390
Now, if you look at the Kenyon
cells, so here they are,

386
00:17:43,390 --> 00:17:46,570
there are, as I mentioned, about
a couple of thousand of them.

387
00:17:46,570 --> 00:17:49,570
And there are up to
600 of them per type.

388
00:17:49,570 --> 00:17:52,610
It's much more like what
we think of as cortex.

389
00:17:52,610 --> 00:17:55,840
We don't think of the cortex
as having millions and millions

390
00:17:55,840 --> 00:17:56,620
of cell types.

391
00:17:56,620 --> 00:18:01,320
Maybe thousands, but there are
many, many cells per cell type.

392
00:18:01,320 --> 00:18:02,440
And that occurs here.

393
00:18:02,440 --> 00:18:06,210
Very small number of cell types
relative to the other things.

394
00:18:06,210 --> 00:18:07,900
And here's one of them.

395
00:18:07,900 --> 00:18:08,980
It's superimposed.

396
00:18:08,980 --> 00:18:12,820
So these Kenyon cells, they
have their cell body here.

397
00:18:12,820 --> 00:18:14,050
They make their connections.

398
00:18:14,050 --> 00:18:16,410
So they get the input from
the projection neuron,

399
00:18:16,410 --> 00:18:20,380
send an axon down, which
in some cases splits.

400
00:18:20,380 --> 00:18:22,710
And there are five lobes here.

401
00:18:22,710 --> 00:18:25,570
There is an alpha lobe
or an alpha prime lobe

402
00:18:25,570 --> 00:18:28,780
here, a beta lobe or a
beta prime lobe here.

403
00:18:28,780 --> 00:18:30,760
And then some of them
send a single axon

404
00:18:30,760 --> 00:18:32,360
down to a gamma lobe.

405
00:18:32,360 --> 00:18:34,350
You will see that
a little bit more.

406
00:18:34,350 --> 00:18:35,090
Then that's it.

407
00:18:35,090 --> 00:18:38,590
That's how the mushroom body's
built. And if you notice,

408
00:18:38,590 --> 00:18:41,990
they do not send anything
out of the mushroom body.

409
00:18:41,990 --> 00:18:43,840
So the first thing
I want to ask, then,

410
00:18:43,840 --> 00:18:48,010
is what happens at this junction
between the orderly world

411
00:18:48,010 --> 00:18:50,890
of the fly, characterized
by these PNs,

412
00:18:50,890 --> 00:18:54,130
and the wild and random world
of the fly, characterized

413
00:18:54,130 --> 00:18:55,090
by these Kenyon sets?

414
00:18:55,090 --> 00:18:59,470
Here's where they meet in this
calyx of the mushroom body.

415
00:18:59,470 --> 00:19:02,110
So the experiment
that I was involved

416
00:19:02,110 --> 00:19:05,950
in the data analysis of
came from Richard's lab

417
00:19:05,950 --> 00:19:08,450
and was done in
the following way.

418
00:19:08,450 --> 00:19:10,600
First, a single Kenyon
cell-- so here you

419
00:19:10,600 --> 00:19:13,480
can see all these cell
bodies of Kenyon cells.

420
00:19:13,480 --> 00:19:14,980
There are zillions
of them up there,

421
00:19:14,980 --> 00:19:16,390
thousands of them up there.

422
00:19:16,390 --> 00:19:18,310
But one of them has been--

423
00:19:18,310 --> 00:19:22,970
the GFP in one of them has
been activated, photoactivated.

424
00:19:22,970 --> 00:19:26,290
So you can see this single
Kenyon cell comes down.

425
00:19:26,290 --> 00:19:29,470
Here it's making connections
to get the olfactory input

426
00:19:29,470 --> 00:19:30,880
from the projection neurons.

427
00:19:30,880 --> 00:19:32,470
And then the axon's
going to go down

428
00:19:32,470 --> 00:19:36,400
through the floor into the
other parts that I showed you.

429
00:19:36,400 --> 00:19:39,510
So the trick in this thing--
you can't see very well,

430
00:19:39,510 --> 00:19:42,490
but I think I maybe made
a circle around one.

431
00:19:42,490 --> 00:19:46,000
You can't see it very
well, but the terminals

432
00:19:46,000 --> 00:19:48,760
of this guy, the postsynaptic
terminals, are like claws.

433
00:19:48,760 --> 00:19:49,870
They're called claws.

434
00:19:49,870 --> 00:19:53,290
And they grab hold of one of
the terminals of the projection

435
00:19:53,290 --> 00:19:54,850
neurons and make a synapse.

436
00:19:54,850 --> 00:19:56,480
So that's how they work.

437
00:19:56,480 --> 00:19:58,870
This guy has about
seven of these claws,

438
00:19:58,870 --> 00:20:03,160
so there are very few
connections per Kenyon cell.

439
00:20:03,160 --> 00:20:08,230
The trick was for Sophie
to inject the die right

440
00:20:08,230 --> 00:20:12,100
into the claw here, which
is a very tightly sealed

441
00:20:12,100 --> 00:20:14,590
little microglomerulus.

442
00:20:14,590 --> 00:20:19,000
And that die is taken up by
a projection neuron, the one

443
00:20:19,000 --> 00:20:22,700
and only one projection neuron
that has a terminal there.

444
00:20:22,700 --> 00:20:25,930
And here you can see the axon
of that projection neuron

445
00:20:25,930 --> 00:20:30,070
as it makes terminals in
other parts of this calyx

446
00:20:30,070 --> 00:20:32,510
and makes connections
with other Kenyon cells.

447
00:20:32,510 --> 00:20:33,160
So there it is.

448
00:20:33,160 --> 00:20:34,730
So that's not the
important part.

449
00:20:34,730 --> 00:20:38,170
The important part is you can
trace back this projection

450
00:20:38,170 --> 00:20:41,715
neuron to the antenna lobe and
see where it got its input.

451
00:20:41,715 --> 00:20:43,090
And now, because
the antenna lobe

452
00:20:43,090 --> 00:20:46,270
is a totally stereotyped,
structured thing,

453
00:20:46,270 --> 00:20:47,770
you can now read out.

454
00:20:47,770 --> 00:20:49,240
If you know the
antennal lobe, you

455
00:20:49,240 --> 00:20:52,330
will know that this input
is of a certain type.

456
00:20:52,330 --> 00:20:54,890
It's from a certain
set of receptors.

457
00:20:54,890 --> 00:20:58,540
So you know right away that
this guy is getting input

458
00:20:58,540 --> 00:21:02,770
from receptor number three,
or whoever sends projections

459
00:21:02,770 --> 00:21:03,830
to that thing.

460
00:21:03,830 --> 00:21:06,730
Furthermore, you can repeat
this with other terminals

461
00:21:06,730 --> 00:21:10,030
of that cell, get a
whole lot of projections,

462
00:21:10,030 --> 00:21:13,750
and find, essentially,
all of the inputs--

463
00:21:13,750 --> 00:21:16,720
sometimes not all, but
most of the inputs--

464
00:21:16,720 --> 00:21:20,330
that go to this Kenyon cell
and figure out what they are.

465
00:21:20,330 --> 00:21:22,240
So in other words,
the result of this,

466
00:21:22,240 --> 00:21:25,030
without doing EM or all
that, is a connectome.

467
00:21:25,030 --> 00:21:29,080
It's the connection matrix
between the glomeruli,

468
00:21:29,080 --> 00:21:31,540
or if you want, these
olfactory channels.

469
00:21:31,540 --> 00:21:35,020
And there are 50 up around
here, plus some hot and cold

470
00:21:35,020 --> 00:21:35,990
and some other stuff.

471
00:21:35,990 --> 00:21:39,310
But basically, the 50
glomeruli are at the top.

472
00:21:39,310 --> 00:21:43,570
And 200 Kenyon cells that were
measured going down the side.

473
00:21:43,570 --> 00:21:45,820
Not all 2,000 Kenyon
cells were measured.

474
00:21:45,820 --> 00:21:48,010
These are not measured
from the same animal.

475
00:21:48,010 --> 00:21:50,920
But you basically get
this connectivity matrix.

476
00:21:50,920 --> 00:21:55,390
A red little square here
means that this connection

477
00:21:55,390 --> 00:21:57,730
was found for this Kenyon cell.

478
00:21:57,730 --> 00:22:00,280
And a yellow one means
a double connection.

479
00:22:00,280 --> 00:22:02,980
There were actually two
connections between that Kenyon

480
00:22:02,980 --> 00:22:05,230
cell and that glomerulus.

481
00:22:05,230 --> 00:22:06,580
So there's the matrix.

482
00:22:06,580 --> 00:22:08,710
So then my job at this
point was say, well, what's

483
00:22:08,710 --> 00:22:10,860
the structure of this matrix?

484
00:22:10,860 --> 00:22:12,110
And that's a trickier problem.

485
00:22:12,110 --> 00:22:14,693
I mean, you look at it by eye,
you say, well, it looks random.

486
00:22:14,693 --> 00:22:16,360
It just looks like
a bunch of dots.

487
00:22:16,360 --> 00:22:17,860
But what you have
to remember, and I

488
00:22:17,860 --> 00:22:19,443
think this is a
really important thing

489
00:22:19,443 --> 00:22:22,000
to remember in
connectomes, is connectomes

490
00:22:22,000 --> 00:22:23,950
don't come labeled, all right?

491
00:22:23,950 --> 00:22:27,490
So this matrix is arranged
in the following way.

492
00:22:27,490 --> 00:22:29,710
This is alphabetical,
which probably is not

493
00:22:29,710 --> 00:22:32,440
of fundamental
neuroscience significance.

494
00:22:32,440 --> 00:22:35,060
And this is the order in
which the cells were measured,

495
00:22:35,060 --> 00:22:38,330
which is also probably not
of neuroscience significance.

496
00:22:38,330 --> 00:22:40,540
So the question is,
is there any way

497
00:22:40,540 --> 00:22:43,690
to permute the rows and
columns of this matrix

498
00:22:43,690 --> 00:22:44,890
to get a structure?

499
00:22:44,890 --> 00:22:47,320
That's the question you
have to answer here.

500
00:22:47,320 --> 00:22:49,370
And just let me show
you an example of that.

501
00:22:49,370 --> 00:22:52,630
So here's a matrix that
I've shrunk the size a bit,

502
00:22:52,630 --> 00:22:54,550
but it's exactly the
same kind of matrix.

503
00:22:54,550 --> 00:22:57,270
In fact, it probably looks to
you pretty much like the data.

504
00:22:57,270 --> 00:22:59,270
It doesn't have the colors,
but other than that.

505
00:22:59,270 --> 00:23:00,790
So here's a data matrix.

506
00:23:00,790 --> 00:23:02,646
But this one I made up.

507
00:23:02,646 --> 00:23:04,520
And it turns out, of
course, I knew the trick

508
00:23:04,520 --> 00:23:08,290
that if you re-sort, if you
permute the rows and columns,

509
00:23:08,290 --> 00:23:10,340
it looks like this.

510
00:23:10,340 --> 00:23:12,970
So just because
that looks random

511
00:23:12,970 --> 00:23:15,430
does not at all mean
there's no structure there.

512
00:23:15,430 --> 00:23:17,200
So you have to do
a lot of analysis

513
00:23:17,200 --> 00:23:20,440
to convince yourself that
there's no structure.

514
00:23:20,440 --> 00:23:23,020
So one of the first
things you could do--

515
00:23:23,020 --> 00:23:24,630
random doesn't mean uniform.

516
00:23:24,630 --> 00:23:27,760
So one thing you can do is
just sum down the columns here

517
00:23:27,760 --> 00:23:31,570
and ask, how many connections
does each of the glomeruli

518
00:23:31,570 --> 00:23:32,390
make?

519
00:23:32,390 --> 00:23:33,760
And it's not uniform.

520
00:23:33,760 --> 00:23:34,900
It's quite uneven.

521
00:23:34,900 --> 00:23:36,370
Here's the histogram.

522
00:23:36,370 --> 00:23:39,550
But really, the question
we ask is, is there

523
00:23:39,550 --> 00:23:41,090
something more to it?

524
00:23:41,090 --> 00:23:44,920
For example, if a Kenyon cell
gets one of these inputs,

525
00:23:44,920 --> 00:23:47,660
is it more likely to also
get one of those inputs?

526
00:23:47,660 --> 00:23:49,670
Are there any correlations here?

527
00:23:49,670 --> 00:23:51,320
And that's really the question.

528
00:23:51,320 --> 00:23:53,230
And we did a whole
lot of analysis.

529
00:23:53,230 --> 00:23:54,280
And the answer's no.

530
00:23:54,280 --> 00:23:56,350
I'm not going to
take you through it.

531
00:23:56,350 --> 00:23:58,420
That all the tests
we could possibly

532
00:23:58,420 --> 00:24:02,110
do are completely consistent
with just randomly selecting

533
00:24:02,110 --> 00:24:04,480
from this probability
distribution

534
00:24:04,480 --> 00:24:08,740
without independent ID,
or whatever it's called.

535
00:24:08,740 --> 00:24:14,920
OK, so there are other
papers, an earlier paper

536
00:24:14,920 --> 00:24:16,810
and a later paper,
that essentially

537
00:24:16,810 --> 00:24:18,230
come to the same conclusion.

538
00:24:18,230 --> 00:24:21,820
What's interesting about the
Murthy, Fiete, and Laurent

539
00:24:21,820 --> 00:24:24,405
paper is they actually
provide some evidence

540
00:24:24,405 --> 00:24:26,530
that, in fact, it's different
in different animals.

541
00:24:26,530 --> 00:24:29,260
This doesn't prove that
because this is already

542
00:24:29,260 --> 00:24:30,485
taken from different animals.

543
00:24:30,485 --> 00:24:32,110
I'm not going to
present that evidence.

544
00:24:32,110 --> 00:24:34,309
But there is
evidence that this is

545
00:24:34,309 --> 00:24:35,600
different in different animals.

546
00:24:35,600 --> 00:24:38,290
So this looks like
a random structure.

547
00:24:38,290 --> 00:24:41,200
Now, it's interesting, you
guys, why seven connections?

548
00:24:41,200 --> 00:24:47,410
Seven seems awfully small to
us cortico-centric people.

549
00:24:47,410 --> 00:24:49,120
And so why seven?

550
00:24:49,120 --> 00:24:51,580
Well, you can do a
following little exercise.

551
00:24:51,580 --> 00:24:55,390
You can say, suppose that
the Kenyon cells only had

552
00:24:55,390 --> 00:24:57,100
one connection.

553
00:24:57,100 --> 00:25:00,360
Then how many duplicate
Kenyon cells would there be?

554
00:25:00,360 --> 00:25:03,280
Well, there are only 50
possible types of input, right?

555
00:25:03,280 --> 00:25:05,159
There are 50 types
of Kenyon grand cell.

556
00:25:05,159 --> 00:25:06,575
So if you only
have one connection

557
00:25:06,575 --> 00:25:08,270
and you're making
2,000 cells, you're

558
00:25:08,270 --> 00:25:11,480
going to get tons of repeats,
hundreds of thousands

559
00:25:11,480 --> 00:25:13,150
of pairs that are identical.

560
00:25:13,150 --> 00:25:15,292
So that you would
not spread out.

561
00:25:15,292 --> 00:25:17,750
Now, you can do this calculation
for two connections, three

562
00:25:17,750 --> 00:25:19,200
connections, four connections.

563
00:25:19,200 --> 00:25:20,940
And it goes down.

564
00:25:20,940 --> 00:25:23,330
And if you look at the
line where you'd only

565
00:25:23,330 --> 00:25:27,980
expect one pair to be the same,
the mushroom body-- in fact,

566
00:25:27,980 --> 00:25:30,050
if you average, it's
between six and seven.

567
00:25:30,050 --> 00:25:31,690
It's right in there.

568
00:25:31,690 --> 00:25:33,920
The mushroom body is
right at the point

569
00:25:33,920 --> 00:25:36,710
where you convince yourself
that most of the time every cell

570
00:25:36,710 --> 00:25:37,760
will be different.

571
00:25:37,760 --> 00:25:41,630
And then why go any further?

572
00:25:41,630 --> 00:25:44,630
Some of you may know something
about the cerebellum.

573
00:25:44,630 --> 00:25:47,810
These are like granule
cells of the cerebellum.

574
00:25:47,810 --> 00:25:49,677
Granule cells in the
cerebellum typically

575
00:25:49,677 --> 00:25:51,260
have four or five
inputs [INAUDIBLE]..

576
00:25:51,260 --> 00:25:55,460
They're small cells with
claws with very few inputs.

577
00:25:55,460 --> 00:25:59,900
And their axons
form parallel fibers

578
00:25:59,900 --> 00:26:02,540
and then can get connected
by Purkinje cells.

579
00:26:02,540 --> 00:26:04,350
This system is the
same, if you notice.

580
00:26:04,350 --> 00:26:07,160
The parallel fibers
are forming the trunk

581
00:26:07,160 --> 00:26:10,800
and that L-shaped region
in the mushroom body.

582
00:26:10,800 --> 00:26:12,230
So these are like granule cells.

583
00:26:15,440 --> 00:26:17,030
OK, so where are we?

584
00:26:17,030 --> 00:26:18,980
So we've got to get a
signal out of this thing

585
00:26:18,980 --> 00:26:20,450
or it's completely
useless, right?

586
00:26:20,450 --> 00:26:23,150
So we've got this random
signal into this beast.

587
00:26:23,150 --> 00:26:25,170
So what do the output
neurons look like?

588
00:26:25,170 --> 00:26:27,410
There's an output
neuron, one of them.

589
00:26:27,410 --> 00:26:28,940
And what you might
notice is it's

590
00:26:28,940 --> 00:26:31,400
going to a very
compact region right

591
00:26:31,400 --> 00:26:34,705
at the head of this alpha--

592
00:26:34,705 --> 00:26:36,830
I don't know if this is an
alpha or an alpha prime.

593
00:26:36,830 --> 00:26:40,350
But it's going to one or
the other of those lobes.

594
00:26:40,350 --> 00:26:43,340
So it's very restricted
in its dendrites.

595
00:26:43,340 --> 00:26:46,880
And then off it goes carrying
the signal wherever it's going.

596
00:26:46,880 --> 00:26:49,880
So in fact, I tried
to argue earlier

597
00:26:49,880 --> 00:26:51,710
that the output neurons
in a mushroom body

598
00:26:51,710 --> 00:26:53,960
have gone back to
this other mode.

599
00:26:53,960 --> 00:26:55,940
Very few cells per type.

600
00:26:55,940 --> 00:26:58,610
Practically as many
types as output cells.

601
00:26:58,610 --> 00:27:00,630
And a very small
number of cells.

602
00:27:00,630 --> 00:27:04,910
And if you took a picture of
this cell in another animal,

603
00:27:04,910 --> 00:27:08,010
it would look exactly the same.

604
00:27:08,010 --> 00:27:12,020
All right, so it was known
before this Janelia work,

605
00:27:12,020 --> 00:27:14,300
that if you take the
mushroom body lobe--

606
00:27:14,300 --> 00:27:17,540
so this is this L-shaped
structure at the bottom,

607
00:27:17,540 --> 00:27:20,600
or it's really at the front
of the mushroom body--

608
00:27:20,600 --> 00:27:22,640
and you peel off the
gamma lobe, the gamma

609
00:27:22,640 --> 00:27:24,990
would sit there but it would
kind of block your view.

610
00:27:24,990 --> 00:27:26,570
So it's been peeled off here.

611
00:27:26,570 --> 00:27:29,390
So you have this
alpha beta lobe.

612
00:27:29,390 --> 00:27:32,420
That's one set of axons
that have bifurcated.

613
00:27:32,420 --> 00:27:35,420
And they come in sort of
here and then bifurcate.

614
00:27:35,420 --> 00:27:38,000
You have the alpha prime
beta lobe bifurcating.

615
00:27:38,000 --> 00:27:39,800
And then you have
this third gamma lobe.

616
00:27:39,800 --> 00:27:45,290
That divides up each of
these into five sections.

617
00:27:45,290 --> 00:27:48,110
They're numbered like this,
but there are five of them, OK?

618
00:27:48,110 --> 00:27:50,990
Alpha 1, 2, 3 and beta 1, 2.

619
00:27:50,990 --> 00:27:55,030
So each of these guys gets
divided into five compartments.

620
00:27:55,030 --> 00:27:57,800
And then there's an extra
compartment right here

621
00:27:57,800 --> 00:28:00,340
called the peduncle, where--

622
00:28:00,340 --> 00:28:01,970
here's the mushroom head.

623
00:28:01,970 --> 00:28:03,230
Here's the stock.

624
00:28:03,230 --> 00:28:04,190
And then you get this.

625
00:28:04,190 --> 00:28:07,460
And right at the base of the
stock, there's another one.

626
00:28:07,460 --> 00:28:13,550
And so what the Janelia
collaboration figured out

627
00:28:13,550 --> 00:28:17,760
by genetically targeting
these cells very precisely.

628
00:28:17,760 --> 00:28:20,160
It is summarized
by this picture.

629
00:28:20,160 --> 00:28:22,970
So this shows different
types of these output

630
00:28:22,970 --> 00:28:24,590
neurons in different colors.

631
00:28:24,590 --> 00:28:26,540
And what you can
see is that they are

632
00:28:26,540 --> 00:28:29,090
respecting the compartments.

633
00:28:29,090 --> 00:28:32,960
That you have basically one
type of output neuron going

634
00:28:32,960 --> 00:28:35,240
to each compartment
without overlap.

635
00:28:35,240 --> 00:28:36,350
And there really is--

636
00:28:36,350 --> 00:28:38,810
there's now EM level
data, and they really

637
00:28:38,810 --> 00:28:41,410
don't overlap at all.

638
00:28:41,410 --> 00:28:45,220
Here's kind of what it looks
like in an anatomical diagram.

639
00:28:45,220 --> 00:28:46,640
Here are the Kenyon cells.

640
00:28:46,640 --> 00:28:48,890
Here's the calyx where
they get their input.

641
00:28:48,890 --> 00:28:50,740
Here's this L-shaped structure.

642
00:28:50,740 --> 00:28:56,560
And these output neurons
respect each other's territory.

643
00:28:56,560 --> 00:28:59,980
Here is the 16
compartments where they do.

644
00:28:59,980 --> 00:29:02,750
And then they're very well
organized in another way.

645
00:29:02,750 --> 00:29:04,240
You notice these colors here.

646
00:29:04,240 --> 00:29:06,130
These colors refer
to the transmitter

647
00:29:06,130 --> 00:29:07,480
of the output neuron.

648
00:29:07,480 --> 00:29:09,880
So all the glutamate
guys are over here.

649
00:29:09,880 --> 00:29:11,750
All the GABA guys are down here.

650
00:29:11,750 --> 00:29:14,060
The cholinergic
guys are over here.

651
00:29:14,060 --> 00:29:20,010
Now, again, you get this extreme
order returning to the system.

652
00:29:20,010 --> 00:29:21,990
Here's a theorist's
version of this.

653
00:29:21,990 --> 00:29:25,770
Here are the compartments, the
16 compartments, 5 per lobe,

654
00:29:25,770 --> 00:29:29,190
plus the peduncle, which kind of
belongs to the alpha beta lobe.

655
00:29:29,190 --> 00:29:31,230
Here they are, the
different compartments.

656
00:29:31,230 --> 00:29:35,650
And then here are the output
cells assigned to them.

657
00:29:35,650 --> 00:29:38,470
They're not necessarily
one cell per blob here.

658
00:29:38,470 --> 00:29:40,050
Sometimes there are a few cells.

659
00:29:40,050 --> 00:29:42,220
But basically, those
are the cell types.

660
00:29:42,220 --> 00:29:44,910
And as I mentioned,
they respect--

661
00:29:44,910 --> 00:29:47,430
they only go to one
compartment each.

662
00:29:47,430 --> 00:29:49,200
And then those are
the transmitters,

663
00:29:49,200 --> 00:29:51,300
which in this diagram,
they don't cluster nicely.

664
00:29:51,300 --> 00:29:54,150
But in the other
diagram they do.

665
00:29:54,150 --> 00:29:56,250
Now, you can ask, why
bother to do this?

666
00:29:56,250 --> 00:29:59,280
Because there are
axons going down.

667
00:29:59,280 --> 00:30:02,010
The parallel fibers that
the Kenyon cells make,

668
00:30:02,010 --> 00:30:03,090
they go that way.

669
00:30:03,090 --> 00:30:07,170
So all of these guys have access
to exactly the same input.

670
00:30:07,170 --> 00:30:09,570
So what would it matter
if this guy decided

671
00:30:09,570 --> 00:30:12,697
to send a branch over and pick
up the axon over there instead

672
00:30:12,697 --> 00:30:13,280
of over there?

673
00:30:13,280 --> 00:30:15,190
It would make no
difference at all.

674
00:30:15,190 --> 00:30:16,740
So at this point,
you would sort of

675
00:30:16,740 --> 00:30:19,770
wonder, why are they respecting
these compartments so

676
00:30:19,770 --> 00:30:20,790
faithfully?

677
00:30:20,790 --> 00:30:22,900
And that's answered
in this slide.

678
00:30:22,900 --> 00:30:24,750
So these are the
output neurons, as you

679
00:30:24,750 --> 00:30:28,950
can see, kind of tiling the
thing in these compartments.

680
00:30:28,950 --> 00:30:30,870
And this is a set
of dopamine neurons,

681
00:30:30,870 --> 00:30:34,200
which were also genetically
isolated in this way

682
00:30:34,200 --> 00:30:37,790
and labeled, that target
these compartments.

683
00:30:37,790 --> 00:30:40,360
And you notice the
perfect alignment.

684
00:30:40,360 --> 00:30:43,530
So the reason these guys
are compartmentalized

685
00:30:43,530 --> 00:30:47,970
is so they can be individually
modulated by dopamine.

686
00:30:47,970 --> 00:30:49,660
And you can see that here.

687
00:30:49,660 --> 00:30:52,200
So the dopamine
neurons come, again,

688
00:30:52,200 --> 00:30:55,170
in slightly more
numbers of types.

689
00:30:55,170 --> 00:31:01,050
But they align and exactly
innervate these compartments

690
00:31:01,050 --> 00:31:02,550
without overlap.

691
00:31:02,550 --> 00:31:05,790
So the reason the
beta 2 guy's in here

692
00:31:05,790 --> 00:31:09,370
is so it can be innervated
by these particular dopamine

693
00:31:09,370 --> 00:31:09,870
neurons.

694
00:31:09,870 --> 00:31:13,110
The dopamine neurons are
divided into two classes.

695
00:31:13,110 --> 00:31:15,150
And again, if we go to
the anatomical-- oh,

696
00:31:15,150 --> 00:31:16,020
I should mention.

697
00:31:16,020 --> 00:31:19,240
If you notice, there were some
missing compartments there,

698
00:31:19,240 --> 00:31:21,890
but some of the dopamine
neurons go to 2,

699
00:31:21,890 --> 00:31:24,540
so everybody gets covered.

700
00:31:24,540 --> 00:31:28,170
If you go back to this
anatomical diagram, what

701
00:31:28,170 --> 00:31:32,010
you see is everybody
over here gets

702
00:31:32,010 --> 00:31:35,290
modulated by these, what are
called, PAM dopamine neurons.

703
00:31:35,290 --> 00:31:37,290
And they're associated
with reward.

704
00:31:37,290 --> 00:31:39,690
So when good stuff
happens, you hammer

705
00:31:39,690 --> 00:31:41,650
this part of the mushroom body.

706
00:31:41,650 --> 00:31:44,160
When bad stuff happens,
you hammer this part

707
00:31:44,160 --> 00:31:46,260
of the mushroom body
with a different set

708
00:31:46,260 --> 00:31:49,290
of what are called
PPL1 dopamine neurons.

709
00:31:49,290 --> 00:31:51,810
So again, this
beautiful structure.

710
00:31:51,810 --> 00:31:56,260
All right, so let me finish
elaborating this for you.

711
00:31:56,260 --> 00:31:58,520
This is the basic structure.

712
00:31:58,520 --> 00:32:02,040
Again, I didn't put it on at
first, but some of these guys

713
00:32:02,040 --> 00:32:04,590
actually conduct
two compartments.

714
00:32:04,590 --> 00:32:08,010
So it's not quite
true what I said.

715
00:32:08,010 --> 00:32:12,600
But basically, that's the output
stream from the mushroom body.

716
00:32:12,600 --> 00:32:18,750
And then there is a
layered system put on.

717
00:32:18,750 --> 00:32:21,000
These are the
connections, but I kind of

718
00:32:21,000 --> 00:32:23,580
depicted it down here
more schematically.

719
00:32:23,580 --> 00:32:25,710
What you have in
this output system

720
00:32:25,710 --> 00:32:29,850
is a one layer system down
here, a two layer system,

721
00:32:29,850 --> 00:32:32,470
a three layer system,
and a four layer system.

722
00:32:32,470 --> 00:32:36,170
So the output is actually
a four layer network,

723
00:32:36,170 --> 00:32:37,470
feedforward network.

724
00:32:37,470 --> 00:32:42,150
There's no recurrence
up to this point.

725
00:32:42,150 --> 00:32:44,910
And all of the action occurs
on the alpha beta lobe.

726
00:32:44,910 --> 00:32:47,310
The alpha beta
lobe is responsible

727
00:32:47,310 --> 00:32:48,720
for long-term memories.

728
00:32:48,720 --> 00:32:51,900
You could think of this as
the most sophisticated lobe.

729
00:32:51,900 --> 00:32:54,360
Gamma lobe is more for
short-term memories,

730
00:32:54,360 --> 00:32:55,830
has a simpler readout.

731
00:32:55,830 --> 00:33:00,910
Alpha prime beta prime lobe is,
to me, kind of God knows what.

732
00:33:00,910 --> 00:33:02,370
But probably somebody knows.

733
00:33:02,370 --> 00:33:05,160
Anyway, but it's, again,
a simpler output system.

734
00:33:05,160 --> 00:33:07,267
So it's just a beautiful system.

735
00:33:07,267 --> 00:33:08,850
In part, I'm just
telling you about it

736
00:33:08,850 --> 00:33:10,470
because it's beautiful.

737
00:33:10,470 --> 00:33:12,540
OK, so that's the thing.

738
00:33:12,540 --> 00:33:15,870
And then these outputs
go to various regions.

739
00:33:15,870 --> 00:33:18,160
If you don't know the fly
brain, you don't care.

740
00:33:18,160 --> 00:33:21,120
But what's interesting
is now the loop closes.

741
00:33:21,120 --> 00:33:24,600
So the regions that receive
output from the mushroom body

742
00:33:24,600 --> 00:33:27,960
also provide input to
the dopamine neurons.

743
00:33:27,960 --> 00:33:30,870
So when the mushroom body
acts, the dopamine neurons

744
00:33:30,870 --> 00:33:32,510
know about it.

745
00:33:32,510 --> 00:33:34,740
And when the dopamine
neurons react,

746
00:33:34,740 --> 00:33:36,250
the mushroom body
knows about it.

747
00:33:36,250 --> 00:33:40,500
So you have this closed system
which finally loops together.

748
00:33:40,500 --> 00:33:44,850
And the dopamine system
is a reporter of behavior.

749
00:33:44,850 --> 00:33:47,930
So it tells the mushroom
body what the fly's doing.

750
00:33:47,930 --> 00:33:50,770
Or also internal state,
how the fly's feeling.

751
00:33:50,770 --> 00:33:52,930
I'll show you that in a second.

752
00:33:52,930 --> 00:33:55,565
And then these are going
to be, obviously, some sort

753
00:33:55,565 --> 00:33:58,200
of learned or
modulating responses,

754
00:33:58,200 --> 00:34:00,070
modulated by this system.

755
00:34:00,070 --> 00:34:02,940
You remember that these cannot
have any intrinsic meaning,

756
00:34:02,940 --> 00:34:05,760
because they've gone
through a random stage here.

757
00:34:05,760 --> 00:34:09,420
They cannot be assigned meaning
without some sort of learning

758
00:34:09,420 --> 00:34:10,530
or instruction.

759
00:34:10,530 --> 00:34:12,909
So these are learned outputs.

760
00:34:12,909 --> 00:34:15,530
And so that's the system.

761
00:34:15,530 --> 00:34:19,639
OK, so what does this system do?

762
00:34:19,639 --> 00:34:23,420
One of the nice things
that's happened in parallel

763
00:34:23,420 --> 00:34:26,719
with this anatomical advance
that I've been describing

764
00:34:26,719 --> 00:34:31,460
is a behavioral advance of
what's the mushroom for.

765
00:34:31,460 --> 00:34:33,170
I'll start with the
classic picture.

766
00:34:33,170 --> 00:34:35,389
Mushroom body has been
studied for a long, long time.

767
00:34:35,389 --> 00:34:37,370
That quote was from 1850.

768
00:34:37,370 --> 00:34:40,460
And it's mostly been studied
as a classical conditioning

769
00:34:40,460 --> 00:34:42,380
system, memory system.

770
00:34:42,380 --> 00:34:44,690
You train a fly to
be afraid of an odor

771
00:34:44,690 --> 00:34:47,659
or to be attracted to an
odor through a classical

772
00:34:47,659 --> 00:34:48,920
conditioning experiment.

773
00:34:48,920 --> 00:34:52,909
And here's a nice,
recent version

774
00:34:52,909 --> 00:34:54,870
of that that's
quite instructive.

775
00:34:54,870 --> 00:34:56,630
So in this experiment,
what you do is

776
00:34:56,630 --> 00:35:00,950
you put one odor in the end of
a chamber, a very small chamber

777
00:35:00,950 --> 00:35:01,970
that holds a fly.

778
00:35:01,970 --> 00:35:03,367
One odor comes in one end.

779
00:35:03,367 --> 00:35:04,700
One odor comes in the other end.

780
00:35:04,700 --> 00:35:06,690
You pump it out in the middle.

781
00:35:06,690 --> 00:35:08,000
And then you track the fly.

782
00:35:08,000 --> 00:35:10,860
Flies pace back and forth.

783
00:35:10,860 --> 00:35:13,010
And so the fly paces
back and forth.

784
00:35:13,010 --> 00:35:15,650
But frequently, if it
doesn't like odor B,

785
00:35:15,650 --> 00:35:18,930
it might come to this central
region, say, oh, that's odor B,

786
00:35:18,930 --> 00:35:20,510
turn around and go back.

787
00:35:20,510 --> 00:35:23,150
And so what you do is
count electronically

788
00:35:23,150 --> 00:35:27,080
how many times the fly
crosses these boundaries.

789
00:35:27,080 --> 00:35:29,210
And you can get a
measure of its preference

790
00:35:29,210 --> 00:35:31,470
for being in the A
end or the B end.

791
00:35:31,470 --> 00:35:36,230
And this is experiments done in
Gero Miesenboeck's laboratory.

792
00:35:36,230 --> 00:35:39,440
Now, what you can do then is--

793
00:35:39,440 --> 00:35:42,140
in the first set of
experiments that I'll show you,

794
00:35:42,140 --> 00:35:44,360
they just look at
the innate preference

795
00:35:44,360 --> 00:35:47,280
of the fly for an odor,
without any training.

796
00:35:47,280 --> 00:35:50,550
That's due to the lateral
horn, as you'll see.

797
00:35:50,550 --> 00:35:53,000
But then you can associate
one of the odors,

798
00:35:53,000 --> 00:35:54,740
for example, with
an electric shock.

799
00:35:54,740 --> 00:35:57,740
And presumably, the fly
is going to then associate

800
00:35:57,740 --> 00:36:00,140
that odor with
danger and avoid it.

801
00:36:00,140 --> 00:36:01,560
So here's the data.

802
00:36:01,560 --> 00:36:03,680
No, first I guess I
built a little model.

803
00:36:03,680 --> 00:36:06,690
So it's been long suspected
how this could work.

804
00:36:06,690 --> 00:36:08,010
This is quite easy.

805
00:36:08,010 --> 00:36:10,047
You have-- there are
the Kenyon cells.

806
00:36:10,047 --> 00:36:11,630
Here's a mushroom
body, output neuron.

807
00:36:11,630 --> 00:36:13,040
Here's a dopamine neuron.

808
00:36:13,040 --> 00:36:16,980
So an odor comes along-- that's
the conditioned stimulus--

809
00:36:16,980 --> 00:36:19,430
activates some Kenyon cells.

810
00:36:19,430 --> 00:36:22,970
Then the unconditioned stimulus
comes along, the shock.

811
00:36:22,970 --> 00:36:25,640
That activates the
dopamine neuron.

812
00:36:25,640 --> 00:36:29,180
And where you have activity
plus dopamine, for example,

813
00:36:29,180 --> 00:36:30,745
you strengthen the synapses.

814
00:36:30,745 --> 00:36:32,120
There's evidence
that it actually

815
00:36:32,120 --> 00:36:34,910
might work by weakening the
synapses, but for this diagram,

816
00:36:34,910 --> 00:36:37,250
I strengthen the synapses, OK?

817
00:36:37,250 --> 00:36:41,720
Then, later on, when
the odor comes along,

818
00:36:41,720 --> 00:36:43,372
it activates the same set.

819
00:36:43,372 --> 00:36:45,080
Now you have these
strengthened synapses.

820
00:36:45,080 --> 00:36:47,570
You activate the mushroom
body output neuron

821
00:36:47,570 --> 00:36:49,350
and you send an alarm signal.

822
00:36:49,350 --> 00:36:53,230
So that's just classical
conditioning with this system.

823
00:36:53,230 --> 00:36:55,410
And here are the data
showing it works.

824
00:36:55,410 --> 00:36:57,770
So first of all, this is
the innate preference.

825
00:36:57,770 --> 00:36:59,360
What's interesting--
the reason I

826
00:36:59,360 --> 00:37:01,520
included this
later experiment is

827
00:37:01,520 --> 00:37:04,340
because they looked at the
innate preference as well

828
00:37:04,340 --> 00:37:05,750
as the learned preference.

829
00:37:05,750 --> 00:37:08,690
So this is just
showing you that this

830
00:37:08,690 --> 00:37:13,820
is the distance between the
PN activity for these odors.

831
00:37:13,820 --> 00:37:16,280
So this is a measure of
the discriminability.

832
00:37:16,280 --> 00:37:20,000
And they sort of argue
that these odors which

833
00:37:20,000 --> 00:37:23,210
have a zero
preference maybe can't

834
00:37:23,210 --> 00:37:24,560
be distinguished by the fly.

835
00:37:24,560 --> 00:37:26,540
You don't know that,
but any rate, zero

836
00:37:26,540 --> 00:37:29,280
means they're equally
likely to go to both ends.

837
00:37:29,280 --> 00:37:30,920
So these odors, they don't care.

838
00:37:30,920 --> 00:37:33,930
But when the odors
are quite different,

839
00:37:33,930 --> 00:37:36,530
they can have a fairly
strong preference

840
00:37:36,530 --> 00:37:39,630
for one odor over the other.

841
00:37:39,630 --> 00:37:42,890
Now you train, and
suddenly you have

842
00:37:42,890 --> 00:37:46,850
a strong preference or a strong
avoidance, a preference for one

843
00:37:46,850 --> 00:37:50,000
over the one that was
associated with shock.

844
00:37:50,000 --> 00:37:52,160
And now what they
did was genetically--

845
00:37:52,160 --> 00:37:54,860
I mentioned that we
now have genetic access

846
00:37:54,860 --> 00:37:55,880
to all these cells.

847
00:37:55,880 --> 00:37:58,790
One of the things you can do
is block synaptic transmission

848
00:37:58,790 --> 00:38:00,230
from all the Kenyon cells.

849
00:38:00,230 --> 00:38:03,520
So you just wipe out the
output of the mushroom body.

850
00:38:03,520 --> 00:38:06,560
That's done by raising the
temperature of these flies.

851
00:38:06,560 --> 00:38:10,500
And suddenly, they go right
back to their innate preferences

852
00:38:10,500 --> 00:38:12,290
as if they'd never
learned something.

853
00:38:12,290 --> 00:38:14,510
But they still can
sense the odor.

854
00:38:14,510 --> 00:38:16,190
They still have their
innate preference,

855
00:38:16,190 --> 00:38:18,542
almost identical to
what it was before.

856
00:38:18,542 --> 00:38:19,250
But they've lost.

857
00:38:19,250 --> 00:38:21,350
Now, if you cool
down these flies,

858
00:38:21,350 --> 00:38:24,700
they'll pop back up to there.

859
00:38:24,700 --> 00:38:29,030
OK, that's classical
conditioning.

860
00:38:29,030 --> 00:38:31,550
Oh, I know what I was
going to mention here.

861
00:38:31,550 --> 00:38:34,490
Not in these experiments,
but in other experiments,

862
00:38:34,490 --> 00:38:36,710
you can replace
the electric shock

863
00:38:36,710 --> 00:38:38,570
by an activation of
the dopamine neuron.

864
00:38:38,570 --> 00:38:43,730
So you can show that these
avoidance type dopamine

865
00:38:43,730 --> 00:38:47,720
neurons really do convey the
avoidance message, because you

866
00:38:47,720 --> 00:38:50,990
can train them to avoid
odor B when all they got

867
00:38:50,990 --> 00:38:54,920
was an activation, let's say
an optogenetic activation

868
00:38:54,920 --> 00:38:56,060
of a dopamine neuron.

869
00:38:56,060 --> 00:38:58,350
That's been done tons now.

870
00:38:58,350 --> 00:39:00,790
OK, so here's another example.

871
00:39:00,790 --> 00:39:05,570
As I said, I think the classic
literature on the fly is that.

872
00:39:05,570 --> 00:39:09,170
It's classical conditioning
studied in zillions of ways,

873
00:39:09,170 --> 00:39:11,940
looking at the molecular
basis, et cetera, et cetera.

874
00:39:11,940 --> 00:39:14,820
But here's some
more newer results.

875
00:39:14,820 --> 00:39:19,050
Here's one from Daisuke
Hattori in Richard's lab.

876
00:39:19,050 --> 00:39:21,630
It involves this alpha
prime 3 lobe, just

877
00:39:21,630 --> 00:39:23,060
to show you what it is.

878
00:39:23,060 --> 00:39:25,490
And it has the
following features.

879
00:39:25,490 --> 00:39:27,590
So it's a little
hard to see, maybe,

880
00:39:27,590 --> 00:39:30,850
but this is a pulse that
shows that the odor, which

881
00:39:30,850 --> 00:39:35,150
is MCH here, the odor
has been introduced.

882
00:39:35,150 --> 00:39:39,890
And here is the response of this
alpha prime 3 output neuron.

883
00:39:39,890 --> 00:39:41,600
So there you're
seeing a response.

884
00:39:41,600 --> 00:39:45,050
And if you look across time,
that response fades away.

885
00:39:45,050 --> 00:39:47,240
It even starts to reverse maybe.

886
00:39:47,240 --> 00:39:49,820
So there's an adaptation
of this response.

887
00:39:49,820 --> 00:39:51,300
You say, big deal.

888
00:39:51,300 --> 00:39:53,300
But this adaptation
is definitely

889
00:39:53,300 --> 00:39:55,670
occurring at the output
of the mushroom body.

890
00:39:55,670 --> 00:39:57,650
The Kenyon cells
are not adapting.

891
00:39:57,650 --> 00:39:59,840
It's due to the dopamine,
because if you block

892
00:39:59,840 --> 00:40:01,340
the dopamine you don't get it.

893
00:40:01,340 --> 00:40:04,700
So this is dopamine
specific adaptation.

894
00:40:04,700 --> 00:40:07,850
But what's more interesting
about it is shown here,

895
00:40:07,850 --> 00:40:11,680
that if you take an odor
response to MCH, adapt it

896
00:40:11,680 --> 00:40:15,350
away, but then
present a new odor,

897
00:40:15,350 --> 00:40:19,610
benzaldehyde, now you
get a response again.

898
00:40:19,610 --> 00:40:23,600
Then you can adapt the way the
response of the benzaldehyde

899
00:40:23,600 --> 00:40:25,670
and introduce a third
order, you get a thing.

900
00:40:25,670 --> 00:40:29,280
So this is an
odor-dependent adaptation,

901
00:40:29,280 --> 00:40:33,170
which really suggests that
the dopamine is specifically

902
00:40:33,170 --> 00:40:36,440
weakening the synapses
that are active at the time

903
00:40:36,440 --> 00:40:37,670
of the dopamine response.

904
00:40:37,670 --> 00:40:39,980
So it's like the
classical conditioned,

905
00:40:39,980 --> 00:40:42,620
but there's no
conditioning here.

906
00:40:42,620 --> 00:40:47,610
Furthermore, when you adapt
one odor and then another,

907
00:40:47,610 --> 00:40:49,310
the first order remains adapted.

908
00:40:49,310 --> 00:40:51,920
So I sort of see this system--

909
00:40:51,920 --> 00:40:54,200
I've always had trouble
with the classical condition

910
00:40:54,200 --> 00:40:56,060
experiments, imagining
where would a fly

911
00:40:56,060 --> 00:40:58,370
get into a situation
where it smells an odor

912
00:40:58,370 --> 00:41:00,640
and gets a shock, or
something like that?

913
00:41:00,640 --> 00:41:03,300
But this, you can immediately
see, would be very useful.

914
00:41:03,300 --> 00:41:06,170
You could adapt
to an environment

915
00:41:06,170 --> 00:41:08,060
that has a whole set of odors.

916
00:41:08,060 --> 00:41:10,400
And then if you come
back to that environment

917
00:41:10,400 --> 00:41:12,110
and there's a new
odor present, you'll

918
00:41:12,110 --> 00:41:13,970
immediately know it,
because this neuron

919
00:41:13,970 --> 00:41:15,230
is going to respond.

920
00:41:15,230 --> 00:41:17,870
Whereas if you come back to
the identical environment,

921
00:41:17,870 --> 00:41:21,630
or without new odors,
this won't respond.

922
00:41:21,630 --> 00:41:27,230
So this is a neuron to
identify unexpected olfactory

923
00:41:27,230 --> 00:41:28,420
features of an environment.

924
00:41:28,420 --> 00:41:31,350
Or it's one thing it could do.

925
00:41:31,350 --> 00:41:36,180
OK, I think I just repeated that
because I wanted to say that.

926
00:41:36,180 --> 00:41:37,370
Here's another example.

927
00:41:37,370 --> 00:41:42,350
This comes from Raphael
Cohn and Vanessa Ruta's lab.

928
00:41:42,350 --> 00:41:47,180
And this is really the
effect of internal state.

929
00:41:47,180 --> 00:41:50,180
So I argued for you that
these dopamine neurons

930
00:41:50,180 --> 00:41:52,860
were reflecting the internal
state of the animal.

931
00:41:52,860 --> 00:41:55,380
And they have a very
beautiful experiment on that.

932
00:41:55,380 --> 00:41:57,110
So these are the gamma.

933
00:41:57,110 --> 00:41:59,270
I guess I didn't say
before, but these

934
00:41:59,270 --> 00:42:01,849
are the gamma 2 through
gamma 5 compartments

935
00:42:01,849 --> 00:42:03,140
that we're going to talk about.

936
00:42:03,140 --> 00:42:05,240
What they did was to
image the dopamine

937
00:42:05,240 --> 00:42:08,840
neurons in those compartments,
gamma 2, 3, 4, and 5,

938
00:42:08,840 --> 00:42:11,240
and observed that
when the fly is--

939
00:42:11,240 --> 00:42:13,550
the fly is in an
uncomfortable position,

940
00:42:13,550 --> 00:42:15,040
to put it mildly here.

941
00:42:15,040 --> 00:42:18,270
It's glued to something,
I don't know what.

942
00:42:18,270 --> 00:42:19,570
And there's a hole in its head.

943
00:42:19,570 --> 00:42:22,070
Other than that,
everything's fine.

944
00:42:22,070 --> 00:42:24,050
So it's an unhappy fly.

945
00:42:24,050 --> 00:42:27,650
You might want to speculate
that this is an unhappy fly.

946
00:42:27,650 --> 00:42:29,810
And what they observed
is while the fly is

947
00:42:29,810 --> 00:42:33,860
flailing about and unhappily
expressing its unhappiness,

948
00:42:33,860 --> 00:42:37,910
these gamma 2 and
gamma 3 compartments

949
00:42:37,910 --> 00:42:39,590
have dopamine input.

950
00:42:39,590 --> 00:42:41,527
And the gamma 4
and gamma 5 don't.

951
00:42:41,527 --> 00:42:43,610
But they also observed
that every once in a while,

952
00:42:43,610 --> 00:42:48,020
the fly just chills out,
hangs there, like, oh Christ.

953
00:42:48,020 --> 00:42:51,740
And when that happens,
it reverses the pattern.

954
00:42:51,740 --> 00:42:54,150
Now these are not
dopamine activated

955
00:42:54,150 --> 00:42:56,120
and these ones are
dopamine modulated.

956
00:42:56,120 --> 00:42:59,730
Although this is not
unequivocal happiness.

957
00:42:59,730 --> 00:43:02,660
This is mixed.

958
00:43:02,660 --> 00:43:04,290
But then they
started manipulating.

959
00:43:04,290 --> 00:43:06,770
So here, you take one
of these unhappy flies,

960
00:43:06,770 --> 00:43:10,130
you give it some sugar, it
becomes a happy fly, right?

961
00:43:10,130 --> 00:43:12,530
Remember, the red over
here, this is a happy fly.

962
00:43:12,530 --> 00:43:15,320
This is a sad fly,
because they shocked it.

963
00:43:15,320 --> 00:43:19,530
So it's clear that this
thing is really reading a--

964
00:43:19,530 --> 00:43:22,250
they'll be a little fanciful--
but happy fly, sad fly.

965
00:43:22,250 --> 00:43:24,530
You could take a look at
these compartments and say,

966
00:43:24,530 --> 00:43:29,510
that is one unhappy
fly, or one happy fly.

967
00:43:29,510 --> 00:43:32,060
Furthermore, now, so that
means the internal state

968
00:43:32,060 --> 00:43:33,770
is being represented here.

969
00:43:33,770 --> 00:43:36,032
But in addition,
it has an effect.

970
00:43:36,032 --> 00:43:37,490
So this is an
experiment where they

971
00:43:37,490 --> 00:43:45,330
imaged the output term, the
dendrites of the output neuron.

972
00:43:45,330 --> 00:43:47,900
So they're looking at
transmission from the Kenyon

973
00:43:47,900 --> 00:43:49,280
cell to the output neuron.

974
00:43:49,280 --> 00:43:50,570
They present an odor.

975
00:43:50,570 --> 00:43:54,270
And they activate the
dopamine neuron themselves.

976
00:43:54,270 --> 00:43:56,630
So when they don't activate
the dopamine neuron,

977
00:43:56,630 --> 00:43:58,990
this is a measure of
synaptic transmission.

978
00:43:58,990 --> 00:44:01,660
The odor response here is weak.

979
00:44:01,660 --> 00:44:04,070
When they do, it
gets much stronger.

980
00:44:04,070 --> 00:44:05,890
So now what you
have is something--

981
00:44:05,890 --> 00:44:09,630
I mean, I think if I saw
this in cortex, I'd go wild--

982
00:44:09,630 --> 00:44:12,820
is a gating effect.

983
00:44:12,820 --> 00:44:15,640
You have internal state
affecting the thing of this,

984
00:44:15,640 --> 00:44:18,670
and it determines
where the output goes.

985
00:44:18,670 --> 00:44:20,475
So for example, if you're--

986
00:44:20,475 --> 00:44:22,100
I can never remember
which one's happy.

987
00:44:22,100 --> 00:44:23,440
This is happy, right?

988
00:44:23,440 --> 00:44:27,130
So if you're happy, then
odors go to one thing, which

989
00:44:27,130 --> 00:44:31,270
might say, approach that order.

990
00:44:31,270 --> 00:44:33,550
You know, be sort of a
little more easy going.

991
00:44:33,550 --> 00:44:38,590
If you're unhappy, then an
odor response gets relayed out

992
00:44:38,590 --> 00:44:39,920
this pathway.

993
00:44:39,920 --> 00:44:42,040
And it might tell you to
be afraid of all odors,

994
00:44:42,040 --> 00:44:42,998
or something like that.

995
00:44:42,998 --> 00:44:44,030
Be very cautious.

996
00:44:44,030 --> 00:44:46,540
So you start to
see in this system

997
00:44:46,540 --> 00:44:50,010
the routing of sensory
information by internal states.

998
00:44:50,010 --> 00:44:53,750
That, to me, is a very
exciting thing to see.

999
00:44:53,750 --> 00:44:56,890
OK, here's another one--
internal state affects memory.

1000
00:44:56,890 --> 00:45:01,750
This is from Tanimoto, another
collaboration with the Janelia

1001
00:45:01,750 --> 00:45:02,530
lab.

1002
00:45:02,530 --> 00:45:05,320
So you can do the same
kind of experiment

1003
00:45:05,320 --> 00:45:08,320
I showed you before with
shock, only do it with sweet.

1004
00:45:08,320 --> 00:45:10,630
So in this case, it's a T maze.

1005
00:45:10,630 --> 00:45:12,790
A fly comes in this way.

1006
00:45:12,790 --> 00:45:18,200
And you associate, let's say,
odor A with a sweet reward.

1007
00:45:18,200 --> 00:45:21,010
Then the fly is going to come
in here and most of the time

1008
00:45:21,010 --> 00:45:21,550
go this way.

1009
00:45:21,550 --> 00:45:25,090
Flies are never 100%
performers, but they'll

1010
00:45:25,090 --> 00:45:28,410
tend to go to odor A because
they associate that with sweet,

1011
00:45:28,410 --> 00:45:29,410
provided they're hungry.

1012
00:45:29,410 --> 00:45:31,320
I'll come back to
the hungry part.

1013
00:45:31,320 --> 00:45:33,785
So you take a hungry
fly, it goes this way.

1014
00:45:33,785 --> 00:45:35,660
Now, here's what they
did that's very clever.

1015
00:45:35,660 --> 00:45:40,210
It involves these PAM
neurons, PAM dopamine neurons.

1016
00:45:40,210 --> 00:45:46,360
So as you all know, you get
the hit of sugar in your mouth

1017
00:45:46,360 --> 00:45:47,140
right away.

1018
00:45:47,140 --> 00:45:49,140
And then you get
nutritional value,

1019
00:45:49,140 --> 00:45:51,130
or you get fat or
whatever later.

1020
00:45:51,130 --> 00:45:55,540
And the decoupling of those
causes us a lot of problems.

1021
00:45:55,540 --> 00:45:57,950
So you see that here
in this system very,

1022
00:45:57,950 --> 00:46:02,080
very well, because they take
a sugar that's sweet tasting

1023
00:46:02,080 --> 00:46:05,380
to the fly but can't be digested
by the fly, that provides

1024
00:46:05,380 --> 00:46:07,780
no nutritional value at all.

1025
00:46:07,780 --> 00:46:09,970
And when they do that--

1026
00:46:09,970 --> 00:46:11,890
so there's no nutrition
in this sugar--

1027
00:46:11,890 --> 00:46:16,360
what they get is a short-term
attraction to that odor,

1028
00:46:16,360 --> 00:46:18,790
enough to buy the
next Coke, sort of.

1029
00:46:18,790 --> 00:46:20,950
It's conveyed
through octopamine,

1030
00:46:20,950 --> 00:46:23,260
so the sweetness
activates octopamine.

1031
00:46:23,260 --> 00:46:27,370
Octopamine activates a certain
set of these PAM neurons.

1032
00:46:27,370 --> 00:46:31,210
That makes changes
in the transmission

1033
00:46:31,210 --> 00:46:32,500
in various compartments.

1034
00:46:32,500 --> 00:46:35,020
This is not isolated to
a unique compartment.

1035
00:46:35,020 --> 00:46:38,660
Then the next time that odor
comes on, it goes out here

1036
00:46:38,660 --> 00:46:40,160
and it gives you attraction.

1037
00:46:40,160 --> 00:46:43,570
But it's a short-term
attraction, lasts a few hours.

1038
00:46:43,570 --> 00:46:47,800
Now, if you make the
sugar nutritious--

1039
00:46:47,800 --> 00:46:52,840
and they do this in a clever way
by using another sugar that has

1040
00:46:52,840 --> 00:46:55,900
no taste to the fly but
that the fly can digest,

1041
00:46:55,900 --> 00:46:57,670
so now this nutritious--

1042
00:46:57,670 --> 00:47:01,090
then it activates a fructose
receptor, blah, blah, blah,

1043
00:47:01,090 --> 00:47:04,450
activates a different
set of dopamine neurons.

1044
00:47:04,450 --> 00:47:07,940
That potentiates or depresses--
we don't actually know--

1045
00:47:07,940 --> 00:47:10,180
but it changes synapses
in the alpha 1 lobe.

1046
00:47:10,180 --> 00:47:12,170
And now you get a
long-term memory.

1047
00:47:12,170 --> 00:47:14,560
So flies are smarter
than people in a way.

1048
00:47:14,560 --> 00:47:17,060
They'll only do this
long-term memory

1049
00:47:17,060 --> 00:47:20,290
if they then also sense
a nutritional benefit

1050
00:47:20,290 --> 00:47:23,680
to whatever they're eating.

1051
00:47:23,680 --> 00:47:25,529
OK, so very elegant thing.

1052
00:47:25,529 --> 00:47:27,320
And then I think this
is my final example--

1053
00:47:27,320 --> 00:47:28,750
I'll start winding up--

1054
00:47:28,750 --> 00:47:32,890
from Scott Waddell's
lab, that another feature

1055
00:47:32,890 --> 00:47:35,170
of this sweet thing is
if the fly's not hungry,

1056
00:47:35,170 --> 00:47:37,510
not surprisingly, it
doesn't care anymore.

1057
00:47:37,510 --> 00:47:42,070
So it's associated odor A with
sweet, but now it's well-fed,

1058
00:47:42,070 --> 00:47:43,480
so who cares.

1059
00:47:43,480 --> 00:47:45,250
And that's a real effect.

1060
00:47:45,250 --> 00:47:50,470
So a fed fly will not
express this odor preference.

1061
00:47:50,470 --> 00:47:53,320
But it still has the memory,
because if you then starve it,

1062
00:47:53,320 --> 00:47:56,362
now it will go to odor A.

1063
00:47:56,362 --> 00:48:01,090
OK, So what Scott Waddell
and his group realized

1064
00:48:01,090 --> 00:48:04,690
was that this was activated
through this dopamine neuron.

1065
00:48:04,690 --> 00:48:08,519
Now, this was done before all
this circuitry was derived.

1066
00:48:08,519 --> 00:48:10,810
But they figured it out that
it's this dopamine neuron,

1067
00:48:10,810 --> 00:48:13,090
because they could activate
this dopamine neuron

1068
00:48:13,090 --> 00:48:18,070
and simulate the fed state, so
the fly would ignore the odor.

1069
00:48:18,070 --> 00:48:20,320
Or they could silence
this dopamine neuron

1070
00:48:20,320 --> 00:48:22,340
and then they would
simulate the hungry state

1071
00:48:22,340 --> 00:48:24,670
and the fly would be
attracted to the odor.

1072
00:48:24,670 --> 00:48:27,330
But now, you notice
this circuitry,

1073
00:48:27,330 --> 00:48:30,370
this is a GABAergic
neuron that inhibits

1074
00:48:30,370 --> 00:48:32,590
the alpha beta lobe output.

1075
00:48:32,590 --> 00:48:34,960
So this is a perfect
pathway by which

1076
00:48:34,960 --> 00:48:39,430
you could turn off the learned
response in this during the fed

1077
00:48:39,430 --> 00:48:40,270
state.

1078
00:48:40,270 --> 00:48:42,880
And then you inactivate
this pathway,

1079
00:48:42,880 --> 00:48:43,960
and now you turn it on.

1080
00:48:43,960 --> 00:48:47,330
So again, an internal
state gating a memory.

1081
00:48:47,330 --> 00:48:48,400
But it's a case--

1082
00:48:48,400 --> 00:48:51,820
we don't really know that
everything I'm saying is true.

1083
00:48:51,820 --> 00:48:54,730
One should never assume that.

1084
00:48:54,730 --> 00:48:58,560
But we now have this pathway.

1085
00:48:58,560 --> 00:49:03,850
People-- we, I say, but people,
we can block this pathway.

1086
00:49:03,850 --> 00:49:06,400
There's enough known about the
circuitry to really work out

1087
00:49:06,400 --> 00:49:08,280
that what I said is
true, that you can

1088
00:49:08,280 --> 00:49:10,650
start to get at these things.

1089
00:49:10,650 --> 00:49:14,430
So one-- yeah, I got a
minute to do CO2 avoidance.

1090
00:49:14,430 --> 00:49:16,620
CO2 avoidance is
a really cool one.

1091
00:49:16,620 --> 00:49:22,475
So CO2 is innately
repulsive to a fly.

1092
00:49:22,475 --> 00:49:23,820
It doesn't like CO2.

1093
00:49:23,820 --> 00:49:25,470
And the reason that
is is in a group

1094
00:49:25,470 --> 00:49:28,920
of flies that are stressed,
they release a lot of CO2.

1095
00:49:28,920 --> 00:49:32,580
So a fly will sense CO2, know
there's trouble in the area,

1096
00:49:32,580 --> 00:49:33,840
and will avoid it.

1097
00:49:33,840 --> 00:49:38,040
So there's a natural avoidance
through the innate pathway

1098
00:49:38,040 --> 00:49:39,120
to CO2.

1099
00:49:39,120 --> 00:49:42,360
Now, that's kind of a fatal
flaw in the design of the fly,

1100
00:49:42,360 --> 00:49:47,280
because flies eat rotting fruit
that releases tons of CO2.

1101
00:49:47,280 --> 00:49:50,190
So you don't want to
avoid your food source.

1102
00:49:50,190 --> 00:49:53,340
So what happens-- it's
not completely understood.

1103
00:49:53,340 --> 00:49:58,920
But somehow, the innate system
trains this beta 2 pathway

1104
00:49:58,920 --> 00:50:02,550
to have, in addition to the
innate pathway, a learned

1105
00:50:02,550 --> 00:50:05,240
pathway for CO2 avoidance.

1106
00:50:05,240 --> 00:50:08,625
And in the hungry state,
the fly channels its CO2--

1107
00:50:08,625 --> 00:50:10,320
it still has CO2 avoidance.

1108
00:50:10,320 --> 00:50:14,040
It channels it
through this pathway.

1109
00:50:14,040 --> 00:50:18,150
Then if, at the same time,
there are fruit odors or fruit

1110
00:50:18,150 --> 00:50:21,120
tastes, it can
modulate this pathway,

1111
00:50:21,120 --> 00:50:24,690
shut it down, and
turn the CO2 avoidance

1112
00:50:24,690 --> 00:50:26,820
into a CO2 attraction.

1113
00:50:26,820 --> 00:50:29,820
So again, you start to
see the neural substrates

1114
00:50:29,820 --> 00:50:33,390
of these really quite complex
behaviors sitting right

1115
00:50:33,390 --> 00:50:36,270
before you in this structure.

1116
00:50:36,270 --> 00:50:40,070
All right, I'll
end here with sort

1117
00:50:40,070 --> 00:50:43,200
of the lesson for
the machine learners.

1118
00:50:43,200 --> 00:50:44,980
So from a machine
learning perspective,

1119
00:50:44,980 --> 00:50:46,260
this is a simple system.

1120
00:50:46,260 --> 00:50:47,310
It's not very deep.

1121
00:50:47,310 --> 00:50:50,430
It's a little bit deep,
but not very deep.

1122
00:50:50,430 --> 00:50:54,210
It contains a random
hidden representation.

1123
00:50:54,210 --> 00:50:57,300
That's not really
anything radical.

1124
00:50:57,300 --> 00:50:59,940
It contains a set
of output neurons.

1125
00:50:59,940 --> 00:51:01,290
It's actually a layered output.

1126
00:51:01,290 --> 00:51:03,870
Again, nothing very radical.

1127
00:51:03,870 --> 00:51:06,255
In neuroscience term,
it's kind of interesting

1128
00:51:06,255 --> 00:51:09,570
that it goes from these highly
stereotyped to random to highly

1129
00:51:09,570 --> 00:51:11,190
stereotyped.

1130
00:51:11,190 --> 00:51:14,250
But really, the
lesson here is this

1131
00:51:14,250 --> 00:51:17,850
is a mediocre machine
learning architecture.

1132
00:51:17,850 --> 00:51:20,250
Not very many
units and all that.

1133
00:51:20,250 --> 00:51:22,180
Where does this
thing make up for it?

1134
00:51:22,180 --> 00:51:24,510
It makes up for it
in a stupendous,

1135
00:51:24,510 --> 00:51:29,490
complicated modulation and
plasticity beyond any machine

1136
00:51:29,490 --> 00:51:31,260
learner's dreams.

1137
00:51:31,260 --> 00:51:32,610
We don't know about this.

1138
00:51:32,610 --> 00:51:35,310
I tried to give you hints of
the different things it can do.

1139
00:51:35,310 --> 00:51:36,780
Dopamine can gate.

1140
00:51:36,780 --> 00:51:38,460
It can induce
short-term learning.

1141
00:51:38,460 --> 00:51:40,290
It can induce
long-term learning.

1142
00:51:40,290 --> 00:51:44,620
It can induce gating of
gating, gating of learning.

1143
00:51:44,620 --> 00:51:47,040
That's what has to be
worked out in this system.

1144
00:51:47,040 --> 00:51:51,210
But there's going to be a really
beautiful effect of dopamine

1145
00:51:51,210 --> 00:51:54,390
acting in many ways
on many time scales.

1146
00:51:54,390 --> 00:51:57,360
And to me, in this
system, that's

1147
00:51:57,360 --> 00:52:00,120
where evolution has put
its money, right there.

1148
00:52:00,120 --> 00:52:04,560
Not in building 20 layers
here or something like that.

1149
00:52:04,560 --> 00:52:07,050
Not in worrying about a
whole lot of back prop.

1150
00:52:07,050 --> 00:52:08,160
This is random.

1151
00:52:08,160 --> 00:52:11,250
It doesn't appear
to be back propped.

1152
00:52:11,250 --> 00:52:17,670
But in putting huge resources
into a rich set of modulatory

1153
00:52:17,670 --> 00:52:21,390
and plastic processes at
these output synapses.

1154
00:52:21,390 --> 00:52:24,390
And I think in the years to
come, they will be worked out.

1155
00:52:24,390 --> 00:52:26,880
And maybe they'll
have implications

1156
00:52:26,880 --> 00:52:30,470
for machine learning once
we know what they are.