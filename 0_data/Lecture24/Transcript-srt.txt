1
00:00:16,020 --> 00:00:20,820
MICHALE FEE: OK, so we're going
to start a new topic today.

2
00:00:20,820 --> 00:00:22,860
We're going to
spend the next three

3
00:00:22,860 --> 00:00:26,520
or so lectures talking
about spectral analysis.

4
00:00:26,520 --> 00:00:28,860
And we're going to
warm up to that topic

5
00:00:28,860 --> 00:00:34,230
today by talking about
time series more generally.

6
00:00:34,230 --> 00:00:36,290
Now, one of the
things that we're

7
00:00:36,290 --> 00:00:39,755
going to discuss in the
context of this new topic--

8
00:00:39,755 --> 00:00:42,980
so I'm going to spend
a few minutes reviewing

9
00:00:42,980 --> 00:00:45,320
a little bit about
receptive fields

10
00:00:45,320 --> 00:00:49,260
that we've talked about
in the last lecture.

11
00:00:49,260 --> 00:00:51,680
And one of the
really cool things

12
00:00:51,680 --> 00:00:57,950
that I find in developing
tools for analyzing data

13
00:00:57,950 --> 00:01:00,680
is that there's a really
big sense in which, when

14
00:01:00,680 --> 00:01:02,630
we developed tools
to analyze data,

15
00:01:02,630 --> 00:01:06,530
we're actually developing
tools that kind of look

16
00:01:06,530 --> 00:01:07,850
like what the brain does.

17
00:01:10,550 --> 00:01:15,410
So our brains basically learn
to analyze sensory stimuli

18
00:01:15,410 --> 00:01:19,010
and extract information
from those sensory stimuli.

19
00:01:19,010 --> 00:01:22,130
And so when we think
about developing tools

20
00:01:22,130 --> 00:01:25,610
for analyzing data, we
take a lot of inspiration

21
00:01:25,610 --> 00:01:29,840
from how neurons and
brain circuits actually

22
00:01:29,840 --> 00:01:31,670
do the same thing.

23
00:01:31,670 --> 00:01:35,150
And a lot of the
sort of formulation

24
00:01:35,150 --> 00:01:39,170
that we've developed for
understanding how neurons

25
00:01:39,170 --> 00:01:42,410
respond to sensory
inputs has a lot

26
00:01:42,410 --> 00:01:48,440
of similarity to the kind of
things we do to analyze data.

27
00:01:48,440 --> 00:01:53,210
All right, so a brief review
of mathematical models

28
00:01:53,210 --> 00:01:56,880
of receptive fields--
so the basic,

29
00:01:56,880 --> 00:01:59,670
most common model for thinking
about how neurons respond

30
00:01:59,670 --> 00:02:02,940
to sensory stimuli is the
linear/non-linear model.

31
00:02:02,940 --> 00:02:04,440
And again, the basic
idea is that we

32
00:02:04,440 --> 00:02:06,540
have a sensory stimulus.

33
00:02:06,540 --> 00:02:10,650
In this case, this is the
intensity of a visual field.

34
00:02:10,650 --> 00:02:14,670
So it's intensity as a
function of position x and y--

35
00:02:14,670 --> 00:02:17,580
let's say on the
screen or on a retina.

36
00:02:17,580 --> 00:02:20,940
Then that stimulus
goes through a filter.

37
00:02:20,940 --> 00:02:24,480
And the filter is
basically a pattern

38
00:02:24,480 --> 00:02:28,830
of sensitivity of the
neuron to the sensory input.

39
00:02:28,830 --> 00:02:32,010
And so in this case, I've
represented this filter

40
00:02:32,010 --> 00:02:37,740
as a filter that's
sensitive to a ring of light

41
00:02:37,740 --> 00:02:40,790
around a center of darkness.

42
00:02:40,790 --> 00:02:45,600
So this might be like an
off neuron in the retina.

43
00:02:45,600 --> 00:02:48,870
So that filter acts
on the stimulus.

44
00:02:48,870 --> 00:02:51,300
It filters some aspect
of the stimulus,

45
00:02:51,300 --> 00:02:55,140
and develops a response
to the stimulus.

46
00:02:55,140 --> 00:02:59,370
That response goes to what's
called an output non-linearity,

47
00:02:59,370 --> 00:03:02,910
which typically looks
something like this, where

48
00:03:02,910 --> 00:03:05,400
a very negative
response produces

49
00:03:05,400 --> 00:03:09,120
no spiking of the neuron,
no output of the neuron,

50
00:03:09,120 --> 00:03:13,110
whereas a large overlap of
the stimulus with the filter,

51
00:03:13,110 --> 00:03:16,180
with the receptive field,
produces a large spiking

52
00:03:16,180 --> 00:03:16,680
response.

53
00:03:16,680 --> 00:03:19,380
So a typical way this
would look for a neuron

54
00:03:19,380 --> 00:03:24,840
is that if the filter
response, L, is 0,

55
00:03:24,840 --> 00:03:29,580
the neuron might have some
spontaneous firing rate, r0.

56
00:03:29,580 --> 00:03:32,580
And the firing
rate of the neuron

57
00:03:32,580 --> 00:03:37,620
is modulated linearly around
that spontaneous firing rate r

58
00:03:37,620 --> 00:03:41,340
by an amount proportional to
the response of the filter.

59
00:03:41,340 --> 00:03:44,190
And then obviously if the
response of the filter

60
00:03:44,190 --> 00:03:46,800
is very negative,
then the firing rate

61
00:03:46,800 --> 00:03:49,560
of the neuron at
some point reaches 0.

62
00:03:49,560 --> 00:03:53,873
And if the r0 plus
L goes below 0,

63
00:03:53,873 --> 00:03:55,290
then the firing
rate of the neuron

64
00:03:55,290 --> 00:03:57,330
can obviously not go negative.

65
00:03:57,330 --> 00:03:59,400
And so the firing
rate of the neuron

66
00:03:59,400 --> 00:04:03,980
will just kind of sit at
that floor of 0 firing rate.

67
00:04:03,980 --> 00:04:06,840
All right, so that
is a response-- that

68
00:04:06,840 --> 00:04:09,480
is an output non-linearity.

69
00:04:09,480 --> 00:04:17,459
And then most neurons fire
sort of randomly, at a rate

70
00:04:17,459 --> 00:04:19,709
corresponding to
this firing rate

71
00:04:19,709 --> 00:04:24,060
that is the output of
this output nonlinearity.

72
00:04:24,060 --> 00:04:27,030
And so what happens is a
neuron generates spikes

73
00:04:27,030 --> 00:04:30,720
probabilistically at
a rate corresponding

74
00:04:30,720 --> 00:04:37,550
to the output of this
non-linear response function.

75
00:04:37,550 --> 00:04:40,140
OK, any questions about that?

76
00:04:40,140 --> 00:04:42,810
All right, so what
we're going to do today

77
00:04:42,810 --> 00:04:46,200
is I'm going to take a
little bit of a detour

78
00:04:46,200 --> 00:04:52,710
and talk about how we
think about the randomness

79
00:04:52,710 --> 00:04:56,790
or the stochasticity of
neuronal firing rates.

80
00:04:56,790 --> 00:05:00,130
OK, and I'll talk about
the Poisson process.

81
00:05:00,130 --> 00:05:04,710
And then we're going
to come back and think

82
00:05:04,710 --> 00:05:08,850
about filters more
generally, and how

83
00:05:08,850 --> 00:05:11,580
we can analyze signals
by applying filters

84
00:05:11,580 --> 00:05:13,950
of different types to them.

85
00:05:13,950 --> 00:05:19,170
OK, so I think this is basically
what we covered last time.

86
00:05:19,170 --> 00:05:22,410
Again, the idea is
that we can think

87
00:05:22,410 --> 00:05:25,650
of the response of a neuron
as a spontaneous firing

88
00:05:25,650 --> 00:05:30,880
rate plus a filter acting
on a stimulus input.

89
00:05:30,880 --> 00:05:33,320
In this case, the filter is
a two-dimensional filter.

90
00:05:33,320 --> 00:05:37,920
So here I'm just fleshing out
what this looks like here,

91
00:05:37,920 --> 00:05:41,460
for the case of a linear
filter in the visual system,

92
00:05:41,460 --> 00:05:43,510
a spatial receptive field.

93
00:05:43,510 --> 00:05:45,990
So G is the spatial
receptive field.

94
00:05:45,990 --> 00:05:49,620
i is the intensity as
a function of position.

95
00:05:49,620 --> 00:05:53,490
And what we do is we multiply
that spatial receptive field

96
00:05:53,490 --> 00:05:57,810
times the stimulus,
and integrate over all

97
00:05:57,810 --> 00:06:00,180
the spatial dimensions x and y.

98
00:06:00,180 --> 00:06:03,030
In one dimension, we would
have a spatial receptive field

99
00:06:03,030 --> 00:06:04,020
that looks like this.

100
00:06:04,020 --> 00:06:09,000
So this receptive
field is sensitive

101
00:06:09,000 --> 00:06:12,420
to a positive brightness
in the center,

102
00:06:12,420 --> 00:06:21,310
and a negative or a dark
feature in the surrounding area.

103
00:06:21,310 --> 00:06:23,790
And again, the way
we think about this

104
00:06:23,790 --> 00:06:27,030
is that the neuron is
maximally responsive

105
00:06:27,030 --> 00:06:31,980
if the pattern of sensory
input looks like the receptive

106
00:06:31,980 --> 00:06:35,470
field, is highly correlated
with the receptive field.

107
00:06:35,470 --> 00:06:38,790
So if the receptive field
has a positive central region

108
00:06:38,790 --> 00:06:41,400
surrounded by negative
flanks, then that neuron

109
00:06:41,400 --> 00:06:44,640
is maximally responsive
if the pattern of light

110
00:06:44,640 --> 00:06:46,960
looks like the receptive field.

111
00:06:46,960 --> 00:06:50,460
So if the light pattern has
a bright spot surrounded

112
00:06:50,460 --> 00:06:56,050
by dark flanking
regions, then we

113
00:06:56,050 --> 00:06:59,230
calculate this
integral, what you find

114
00:06:59,230 --> 00:07:02,110
is that the positive parts--

115
00:07:02,110 --> 00:07:06,970
the positive receptive field
times the positive intensity

116
00:07:06,970 --> 00:07:10,660
or brightness multiplies to
give you a positive contribution

117
00:07:10,660 --> 00:07:12,520
to the neuronal response.

118
00:07:12,520 --> 00:07:15,850
A negative component
of the receptive field

119
00:07:15,850 --> 00:07:19,870
multiplies by a negative
component of the intensity.

120
00:07:19,870 --> 00:07:22,890
And that gives you a positive
contribution to the response.

121
00:07:22,890 --> 00:07:25,900
And so you can see that even
though the receptive field has

122
00:07:25,900 --> 00:07:28,060
positive and negative
parts, so does

123
00:07:28,060 --> 00:07:31,448
the intensity function have
positive and negative parts.

124
00:07:31,448 --> 00:07:32,990
And when you multiply
those together,

125
00:07:32,990 --> 00:07:36,160
you get a positive contribution
to the response of the neuron

126
00:07:36,160 --> 00:07:36,770
everywhere.

127
00:07:36,770 --> 00:07:40,610
And so when you integrate
that, you get a big response.

128
00:07:40,610 --> 00:07:44,840
In contrast, if the intensity
profile looked like this--

129
00:07:44,840 --> 00:07:45,920
it's very broad.

130
00:07:45,920 --> 00:07:50,540
So this looks like a bright
spot surrounded by a dark ring.

131
00:07:50,540 --> 00:07:53,840
If, on the other hand, you
have a large bright spot that

132
00:07:53,840 --> 00:07:56,600
completely overlaps
this receptive field,

133
00:07:56,600 --> 00:07:59,030
then when you multiply these
two functions together,

134
00:07:59,030 --> 00:08:02,270
this positive times positive
will give you a positive here.

135
00:08:02,270 --> 00:08:05,090
But the negative part
of the receptive field

136
00:08:05,090 --> 00:08:07,820
overlaps with a positive
part of the intensity.

137
00:08:07,820 --> 00:08:09,710
And that gives you a
negative contribution

138
00:08:09,710 --> 00:08:11,210
to the neuronal response.

139
00:08:11,210 --> 00:08:13,880
And when you integrate
that, the positive here

140
00:08:13,880 --> 00:08:15,890
is canceled by the
negative there,

141
00:08:15,890 --> 00:08:18,680
and you get a small response.

142
00:08:18,680 --> 00:08:21,600
All right, any
questions about that?

143
00:08:21,600 --> 00:08:24,880
I think we covered that in
a lot of detail last time.

144
00:08:24,880 --> 00:08:27,830
But again, the
important point here

145
00:08:27,830 --> 00:08:33,409
is that this neuron is
looking for a particular kind

146
00:08:33,409 --> 00:08:35,900
of pattern in the sensory input.

147
00:08:35,900 --> 00:08:39,530
And it responds when the
sensory input has that pattern.

148
00:08:43,700 --> 00:08:46,460
It doesn't respond as well
when the sensory input has

149
00:08:46,460 --> 00:08:47,330
a different pattern.

150
00:08:53,900 --> 00:08:57,350
And we have the same
kind of situation

151
00:08:57,350 --> 00:09:02,430
for the sensitivity of
neurons to temporal patterns.

152
00:09:02,430 --> 00:09:04,850
So we can write down the
firing rate of a neuron

153
00:09:04,850 --> 00:09:06,600
as a function of time.

154
00:09:06,600 --> 00:09:12,980
It's just a spontaneous firing
rate plus a filter acting

155
00:09:12,980 --> 00:09:14,910
on a time-dependent stimulus.

156
00:09:14,910 --> 00:09:18,350
So in this case, this
filter will be looking for

157
00:09:18,350 --> 00:09:22,070
or sensitive to a
particular temporal pattern.

158
00:09:22,070 --> 00:09:25,380
And as you recall, if we have
a time-dependent stimulus--

159
00:09:25,380 --> 00:09:29,120
let's say this is the
intensity of a spot of light,

160
00:09:29,120 --> 00:09:30,980
that you can have
a neuron that's

161
00:09:30,980 --> 00:09:33,480
responsive to a particular
temporal pattern.

162
00:09:33,480 --> 00:09:36,710
Let's say a brief darkening
of the stimulus followed

163
00:09:36,710 --> 00:09:41,780
by a pulse of bright
high intensity,

164
00:09:41,780 --> 00:09:46,220
and then the neuron
response after it sees

165
00:09:46,220 --> 00:09:48,260
that pattern in the stimulus.

166
00:09:48,260 --> 00:09:52,460
And the way we think
about this mathematically

167
00:09:52,460 --> 00:09:54,980
is that what's happening
is that the stimulus

168
00:09:54,980 --> 00:10:00,200
is being convolved with
this linear temporal kernel.

169
00:10:00,200 --> 00:10:03,110
And the way we think about
that is that the kernel

170
00:10:03,110 --> 00:10:05,360
is sliding across the stimulus.

171
00:10:05,360 --> 00:10:07,760
We're doing that
same kind of overlap.

172
00:10:07,760 --> 00:10:11,210
We're multiplying the
stimulus times the kernel,

173
00:10:11,210 --> 00:10:13,430
integrating over
time, and asking,

174
00:10:13,430 --> 00:10:17,270
where in time does the
stimulus have a strong overlap

175
00:10:17,270 --> 00:10:17,960
with the kernel?

176
00:10:17,960 --> 00:10:19,830
And you can see
that in this case,

177
00:10:19,830 --> 00:10:21,470
there's a strong
overlap at this point.

178
00:10:21,470 --> 00:10:26,090
The stimulus looks
like the kernel.

179
00:10:26,090 --> 00:10:27,800
The positive parts
of the stimulus

180
00:10:27,800 --> 00:10:30,110
overlap with positive
parts of the kernel.

181
00:10:30,110 --> 00:10:32,887
Negative parts of the stimulus
overlap with negative parts

182
00:10:32,887 --> 00:10:33,470
of the kernel.

183
00:10:33,470 --> 00:10:35,730
So when you multiply
that all together,

184
00:10:35,730 --> 00:10:38,640
you get a big positive response.

185
00:10:38,640 --> 00:10:42,710
And if you actually slide that
across and do that integral

186
00:10:42,710 --> 00:10:46,190
as a function of time, you can
see that this convolution has

187
00:10:46,190 --> 00:10:49,680
a peak at the point where
that kernel overlaps

188
00:10:49,680 --> 00:10:50,430
with the stimulus.

189
00:10:50,430 --> 00:10:52,250
And right there is
where the neuron

190
00:10:52,250 --> 00:10:54,350
would tend to produce a spike.

191
00:10:56,880 --> 00:11:01,090
All right, and so, I think near
the end of the last lecture,

192
00:11:01,090 --> 00:11:04,690
we talked about integrating
or putting together

193
00:11:04,690 --> 00:11:13,000
the spatial and temporal
parts of a receptive field

194
00:11:13,000 --> 00:11:18,280
into sort of a larger concept
of a spatio-temporal receptive

195
00:11:18,280 --> 00:11:23,950
field that combines both spatial
and temporal information.

196
00:11:27,140 --> 00:11:30,290
All right, so here
are the things

197
00:11:30,290 --> 00:11:33,270
that we're going to
talk about today.

198
00:11:33,270 --> 00:11:36,950
We're going to again, take
a little bit of a detour,

199
00:11:36,950 --> 00:11:39,050
and talk about spike
trains being probabilistic.

200
00:11:39,050 --> 00:11:41,450
We'll talk about a
Poisson process, which

201
00:11:41,450 --> 00:11:45,710
is the kind of random process
that most people think

202
00:11:45,710 --> 00:11:49,370
about when you talk about
spike trains of neurons.

203
00:11:49,370 --> 00:11:53,480
We're going to develop a couple
of measures of spike train

204
00:11:53,480 --> 00:11:54,170
variability.

205
00:11:54,170 --> 00:11:57,680
So an important thing
that neuroscientists often

206
00:11:57,680 --> 00:11:59,510
think about when you
measure spike trains

207
00:11:59,510 --> 00:12:03,050
is how variable are they,
how reproducible are they

208
00:12:03,050 --> 00:12:05,690
in responding to a stimulus.

209
00:12:05,690 --> 00:12:09,200
And a number of different
statistical measures

210
00:12:09,200 --> 00:12:12,680
have been developed to
quantify spike trains.

211
00:12:12,680 --> 00:12:14,930
And we're just going to
describe those briefly.

212
00:12:14,930 --> 00:12:16,820
And I think you'll
have a problem set

213
00:12:16,820 --> 00:12:19,200
problem that deals with those.

214
00:12:19,200 --> 00:12:24,370
And then I'm going to come
back to kind of a broader

215
00:12:24,370 --> 00:12:26,730
discussion of convolution.

216
00:12:26,730 --> 00:12:31,120
I'll introduce two
new metrics or methods

217
00:12:31,120 --> 00:12:39,080
for analyzing time series data,
data that's a function of time.

218
00:12:39,080 --> 00:12:42,490
Those are cross-correlation
and autocorrelation functions.

219
00:12:42,490 --> 00:12:45,070
And I'm going to relate
those to the convolution

220
00:12:45,070 --> 00:12:48,960
that you've been
using more often

221
00:12:48,960 --> 00:12:51,730
and we've been seeing in class.

222
00:12:51,730 --> 00:12:55,240
And then finally we're
going to jump right

223
00:12:55,240 --> 00:13:01,210
into spectral analysis
of time series, which

224
00:13:01,210 --> 00:13:06,100
is a way of pulling out
periodic signals from data.

225
00:13:06,100 --> 00:13:11,740
And what you're going to see is
that that method of pulling out

226
00:13:11,740 --> 00:13:14,890
temporal structure
out of signals

227
00:13:14,890 --> 00:13:17,500
looks a lot like the
way we've been talking

228
00:13:17,500 --> 00:13:19,990
about how neurons
have sensitivity

229
00:13:19,990 --> 00:13:23,300
to temporal
structure in signals.

230
00:13:23,300 --> 00:13:27,280
OK, we're going to use that
same idea of taking a signal

231
00:13:27,280 --> 00:13:30,280
and asking how much
does it overlap

232
00:13:30,280 --> 00:13:36,908
with a linear kernel
with a filter.

233
00:13:36,908 --> 00:13:38,950
And we're going to talk
about the kind of filters

234
00:13:38,950 --> 00:13:44,020
you use to detect periodic
structure and signal.

235
00:13:44,020 --> 00:13:48,340
And not surprisingly, those are
going to be periodic filters.

236
00:13:48,340 --> 00:13:52,010
All right so that's what we're
going to talk about today.

237
00:13:52,010 --> 00:13:55,690
All right, so let's start with
probabilistic spike trains.

238
00:13:55,690 --> 00:13:59,740
So the first thing
that you discover

239
00:13:59,740 --> 00:14:02,050
when you record from
neurons in the brain

240
00:14:02,050 --> 00:14:06,670
and you present a
stimulus to the animal--

241
00:14:06,670 --> 00:14:09,700
let's say you record from
neurons in visual cortex

242
00:14:09,700 --> 00:14:11,740
or auditory cortex,
and you present

243
00:14:11,740 --> 00:14:14,590
a stimulus for some period
of time, what you find

244
00:14:14,590 --> 00:14:16,330
is that the neurons respond.

245
00:14:16,330 --> 00:14:18,700
They respond with some
temporal structure.

246
00:14:18,700 --> 00:14:21,100
But each time you
present the stimulus,

247
00:14:21,100 --> 00:14:23,380
the response of the neuron
is a little bit different.

248
00:14:23,380 --> 00:14:26,320
So you can see that this--
so what I'm showing here

249
00:14:26,320 --> 00:14:30,570
is a raster plot.

250
00:14:30,570 --> 00:14:34,660
So each row of this shows
the spiking activity

251
00:14:34,660 --> 00:14:40,410
of a neuron during a
presentation of this stimulus.

252
00:14:40,410 --> 00:14:46,770
The stimulus is a bunch of
dots presented that move

253
00:14:46,770 --> 00:14:47,970
across the screen.

254
00:14:47,970 --> 00:14:52,500
And this is a part of the brain
that sensitive to movement

255
00:14:52,500 --> 00:14:55,590
of visual stimuli.

256
00:14:55,590 --> 00:15:00,600
And what you can see is
that each time the stimulus

257
00:15:00,600 --> 00:15:04,500
is presented, the
neuron generates spikes.

258
00:15:04,500 --> 00:15:07,510
Each row here is a different
presentation of the stimulus.

259
00:15:07,510 --> 00:15:10,240
If you average across
all of those rows,

260
00:15:10,240 --> 00:15:13,650
you can see that there is
some repeatable structure.

261
00:15:13,650 --> 00:15:20,480
So the neuron tends to spike
most often at certain times

262
00:15:20,480 --> 00:15:24,000
after the presentation
of this stimulus.

263
00:15:24,000 --> 00:15:26,940
But each time the
stimulus is presented,

264
00:15:26,940 --> 00:15:29,790
the spikes don't occur in
exactly the same place.

265
00:15:29,790 --> 00:15:33,740
So you have this sense that
when you present the stimulus,

266
00:15:33,740 --> 00:15:37,940
there is some sort of underlying
modulation of the firing

267
00:15:37,940 --> 00:15:40,610
rate of the neuron.

268
00:15:40,610 --> 00:15:44,390
But the response isn't
exactly the same each time.

269
00:15:44,390 --> 00:15:48,480
There's some
randomness about it.

270
00:15:48,480 --> 00:15:51,300
So we're going to talk a little
bit about how you characterize

271
00:15:51,300 --> 00:15:53,010
that randomness.

272
00:15:53,010 --> 00:16:01,430
And the way that most people
think about the random spiking

273
00:16:01,430 --> 00:16:04,250
of neurons is that there is a--

274
00:16:04,250 --> 00:16:04,970
sorry about that.

275
00:16:04,970 --> 00:16:08,090
That mu was supposed
to be up there.

276
00:16:08,090 --> 00:16:11,150
So let's go to a very
simple case, where

277
00:16:11,150 --> 00:16:12,920
we turn on a stimulus.

278
00:16:12,920 --> 00:16:17,270
And instead of having a
kind of a time-varying rate,

279
00:16:17,270 --> 00:16:20,510
let's imagine that the
stimulus just comes on,

280
00:16:20,510 --> 00:16:26,800
and the neuron starts to spike
at a constant average rate.

281
00:16:26,800 --> 00:16:29,830
And let's call that
average rate mu.

282
00:16:29,830 --> 00:16:30,790
So what does that mean?

283
00:16:33,710 --> 00:16:35,530
What that means is
that if you were

284
00:16:35,530 --> 00:16:38,950
to present this stimulus
many, many times

285
00:16:38,950 --> 00:16:41,110
and look at where
the spikes occur,

286
00:16:41,110 --> 00:16:44,410
there would be some uniform
probability per unit of time

287
00:16:44,410 --> 00:16:48,580
that spikes would occur
anywhere under that stimulus

288
00:16:48,580 --> 00:16:51,350
during the presentation
of that stimulus.

289
00:16:51,350 --> 00:16:55,710
So let's break
that time window up

290
00:16:55,710 --> 00:16:57,450
during the presentation
of the stimulus

291
00:16:57,450 --> 00:17:04,430
into little tiny
bins, delta-T. Now,

292
00:17:04,430 --> 00:17:08,960
if these spikes occur
randomly, then they're

293
00:17:08,960 --> 00:17:14,290
generated independently
of any other spikes,

294
00:17:14,290 --> 00:17:16,470
with an equal
probability in each bin.

295
00:17:20,140 --> 00:17:23,390
And what that means is that
if the bins are small enough,

296
00:17:23,390 --> 00:17:27,250
most of the bins will
have zero spikes.

297
00:17:27,250 --> 00:17:28,990
And you can write
down the probability

298
00:17:28,990 --> 00:17:34,420
that a spike occurs in any one
bin is the number of spikes

299
00:17:34,420 --> 00:17:38,350
per unit time, which is
the average firing rate,

300
00:17:38,350 --> 00:17:44,150
times the width of
that bin in time.

301
00:17:44,150 --> 00:17:45,500
Does that make sense?

302
00:17:45,500 --> 00:17:49,520
The probability that you have a
spike in any one of those very

303
00:17:49,520 --> 00:17:56,110
tiny bins is just going to be
the spikes per unit of time

304
00:17:56,110 --> 00:17:58,930
times the width of
the bin in time.

305
00:18:02,190 --> 00:18:06,660
Now, that's only true if
delta-T is very small.

306
00:18:06,660 --> 00:18:09,870
Because if delta-T
gets big, then you

307
00:18:09,870 --> 00:18:16,460
have some probability that you
could have two or three spikes.

308
00:18:16,460 --> 00:18:20,420
And so this is only
true in the case

309
00:18:20,420 --> 00:18:21,920
where delta-t is very small.

310
00:18:24,920 --> 00:18:26,900
So the probability
that no spikes

311
00:18:26,900 --> 00:18:36,000
occur is 1 minus mu
delta-T. And we can ask,

312
00:18:36,000 --> 00:18:41,840
how many spikes land
in this interval T?

313
00:18:41,840 --> 00:18:47,730
And we're going to call
that probability P. And it's

314
00:18:47,730 --> 00:18:53,900
the probability that n spikes
land in this interval, T.

315
00:18:53,900 --> 00:18:59,960
And we can calculate that
probability as follows.

316
00:18:59,960 --> 00:19:02,260
So that probability
is just the product

317
00:19:02,260 --> 00:19:05,200
of three different things.

318
00:19:05,200 --> 00:19:09,025
It's the probability of
having n bins with a spike.

319
00:19:12,970 --> 00:19:15,580
So that's mu delta-T to the n.

320
00:19:18,260 --> 00:19:28,160
It's n independent events,
with probability mu delta-T,

321
00:19:28,160 --> 00:19:35,000
times the probability of having
M minus n beans with no spike.

322
00:19:35,000 --> 00:19:39,380
So that's 1 minus mu
delta-T to the M minus n.

323
00:19:42,450 --> 00:19:47,010
And we also have to multiply
by the number of different ways

324
00:19:47,010 --> 00:19:51,510
that you can distribute
those n spikes in M bins.

325
00:19:51,510 --> 00:19:56,360
And that's called M choose n.

326
00:19:56,360 --> 00:19:57,238
Yes.

327
00:19:57,238 --> 00:19:58,867
AUDIENCE: So when
we pick delta-T,

328
00:19:58,867 --> 00:20:00,450
we still have to
pick it big enough so

329
00:20:00,450 --> 00:20:04,830
that it's not less than how
long the [INAUDIBLE],, right?

330
00:20:04,830 --> 00:20:06,080
Because you can't have--

331
00:20:06,080 --> 00:20:07,890
MICHALE FEE: Yeah,
so, OK, good question.

332
00:20:07,890 --> 00:20:11,190
So just to clarify, we're
kind of imagining that spikes

333
00:20:11,190 --> 00:20:13,650
are delta functions now.

334
00:20:13,650 --> 00:20:18,210
So we are-- so in
this case, we're

335
00:20:18,210 --> 00:20:21,750
imagining that spikes
are not like produced

336
00:20:21,750 --> 00:20:25,980
by influx of sodium and
an outflux of potassium,

337
00:20:25,980 --> 00:20:29,010
and it takes a millisecond.

338
00:20:29,010 --> 00:20:33,520
In general, spikes are, let's
say, a millisecond across.

339
00:20:33,520 --> 00:20:35,430
And we're usually
thinking of these bins

340
00:20:35,430 --> 00:20:38,010
as kind of approaching
about a millisecond.

341
00:20:38,010 --> 00:20:40,470
But if you-- what
we're about to do,

342
00:20:40,470 --> 00:20:44,982
actually, is take the limit
where delta-T goes to 0.

343
00:20:44,982 --> 00:20:46,440
And in that case,
you have to think

344
00:20:46,440 --> 00:20:48,460
of the spikes as
delta functions.

345
00:20:51,210 --> 00:20:54,270
OK, so the probability
that you have

346
00:20:54,270 --> 00:20:58,720
n spikes in this
interval, T, is just

347
00:20:58,720 --> 00:21:00,420
the product of those things.

348
00:21:00,420 --> 00:21:03,660
It's the probability
of having n bins

349
00:21:03,660 --> 00:21:06,600
with a spike times the
number of different ways

350
00:21:06,600 --> 00:21:10,200
that you can put n
spikes into M bins.

351
00:21:10,200 --> 00:21:12,630
So you multiply those
things together,

352
00:21:12,630 --> 00:21:16,380
and you take the limit
that delta-T goes to 0.

353
00:21:16,380 --> 00:21:21,990
And it's kind of a
cute little derivation.

354
00:21:21,990 --> 00:21:26,130
I've put the full
derivation at the end

355
00:21:26,130 --> 00:21:29,730
so that we don't have to
go through it in class.

356
00:21:29,730 --> 00:21:33,000
But it's kind of fun
to look at anyway.

357
00:21:33,000 --> 00:21:39,030
And what you find is that in the
limit, that delta-T goes to 0.

358
00:21:39,030 --> 00:21:42,990
Of course as delta-T goes
to 0, the number of bins

359
00:21:42,990 --> 00:21:43,920
goes to infinity.

360
00:21:43,920 --> 00:21:46,965
Because the number of
bins is just capital

361
00:21:46,965 --> 00:21:50,070
T divided by delta-T.

362
00:21:50,070 --> 00:21:53,010
So you can go through
each of those terms

363
00:21:53,010 --> 00:21:55,470
and calculate what happens
to them in the limit

364
00:21:55,470 --> 00:21:57,330
that delta-T goes to 0.

365
00:21:57,330 --> 00:21:59,430
And what you find is
that the probability

366
00:21:59,430 --> 00:22:02,190
of having n spikes
in that window

367
00:22:02,190 --> 00:22:06,930
T just like mu T to the n.

368
00:22:06,930 --> 00:22:08,190
What is mu T?

369
00:22:08,190 --> 00:22:12,670
mu T is the expected number
of spikes in that interval.

370
00:22:12,670 --> 00:22:15,750
It's just the number of
spikes per unit time,

371
00:22:15,750 --> 00:22:24,410
times the length of the
window divided by n factorial,

372
00:22:24,410 --> 00:22:29,540
times e to the minus
mu T. And again, mu T

373
00:22:29,540 --> 00:22:32,660
is the expected
number of spikes.

374
00:22:32,660 --> 00:22:37,280
And that is the
Poisson distribution.

375
00:22:37,280 --> 00:22:41,480
And it comes from a very
simple assumption, which

376
00:22:41,480 --> 00:22:46,550
is just that spikes occur.

377
00:22:46,550 --> 00:22:51,170
The spikes occur
independently of each other,

378
00:22:51,170 --> 00:22:58,130
at a rate mu spikes per second,
with some constant probability

379
00:22:58,130 --> 00:23:01,790
per unit time of having a
spike in each little time bin.

380
00:23:07,380 --> 00:23:11,010
Now notice that if
you have a rate--

381
00:23:11,010 --> 00:23:13,890
there's some tiny probability
per unit of time of having

382
00:23:13,890 --> 00:23:16,470
a spike there, probability
of having a spike there,

383
00:23:16,470 --> 00:23:19,750
probability of having a
spike there, and so on--

384
00:23:19,750 --> 00:23:24,880
you're going to end up sometimes
with one spike in the window,

385
00:23:24,880 --> 00:23:27,950
sometimes with two spikes,
sometimes with three,

386
00:23:27,950 --> 00:23:30,850
sometimes four, sometimes five.

387
00:23:30,850 --> 00:23:33,310
If this window's
really short, you're

388
00:23:33,310 --> 00:23:39,070
going to have more cases where
you have zero or one spikes.

389
00:23:39,070 --> 00:23:42,190
If this window is
really long, then it's

390
00:23:42,190 --> 00:23:46,030
going to be pretty rare to
have just 0 or 1 spikes.

391
00:23:46,030 --> 00:23:49,300
And you're going to end
up with, on average,

392
00:23:49,300 --> 00:23:51,760
20 spikes, let's say.

393
00:23:51,760 --> 00:23:55,740
So you could see that, first
of all, the number of spikes

394
00:23:55,740 --> 00:23:59,100
you get is random.

395
00:23:59,100 --> 00:24:02,270
And it depends on the
size of the window.

396
00:24:02,270 --> 00:24:04,300
And the average number
of bikes you get

397
00:24:04,300 --> 00:24:05,920
depends on the
size of the window

398
00:24:05,920 --> 00:24:08,360
and the average firing
rate of the neuron.

399
00:24:08,360 --> 00:24:12,190
OK, so let's just take a look
at what this function looks

400
00:24:12,190 --> 00:24:18,680
like for different
expected spike counts.

401
00:24:18,680 --> 00:24:22,230
So here's what that looks like.

402
00:24:22,230 --> 00:24:26,210
So we can calculate the
expected number of spikes.

403
00:24:26,210 --> 00:24:29,780
And just to convince you, if
we calculate the average number

404
00:24:29,780 --> 00:24:32,930
of spikes using
that distribution,

405
00:24:32,930 --> 00:24:37,990
we just sum, over all
possible number of spikes,

406
00:24:37,990 --> 00:24:41,320
n times the probability
of having n spikes.

407
00:24:41,320 --> 00:24:43,120
And when you do
that, what you find

408
00:24:43,120 --> 00:24:49,570
is that the average
number is mu times T.

409
00:24:49,570 --> 00:24:57,460
So you can see that the
firing rate, mu, is just

410
00:24:57,460 --> 00:24:59,890
the expected number
of spikes divided

411
00:24:59,890 --> 00:25:01,630
by the width of the window.

412
00:25:01,630 --> 00:25:03,830
Does that make sense?

413
00:25:03,830 --> 00:25:04,780
That's pretty obvious.

414
00:25:04,780 --> 00:25:07,000
That's just the spike rate.

415
00:25:07,000 --> 00:25:10,820
And we're going to often
use the variable r for that,

416
00:25:10,820 --> 00:25:12,990
for firing rate.

417
00:25:12,990 --> 00:25:14,230
OK.

418
00:25:14,230 --> 00:25:17,490
And here's what that looks like.

419
00:25:17,490 --> 00:25:20,900
You can see that if the
firing rate is low enough

420
00:25:20,900 --> 00:25:27,250
or the window is short enough,
such that the expected number

421
00:25:27,250 --> 00:25:31,840
of spikes is 1, you can
see that, most of the time,

422
00:25:31,840 --> 00:25:34,360
you're going to
get 0 or 1 spikes,

423
00:25:34,360 --> 00:25:37,390
and then occasionally 2,
and very occasionally 3,

424
00:25:37,390 --> 00:25:42,580
and then almost never
more than 4 or 5.

425
00:25:42,580 --> 00:25:45,540
If the expected
number of spikes is 4,

426
00:25:45,540 --> 00:25:48,400
you can see that the
mode of that-- you

427
00:25:48,400 --> 00:25:50,830
can see that that distribution
moves to the right.

428
00:25:50,830 --> 00:25:56,170
You have a higher probability
of getting 3 or 4 spikes.

429
00:25:56,170 --> 00:25:58,480
But again, there's
still a distribution.

430
00:25:58,480 --> 00:26:01,210
So even if the average
number of spikes is 4,

431
00:26:01,210 --> 00:26:04,510
you have quite a wide range
of actual spike counts

432
00:26:04,510 --> 00:26:08,630
that you would get
on any given trial.

433
00:26:08,630 --> 00:26:11,300
As the expected number of
spikes gets bigger-- let's say,

434
00:26:11,300 --> 00:26:13,840
on average, 10--

435
00:26:13,840 --> 00:26:16,030
does anyone know what
this distribution

436
00:26:16,030 --> 00:26:17,838
starts turning into?

437
00:26:17,838 --> 00:26:18,630
AUDIENCE: Gaussian.

438
00:26:18,630 --> 00:26:20,400
MICHALE FEE: Gaussian, good.

439
00:26:20,400 --> 00:26:22,110
So what you can see
is that you end up

440
00:26:22,110 --> 00:26:26,040
having a more symmetric
distribution, where the peak is

441
00:26:26,040 --> 00:26:30,010
sitting at the expected number.

442
00:26:30,010 --> 00:26:33,100
In that case, the distribution
becomes more symmetric,

443
00:26:33,100 --> 00:26:38,520
and in the limit of infinite
expected number of spikes,

444
00:26:38,520 --> 00:26:41,158
becomes exactly a
Gaussian distribution.

445
00:26:45,460 --> 00:26:47,650
All right, there
are two measures

446
00:26:47,650 --> 00:26:51,220
that we use to characterize
how variable spike trains are.

447
00:26:51,220 --> 00:26:54,450
Le me just go through
them real quick.

448
00:26:54,450 --> 00:26:56,440
And we'll describe--
and I'll describe to you

449
00:26:56,440 --> 00:27:03,100
what we expect those to look
like for spike trains that

450
00:27:03,100 --> 00:27:06,015
have a Poisson distribution.

451
00:27:06,015 --> 00:27:07,390
So the first thing
we can look at

452
00:27:07,390 --> 00:27:09,400
is the variance in
the spike count.

453
00:27:09,400 --> 00:27:11,590
So remember, for
a Poisson process,

454
00:27:11,590 --> 00:27:13,810
the average number of
spikes in the interval

455
00:27:13,810 --> 00:27:18,620
is mu times T. We can calculate
the variance in that, which

456
00:27:18,620 --> 00:27:23,300
is basically just some
measure of the width

457
00:27:23,300 --> 00:27:27,050
of this distribution here.

458
00:27:27,050 --> 00:27:31,270
So the variance
is just the number

459
00:27:31,270 --> 00:27:39,970
of counts on a given trial minus
the expected number, squared.

460
00:27:39,970 --> 00:27:44,080
n minus average and, squared.

461
00:27:44,080 --> 00:27:46,450
And if you multiply
that out, you get--

462
00:27:46,450 --> 00:27:51,730
it's the average n squared
minus the average squared.

463
00:27:51,730 --> 00:27:55,120
And it turns out, for
the Poisson process,

464
00:27:55,120 --> 00:28:00,840
that that variance is also
mu T. So the variance is--

465
00:28:00,840 --> 00:28:03,870
the average spike count
is mu T, and the variance

466
00:28:03,870 --> 00:28:10,820
in the spike count is also mu T.

467
00:28:10,820 --> 00:28:16,940
So there is a quantity called
the Fano factor, which is just

468
00:28:16,940 --> 00:28:20,240
defined as the variance
of the spike count divided

469
00:28:20,240 --> 00:28:21,870
by the average spike count.

470
00:28:21,870 --> 00:28:27,590
And for a Poisson process,
the Fano factor is 1.

471
00:28:27,590 --> 00:28:31,400
And what you find is that
for neurons in cortex

472
00:28:31,400 --> 00:28:35,210
and other parts of the brain,
the Fano factor actually

473
00:28:35,210 --> 00:28:37,970
can be quite close to one.

474
00:28:37,970 --> 00:28:42,860
It's usually between
1 and 1 and 1/2 or so.

475
00:28:42,860 --> 00:28:49,040
So there's been a lot of
discussion and interest

476
00:28:49,040 --> 00:28:53,120
in why it is that spike
counts in the brain

477
00:28:53,120 --> 00:29:00,410
are actually so random, why do
neurons behave in such a way

478
00:29:00,410 --> 00:29:04,220
that their spikes occur
essentially randomly

479
00:29:04,220 --> 00:29:07,480
at some rate.

480
00:29:07,480 --> 00:29:14,560
So it's a interesting topic
of current research interest.

481
00:29:14,560 --> 00:29:17,860
OK, let me tell you about
one other measure, called

482
00:29:17,860 --> 00:29:20,650
the interspike
interval distribution.

483
00:29:20,650 --> 00:29:23,080
And basically the inner
spike interval distribution

484
00:29:23,080 --> 00:29:27,292
is the distribution of
times between spikes.

485
00:29:27,292 --> 00:29:28,750
And I'm just going
to show you what

486
00:29:28,750 --> 00:29:30,890
that looks like in
the Poisson process,

487
00:29:30,890 --> 00:29:33,040
and then briefly
describe what that

488
00:29:33,040 --> 00:29:34,280
looks like for real neurons.

489
00:29:37,070 --> 00:29:39,060
OK, so let's say
we have a spike.

490
00:29:41,820 --> 00:29:43,900
OK, let's calculate
the distribution

491
00:29:43,900 --> 00:29:45,260
of intervals between spikes.

492
00:29:45,260 --> 00:29:48,960
So let's say we have a
spike at time T-sub-i.

493
00:29:48,960 --> 00:29:52,660
We're going to ask what is
the probability that we have

494
00:29:52,660 --> 00:29:57,280
a spike some time, tau, later--

495
00:29:57,280 --> 00:30:04,180
tau-sub-i later, within
some little window, delta-T.

496
00:30:04,180 --> 00:30:05,630
So let's calculate that.

497
00:30:05,630 --> 00:30:11,020
So tau-sub-i is
initial spike interval

498
00:30:11,020 --> 00:30:17,350
between the i-plus-1
spike and the i-th spike.

499
00:30:17,350 --> 00:30:19,630
So the probability of
having the next spike

500
00:30:19,630 --> 00:30:25,150
land in the interval between
t of i plus 1 and t of i

501
00:30:25,150 --> 00:30:28,000
plus 1 plus delta t in
this little window here

502
00:30:28,000 --> 00:30:29,140
is going to be what?

503
00:30:29,140 --> 00:30:31,960
It's going to be the
probability of having

504
00:30:31,960 --> 00:30:37,390
no spike in this interval,
times the probability of having

505
00:30:37,390 --> 00:30:39,280
a spike in that little interval.

506
00:30:39,280 --> 00:30:40,930
So what's the
probability of having

507
00:30:40,930 --> 00:30:47,890
no spike in that interval, tau?

508
00:30:47,890 --> 00:30:52,540
What distribution can we use
to calculate that probability?

509
00:30:57,480 --> 00:31:02,890
AUDIENCE: [INAUDIBLE]

510
00:31:02,890 --> 00:31:03,640
MICHALE FEE: Yeah.

511
00:31:03,640 --> 00:31:06,170
So what is the
Poisson distribution?

512
00:31:06,170 --> 00:31:10,070
It tells us the
probability of having

513
00:31:10,070 --> 00:31:14,670
n spikes in an
interval T-- capital T.

514
00:31:14,670 --> 00:31:16,950
So how would we use
that to calculate

515
00:31:16,950 --> 00:31:20,818
the probability of having
no spike in that interval?

516
00:31:20,818 --> 00:31:23,125
AUDIENCE: [INAUDIBLE].

517
00:31:23,125 --> 00:31:24,000
MICHALE FEE: Exactly.

518
00:31:24,000 --> 00:31:26,440
We just use the
Poisson distribution,

519
00:31:26,440 --> 00:31:28,920
and plug n equals 0 into it.

520
00:31:28,920 --> 00:31:31,530
So go to that.

521
00:31:31,530 --> 00:31:36,880
There's the Poisson
distribution.

522
00:31:36,880 --> 00:31:39,760
What does this look like
if we set n equals 0?

523
00:31:39,760 --> 00:31:42,592
So what is mu T to the zero?

524
00:31:42,592 --> 00:31:43,980
AUDIENCE: [INAUDIBLE]

525
00:31:43,980 --> 00:31:44,870
MICHALE FEE: 1.

526
00:31:44,870 --> 00:31:47,720
What is 0 factorial?

527
00:31:47,720 --> 00:31:48,570
AUDIENCE: 1.

528
00:31:48,570 --> 00:31:50,240
MICHALE FEE: 1.

529
00:31:50,240 --> 00:31:54,380
And so the probability of
having zero spikes in a window T

530
00:31:54,380 --> 00:31:59,890
is just e to the minus mu T. All
right, so let's plug that in--

531
00:31:59,890 --> 00:32:00,640
good.

532
00:32:00,640 --> 00:32:04,300
So the probability of having
no spikes in that interval

533
00:32:04,300 --> 00:32:10,690
is e to the minus mu T, or rT,
if we're using r for rate now.

534
00:32:13,410 --> 00:32:15,420
Now, what is the
probability of having

535
00:32:15,420 --> 00:32:17,910
a spike in that little
window right there?

536
00:32:25,720 --> 00:32:28,268
Any thoughts?

537
00:32:28,268 --> 00:32:29,977
AUDIENCE: [INAUDIBLE]

538
00:32:29,977 --> 00:32:31,019
MICHALE FEE: What's that?

539
00:32:31,019 --> 00:32:34,830
AUDIENCE: [INAUDIBLE]

540
00:32:34,830 --> 00:32:35,580
MICHALE FEE: Yeah.

541
00:32:35,580 --> 00:32:36,970
You could do that.

542
00:32:36,970 --> 00:32:39,510
But we sort of derive
the Poisson process

543
00:32:39,510 --> 00:32:42,980
by using the answer to
this question already.

544
00:32:42,980 --> 00:32:44,760
AUDIENCE: Oh, r delta.

545
00:32:44,760 --> 00:32:46,890
MICHALE FEE: r delta-T. Good.

546
00:32:46,890 --> 00:32:49,820
OK, so the probability of having
a spike in that little window

547
00:32:49,820 --> 00:32:53,510
is just r delta-T. OK.

548
00:32:53,510 --> 00:32:54,010
Yes.

549
00:32:54,010 --> 00:32:55,718
AUDIENCE: Stupid
question-- I just missed

550
00:32:55,718 --> 00:32:57,790
the transition between u and r.

551
00:32:57,790 --> 00:32:59,260
MICHALE FEE: Yeah,
I just changed

552
00:32:59,260 --> 00:33:01,190
the name of the variable.

553
00:33:01,190 --> 00:33:03,110
If you look in the
statistics literature,

554
00:33:03,110 --> 00:33:05,680
they most often use mu.

555
00:33:05,680 --> 00:33:07,960
But when we're talking about
prime rates of neurons,

556
00:33:07,960 --> 00:33:12,100
it's more convenient to use R.
And so they're just the same.

557
00:33:15,376 --> 00:33:17,250
AUDIENCE: [INAUDIBLE]

558
00:33:17,250 --> 00:33:18,360
MICHALE FEE: Yes.

559
00:33:18,360 --> 00:33:19,170
AUDIENCE: Are we
talking the probability

560
00:33:19,170 --> 00:33:21,290
of having the next five
commands [INAUDIBLE]

561
00:33:21,290 --> 00:33:24,480
given that there was no
spike at the first interval?

562
00:33:24,480 --> 00:33:26,640
MICHALE FEE: Well, so
remember, the probability

563
00:33:26,640 --> 00:33:30,120
of having a spike in any
interval in a process

564
00:33:30,120 --> 00:33:33,084
is completely independent of
what happens at any other time.

565
00:33:33,084 --> 00:33:34,626
AUDIENCE: So why
are we calculating--

566
00:33:34,626 --> 00:33:37,340
why did we do that [INAUDIBLE]?

567
00:33:37,340 --> 00:33:40,130
MICHALE FEE: OK, because
in order for this

568
00:33:40,130 --> 00:33:44,240
to be the interval between
one spike and the next spike,

569
00:33:44,240 --> 00:33:47,128
we needed to have zero spikes
in the intervening interval.

570
00:33:47,128 --> 00:33:48,545
AUDIENCE: Oh, OK,
so [INAUDIBLE]..

571
00:33:48,545 --> 00:33:49,195
OK.

572
00:33:49,195 --> 00:33:50,570
MICHALE FEE:
Because if there had

573
00:33:50,570 --> 00:33:52,820
been another spike
in here somewhere,

574
00:33:52,820 --> 00:33:55,460
this would not be our
inter-spike interval.

575
00:33:55,460 --> 00:33:58,970
The inter-spike interval would
be between here and wherever

576
00:33:58,970 --> 00:33:59,840
that spike occurred.

577
00:33:59,840 --> 00:34:01,550
And we'd just be
back to calculating

578
00:34:01,550 --> 00:34:04,380
what's the probability of
having no spike between there

579
00:34:04,380 --> 00:34:04,880
and there.

580
00:34:10,159 --> 00:34:11,110
OK, good.

581
00:34:11,110 --> 00:34:15,210
So that's the probability
of having no spike from here

582
00:34:15,210 --> 00:34:20,159
to here, and having a spike
in the next little delta-T.

583
00:34:20,159 --> 00:34:26,690
We can now calculate what's
called the probability density.

584
00:34:26,690 --> 00:34:29,840
It's the probability
per unit time

585
00:34:29,840 --> 00:34:34,040
of having inter-spike
intervals of that duration.

586
00:34:34,040 --> 00:34:35,600
And to do that,
we just calculate

587
00:34:35,600 --> 00:34:40,159
the probability divided by
delta-T. And what you find

588
00:34:40,159 --> 00:34:45,409
is that the probability density
of inter-spike intervals

589
00:34:45,409 --> 00:34:48,830
is just re to the
minus r tau, where

590
00:34:48,830 --> 00:34:51,260
tau is the spike interval.

591
00:34:51,260 --> 00:34:53,889
And so this is what that looks
like for a Poisson process.

592
00:34:58,090 --> 00:35:02,380
OK, so you can see that
the highest probability

593
00:35:02,380 --> 00:35:06,420
is having very short intervals.

594
00:35:06,420 --> 00:35:10,470
And you have exponentially
lower probabilities

595
00:35:10,470 --> 00:35:13,283
of having longer and
longer intervals.

596
00:35:16,121 --> 00:35:18,490
Does that make sense?

597
00:35:18,490 --> 00:35:21,310
So it turns out
that that's actually

598
00:35:21,310 --> 00:35:24,820
a lot like what interspike
intervals of real neurons

599
00:35:24,820 --> 00:35:25,960
looks like.

600
00:35:25,960 --> 00:35:30,730
They very often have
this exponential tail.

601
00:35:30,730 --> 00:35:36,040
Now, what is
completely unrealistic

602
00:35:36,040 --> 00:35:39,470
about this interspike
interval distribution?

603
00:35:39,470 --> 00:35:43,540
What is it that can't
be true about this?

604
00:35:43,540 --> 00:35:45,186
[INAUDIBLE]

605
00:35:45,186 --> 00:35:48,614
AUDIENCE: Intervals,
like, which are huge.

606
00:35:51,328 --> 00:35:52,870
MICHALE FEE: Well,
so it's actually--

607
00:35:52,870 --> 00:35:55,287
the bigger problem is not on
this end of the distribution.

608
00:35:55,287 --> 00:35:56,162
AUDIENCE: [INAUDIBLE]

609
00:35:56,162 --> 00:35:56,950
MICHALE FEE: Yeah.

610
00:35:56,950 --> 00:35:59,842
What happens here that's wrong?

611
00:35:59,842 --> 00:36:01,545
AUDIENCE: [INAUDIBLE]

612
00:36:01,545 --> 00:36:02,420
MICHALE FEE: Exactly.

613
00:36:02,420 --> 00:36:06,115
So what happens immediately
after a neuron spikes?

614
00:36:06,115 --> 00:36:07,490
AUDIENCE: You
can't have a spike.

615
00:36:07,490 --> 00:36:09,698
MICHALE FEE: You can't have
another spike right away.

616
00:36:09,698 --> 00:36:10,485
Why is that?

617
00:36:10,485 --> 00:36:11,360
AUDIENCE: [INAUDIBLE]

618
00:36:11,360 --> 00:36:13,277
MICHALE FEE: Because of
the refractory period,

619
00:36:13,277 --> 00:36:14,118
which comes from--

620
00:36:14,118 --> 00:36:15,552
AUDIENCE: [INAUDIBLE]

621
00:36:15,552 --> 00:36:18,310
MICHALE FEE: Hyperpolarization
is one of them.

622
00:36:18,310 --> 00:36:20,290
Once you have the
spike, the neuron

623
00:36:20,290 --> 00:36:23,620
is actually briefly
hyperpolarized.

624
00:36:23,620 --> 00:36:28,170
You could imagine trying to
re-polarize it very quickly,

625
00:36:28,170 --> 00:36:30,128
but then something
else is a problem.

626
00:36:30,128 --> 00:36:31,430
AUDIENCE: [INAUDIBLE]

627
00:36:31,430 --> 00:36:33,380
MICHALE FEE: Sodium
channel inactivation.

628
00:36:33,380 --> 00:36:35,660
So even if you were to
repolarize the neuron very

629
00:36:35,660 --> 00:36:37,700
quickly, it still
would have a hard time

630
00:36:37,700 --> 00:36:42,290
making a spike because of
sodium channel inactivation.

631
00:36:42,290 --> 00:36:46,600
So what does this actually
look like for real neuron?

632
00:36:46,600 --> 00:36:48,283
What do you imagine
it looks like?

633
00:36:48,283 --> 00:36:50,450
AUDIENCE: [INAUDIBLE]

634
00:36:50,450 --> 00:36:53,080
MICHALE FEE: Right, so
immediately after a spike,

635
00:36:53,080 --> 00:36:56,990
there is zero probability
of having another spike.

636
00:36:56,990 --> 00:37:00,950
So this starts at
zero, climbs up here,

637
00:37:00,950 --> 00:37:02,910
and then decays exponentially.

638
00:37:02,910 --> 00:37:07,220
OK, so that's what most
inter-spike intervals

639
00:37:07,220 --> 00:37:09,650
for real neurons
actually looks like.

640
00:37:12,510 --> 00:37:15,620
So this is probability density.

641
00:37:15,620 --> 00:37:16,120
This is tau.

642
00:37:21,270 --> 00:37:25,990
And this is the
refractory period.

643
00:37:33,350 --> 00:37:37,570
In fact, when you
record from neurons

644
00:37:37,570 --> 00:37:42,153
with an electrode in the
brain, you get lots of spikes.

645
00:37:42,153 --> 00:37:43,570
One of the first
things you should

646
00:37:43,570 --> 00:37:48,400
do when you set a threshold
and find those spike times

647
00:37:48,400 --> 00:37:52,030
is compute by
interval distribution.

648
00:37:52,030 --> 00:37:55,510
Because if you're recording
from a single neuron,

649
00:37:55,510 --> 00:37:57,280
that interspike
interval distribution

650
00:37:57,280 --> 00:38:02,030
will have this
refractory period.

651
00:38:02,030 --> 00:38:04,100
If you're recording
from-- it's quite easy

652
00:38:04,100 --> 00:38:07,140
to get multiple spikes on
the end of an electrode.

653
00:38:07,140 --> 00:38:11,240
And what happens if you
have multiple spikes,

654
00:38:11,240 --> 00:38:13,250
you can think they're
coming from one neuron,

655
00:38:13,250 --> 00:38:15,730
but in fact they're
coming from two neurons.

656
00:38:15,730 --> 00:38:17,480
And if you compute the
interspike interval

657
00:38:17,480 --> 00:38:21,160
distribution, it won't
have this dip here.

658
00:38:21,160 --> 00:38:25,120
So it's a really important
tool to use to test

659
00:38:25,120 --> 00:38:28,990
whether your signal is clean.

660
00:38:28,990 --> 00:38:31,300
You'd be amazed at how few
people actually do that.

661
00:38:35,915 --> 00:38:37,540
All right, I just
want to introduce you

662
00:38:37,540 --> 00:38:40,890
to one important term.

663
00:38:40,890 --> 00:38:46,420
And that's called homogeneous
versus inhomogeneous

664
00:38:46,420 --> 00:38:48,760
in the context of
Poisson process.

665
00:38:48,760 --> 00:38:53,170
What that means is that a
homogeneous Poisson process has

666
00:38:53,170 --> 00:38:55,540
a constant rate, mu.

667
00:38:55,540 --> 00:38:58,180
Most neurons don't do that.

668
00:38:58,180 --> 00:39:02,110
Because in most neurons,
there's information

669
00:39:02,110 --> 00:39:05,350
carried in the fluctuation
of the firing rate.

670
00:39:05,350 --> 00:39:08,350
And so most neurons have
what's called behave more

671
00:39:08,350 --> 00:39:12,190
like an inhomogeneous
Poisson process,

672
00:39:12,190 --> 00:39:15,380
where the rate is actually
fluctuating in time.

673
00:39:15,380 --> 00:39:17,710
And the example we
were looking at before

674
00:39:17,710 --> 00:39:20,570
shows you what an
inhomogenous Poisson

675
00:39:20,570 --> 00:39:21,590
process would look like.

676
00:39:26,460 --> 00:39:30,090
So let's see what's next.

677
00:39:30,090 --> 00:39:32,730
All right, so
let's change topics

678
00:39:32,730 --> 00:39:36,540
to talk about convolution,
cross-correlation,

679
00:39:36,540 --> 00:39:38,880
and auto-correlation functions.

680
00:39:38,880 --> 00:39:42,090
All right, so we've been using
the notion of a convolution

681
00:39:42,090 --> 00:39:47,160
where we have a kernel that
we multiply by a signal.

682
00:39:47,160 --> 00:39:49,750
We multiply that, and
integrate over time,

683
00:39:49,750 --> 00:39:53,010
and then we slide that
kernel across the signal,

684
00:39:53,010 --> 00:39:56,700
and ask, where does the
signal have structure

685
00:39:56,700 --> 00:39:58,480
that looks like the kernel.

686
00:39:58,480 --> 00:40:02,730
And that gives you
an output y of T.

687
00:40:02,730 --> 00:40:07,020
So we've used that to model
the membrane potential

688
00:40:07,020 --> 00:40:08,980
of [INAUDIBLE] synaptic input.

689
00:40:08,980 --> 00:40:10,740
So in that case, we
had spikes coming

690
00:40:10,740 --> 00:40:14,220
from a presynaptic neuron
that generate a response

691
00:40:14,220 --> 00:40:15,960
in the postsynaptic neuron.

692
00:40:15,960 --> 00:40:18,840
And now we can take--

693
00:40:18,840 --> 00:40:22,050
the output of that, the response
in the postsynaptic neuron

694
00:40:22,050 --> 00:40:24,930
as a convolution of
that exponential,

695
00:40:24,930 --> 00:40:28,850
with an input spike train.

696
00:40:28,850 --> 00:40:32,120
We've used it to model
the response of neurons

697
00:40:32,120 --> 00:40:35,550
to a time-dependent stimulus.

698
00:40:35,550 --> 00:40:37,680
And you also used it--

699
00:40:37,680 --> 00:40:39,930
I've described how you
can use that to implement

700
00:40:39,930 --> 00:40:41,940
a low-pass filter or
a high-pass filter.

701
00:40:41,940 --> 00:40:45,240
And we talked about
doing that for extracting

702
00:40:45,240 --> 00:40:49,560
either low-frequency signals,
to get the local field

703
00:40:49,560 --> 00:40:52,920
potential out of neurons, or
doing a high-pass filter to get

704
00:40:52,920 --> 00:40:58,360
rid of the low-frequency signals
so that you can see the spikes.

705
00:40:58,360 --> 00:41:04,910
OK, but most generally,
convolution is--

706
00:41:04,910 --> 00:41:07,100
you should think
about it as allowing

707
00:41:07,100 --> 00:41:14,610
you to model how a system
responds to an input

708
00:41:14,610 --> 00:41:16,230
where the response
of the system is

709
00:41:16,230 --> 00:41:19,320
controlled by a linear filter.

710
00:41:19,320 --> 00:41:24,230
The system is sensitive
to particular patterns

711
00:41:24,230 --> 00:41:25,400
in the input.

712
00:41:25,400 --> 00:41:29,330
Those patterns can be
detected by a filter.

713
00:41:29,330 --> 00:41:32,180
So you apply that
filter to the input,

714
00:41:32,180 --> 00:41:34,370
and you estimate how
the system responds.

715
00:41:34,370 --> 00:41:41,600
And it's very broadly useful
in engineering and biology

716
00:41:41,600 --> 00:41:47,030
and neuroscience to use
convolutions to model

717
00:41:47,030 --> 00:41:49,220
how a system responds
to its input.

718
00:41:53,200 --> 00:41:55,910
All right, so there is a
different kind of function,

719
00:41:55,910 --> 00:41:59,570
called a cross-correlation
function, that looks like this.

720
00:41:59,570 --> 00:42:03,140
And it looks very
similar to a convolution,

721
00:42:03,140 --> 00:42:05,000
but it's used very differently.

722
00:42:05,000 --> 00:42:08,810
Now, you might think, OK,
there's just a sign change.

723
00:42:08,810 --> 00:42:12,910
Here I have a T minus tau,
and here I have a T plus tau.

724
00:42:12,910 --> 00:42:16,590
Is that the only
difference between those?

725
00:42:16,590 --> 00:42:17,650
It's not.

726
00:42:17,650 --> 00:42:21,380
Because here I'm
integrating over a d tau,

727
00:42:21,380 --> 00:42:24,110
and here I'm
integrating over dT.

728
00:42:24,110 --> 00:42:30,740
Here I'm getting the response
as a function of time.

729
00:42:30,740 --> 00:42:35,600
Here, what I'm doing is I'm
kind of extracting the kernel.

730
00:42:35,600 --> 00:42:40,550
What I'm getting out of
this is a kernel, tau,

731
00:42:40,550 --> 00:42:41,990
as a function of tau.

732
00:42:41,990 --> 00:42:46,290
OK, so let me walk
through how that works.

733
00:42:46,290 --> 00:42:51,980
So in this case, we have
two signals, x and y.

734
00:42:51,980 --> 00:42:54,230
And what we're doing is we're
taking those two signals

735
00:42:54,230 --> 00:42:58,340
and we're multiplying them
by each other, x times y.

736
00:42:58,340 --> 00:43:01,790
And what we're doing is
we're multiplying the signals

737
00:43:01,790 --> 00:43:04,760
and then integrating
over the product.

738
00:43:07,270 --> 00:43:09,610
And then we shift
one of those signals

739
00:43:09,610 --> 00:43:11,470
by a little amount, tau.

740
00:43:11,470 --> 00:43:14,050
And we repeat that process.

741
00:43:14,050 --> 00:43:15,670
So let's see what
that looks like.

742
00:43:15,670 --> 00:43:17,200
So what do you see here?

743
00:43:17,200 --> 00:43:21,600
You see two different
signals, x and [AUDIO OUT]

744
00:43:21,600 --> 00:43:23,560
I'm sorry, x and y.

745
00:43:23,560 --> 00:43:26,360
They look kind of similar.

746
00:43:26,360 --> 00:43:29,410
You can see this
one has a bump here,

747
00:43:29,410 --> 00:43:31,570
and a couple bumps
there, and a bump there.

748
00:43:31,570 --> 00:43:34,410
And you see something pretty
similar to that here, right?

749
00:43:34,410 --> 00:43:36,190
Here's three big bumps.

750
00:43:36,190 --> 00:43:37,160
Here's three big bumps.

751
00:43:37,160 --> 00:43:41,775
So those signals are actually
quite similar to each other,

752
00:43:41,775 --> 00:43:43,150
but they're not
exactly the same.

753
00:43:43,150 --> 00:43:47,800
Right you can see that these
fast little fluctuations are

754
00:43:47,800 --> 00:43:50,380
different on those two signals.

755
00:43:50,380 --> 00:43:53,070
Now, what happens when
we take this signal--

756
00:43:53,070 --> 00:43:56,380
and you can see that
there's this offset here.

757
00:43:56,380 --> 00:43:59,320
So what happens if
we take x times y,

758
00:43:59,320 --> 00:44:04,270
we multiply them together,
and we integrate the result?

759
00:44:04,270 --> 00:44:10,300
Then we shift y a little
bit, by an amount, tau,

760
00:44:10,300 --> 00:44:12,550
and we multiply those
two signals together,

761
00:44:12,550 --> 00:44:13,482
and we integrate.

762
00:44:13,482 --> 00:44:14,440
And we keep doing that.

763
00:44:18,910 --> 00:44:22,210
And now we're going
to plot this k

764
00:44:22,210 --> 00:44:25,295
as a function of that
little shift, tau,

765
00:44:25,295 --> 00:44:26,170
that we put in there.

766
00:44:29,350 --> 00:44:31,070
And here's what that looks like.

767
00:44:31,070 --> 00:44:36,790
So k is the cross-correlation--
sometimes called the lag

768
00:44:36,790 --> 00:44:39,790
cross-correlation-- of x and y.

769
00:44:39,790 --> 00:44:43,330
So that little
circle is the symbol

770
00:44:43,330 --> 00:44:46,070
for lag cross-correlation.

771
00:44:46,070 --> 00:44:51,080
And you can see that,
at a particular lag,

772
00:44:51,080 --> 00:44:55,010
like right here, the positive
fluctuations in this signal

773
00:44:55,010 --> 00:44:57,320
are going to line up with
the positive fluctuations

774
00:44:57,320 --> 00:44:58,580
in that signal.

775
00:44:58,580 --> 00:45:00,710
The negative fluctuations
in this signal

776
00:45:00,710 --> 00:45:02,840
are going to line up with
the negative fluctuations

777
00:45:02,840 --> 00:45:04,020
in that signal.

778
00:45:04,020 --> 00:45:06,380
And when you multiply
them together,

779
00:45:06,380 --> 00:45:10,280
you're going to get the
maximum positive contribution.

780
00:45:10,280 --> 00:45:14,150
Those signals are going
to be maximally overlapped

781
00:45:14,150 --> 00:45:16,460
at a particular shift, tau.

782
00:45:20,440 --> 00:45:24,370
And when you put that
function, K of tau,

783
00:45:24,370 --> 00:45:29,360
you're going to have a
peak at that lag that

784
00:45:29,360 --> 00:45:32,180
corresponds to where those
signals are maximally

785
00:45:32,180 --> 00:45:33,320
overlapped.

786
00:45:33,320 --> 00:45:39,800
So a lag cross-correlation
function is really useful

787
00:45:39,800 --> 00:45:45,100
for finding, let's say, the
time at which two signals--

788
00:45:45,100 --> 00:45:48,320
like if one signal is like
a copy of the other one,

789
00:45:48,320 --> 00:45:52,250
but it's shifted in time, a
lag cross-correlation function

790
00:45:52,250 --> 00:45:56,900
is really useful for finding
that the lag between those two

791
00:45:56,900 --> 00:45:57,725
functions.

792
00:46:00,520 --> 00:46:04,240
There's another context in
which this lag cross-correlation

793
00:46:04,240 --> 00:46:05,410
function is really useful.

794
00:46:08,360 --> 00:46:11,650
So when we did the
spike-triggered average,

795
00:46:11,650 --> 00:46:16,120
when we took spikes
from a neuron, and we--

796
00:46:16,120 --> 00:46:18,130
at the time of those
spikes, we extracted

797
00:46:18,130 --> 00:46:19,780
what the input
was to the neuron,

798
00:46:19,780 --> 00:46:22,180
and we averaged
that [AUDIO OUT]..

799
00:46:22,180 --> 00:46:27,040
What we were really doing was we
were doing a cross-correlation

800
00:46:27,040 --> 00:46:31,630
between the spike train of
a neuron and the stimulus

801
00:46:31,630 --> 00:46:34,330
that drove that neuron,
the stimulus that

802
00:46:34,330 --> 00:46:36,940
was input to that neuron.

803
00:46:36,940 --> 00:46:40,660
And that
cross-correlation was just

804
00:46:40,660 --> 00:46:43,360
the kernel that
described how you

805
00:46:43,360 --> 00:46:45,610
get from that
input to the neuron

806
00:46:45,610 --> 00:46:46,990
to the response of the neuron.

807
00:46:50,680 --> 00:46:54,750
So spike-triggered average
is actually sometimes called

808
00:46:54,750 --> 00:46:55,920
reverse correlation.

809
00:46:55,920 --> 00:46:57,390
And the reverse
comes from the fact

810
00:46:57,390 --> 00:47:00,930
that you have to actually flip
this over to get the kernel.

811
00:47:00,930 --> 00:47:02,380
So let's not worry about that.

812
00:47:02,380 --> 00:47:06,030
But it's sometimes referred
to as the correlation

813
00:47:06,030 --> 00:47:08,310
between the spike train
and the stimulus input.

814
00:47:08,310 --> 00:47:09,596
Yes.

815
00:47:09,596 --> 00:47:12,061
AUDIENCE: [INAUDIBLE]

816
00:47:16,850 --> 00:47:19,490
MICHALE FEE: So there's
no convolution here.

817
00:47:19,490 --> 00:47:23,810
We're doing the lag
cross-correlation, OK.

818
00:47:23,810 --> 00:47:28,040
We're just taking
those two signals,

819
00:47:28,040 --> 00:47:32,820
and shifting one of them,
multiplying, and integrating.

820
00:47:32,820 --> 00:47:33,320
Sorry.

821
00:47:33,320 --> 00:47:34,070
Ask your question.

822
00:47:34,070 --> 00:47:35,510
I just wanted to
clarify, there's

823
00:47:35,510 --> 00:47:37,736
no convolution being done here.

824
00:47:37,736 --> 00:47:49,000
AUDIENCE: So [INAUDIBLE]
is that y [INAUDIBLE]

825
00:47:49,000 --> 00:47:51,360
MICHALE FEE: Ah, OK, great.

826
00:47:51,360 --> 00:47:53,910
That's actually one
of the things that's

827
00:47:53,910 --> 00:47:57,230
easiest to get
mixed up about when

828
00:47:57,230 --> 00:48:02,090
you do lag cross-correlation.

829
00:48:02,090 --> 00:48:09,920
You have to be careful about
which side this peak is on.

830
00:48:09,920 --> 00:48:12,710
And I personally can
never keep it straight.

831
00:48:12,710 --> 00:48:15,320
So what I do is just
make two test functions,

832
00:48:15,320 --> 00:48:16,850
and stick them in.

833
00:48:16,850 --> 00:48:20,190
And make sure that if I
have one of my functions--

834
00:48:20,190 --> 00:48:24,770
so in this case, here
are two test functions.

835
00:48:24,770 --> 00:48:27,560
You can see that x is--

836
00:48:27,560 --> 00:48:31,710
sorry, y is before x.

837
00:48:31,710 --> 00:48:35,870
And so this peak
here corresponds

838
00:48:35,870 --> 00:48:38,670
to y happening before x.

839
00:48:38,670 --> 00:48:43,980
So you just have to make sure
you know what the sign is.

840
00:48:43,980 --> 00:48:49,260
And I recommend doing that
with just two functions

841
00:48:49,260 --> 00:48:51,520
that you know.

842
00:48:51,520 --> 00:48:54,410
It's easy to get it backwards.

843
00:48:54,410 --> 00:48:54,910
Yes.

844
00:48:54,910 --> 00:48:57,904
AUDIENCE: [INAUDIBLE] part
of y equals [INAUDIBLE]..

845
00:49:04,890 --> 00:49:06,676
MICHALE FEE: What do
you mean, first part?

846
00:49:06,676 --> 00:49:08,540
AUDIENCE: The very
first [INAUDIBLE]..

847
00:49:08,540 --> 00:49:09,060
MICHALE FEE: Oh, these?

848
00:49:09,060 --> 00:49:09,800
AUDIENCE: Yes.

849
00:49:09,800 --> 00:49:12,740
MICHALE FEE: I'm just
taking copies of this,

850
00:49:12,740 --> 00:49:15,300
and placing them on top of
each other, and shifting them.

851
00:49:15,300 --> 00:49:17,940
So you should ignore this
little part right here.

852
00:49:17,940 --> 00:49:22,993
AUDIENCE: [INAUDIBLE]

853
00:49:22,993 --> 00:49:23,910
MICHALE FEE: Oh, yeah.

854
00:49:23,910 --> 00:49:31,170
So there are Matlab functions
to do this cross-correlation.

855
00:49:31,170 --> 00:49:36,700
And it handles all of
that stuff for you.

856
00:49:36,700 --> 00:49:37,676
Yes.

857
00:49:37,676 --> 00:49:41,092
AUDIENCE: [INAUDIBLE]

858
00:49:43,322 --> 00:49:44,030
MICHALE FEE: Yes.

859
00:49:44,030 --> 00:49:46,250
AUDIENCE: Like,
is the x-axis tau?

860
00:49:46,250 --> 00:49:47,653
MICHALE FEE: The x-axis is tau.

861
00:49:47,653 --> 00:49:49,070
I should have
labeled it on there.

862
00:49:52,401 --> 00:49:54,526
AUDIENCE: I just want to
clarify whether they meet.

863
00:49:54,526 --> 00:50:00,374
So how it's kind of flat, and
then this idea of the flat area

864
00:50:00,374 --> 00:50:03,226
that, when you multiply them
and they're slightly off,

865
00:50:03,226 --> 00:50:05,170
this is generally not zero.

866
00:50:05,170 --> 00:50:07,117
But you know, they
cancel each other out.

867
00:50:07,117 --> 00:50:09,700
MICHALE FEE: So you can see that
if these things are shifted--

868
00:50:09,700 --> 00:50:12,117
if they're kind of noisy, and
they're shifted with respect

869
00:50:12,117 --> 00:50:15,880
to each other, you can see
that the positive parts here

870
00:50:15,880 --> 00:50:17,770
might line up with the
negative parts there.

871
00:50:17,770 --> 00:50:20,350
And the negative parts here
line up with the positive parts

872
00:50:20,350 --> 00:50:20,950
there.

873
00:50:20,950 --> 00:50:25,660
And they're shifted randomly
at any other time with respect

874
00:50:25,660 --> 00:50:26,350
to each other.

875
00:50:26,350 --> 00:50:30,220
On average, positive
times negative,

876
00:50:30,220 --> 00:50:31,995
you're going to have
some parts where

877
00:50:31,995 --> 00:50:34,120
it's positive times positive,
and other parts where

878
00:50:34,120 --> 00:50:35,380
it's positive times negative.

879
00:50:35,380 --> 00:50:38,050
And it's all going to wash
out and give you zero.

880
00:50:38,050 --> 00:50:42,070
Because those signals are
uncorrelated with each other

881
00:50:42,070 --> 00:50:44,715
at different time lags.

882
00:50:44,715 --> 00:50:47,446
AUDIENCE: So only when the
perfectly overlap and kind

883
00:50:47,446 --> 00:50:49,600
of exaggerate each other
is when they'll be flat.

884
00:50:49,600 --> 00:50:50,560
MICHALE FEE: Exactly.

885
00:50:50,560 --> 00:50:54,940
It's only when they overlap
that all of the positive parts

886
00:50:54,940 --> 00:50:58,493
here will line up with
the positive parts here,

887
00:50:58,493 --> 00:51:00,160
and the negative parts
here will line up

888
00:51:00,160 --> 00:51:01,185
with the negative parts.

889
00:51:01,185 --> 00:51:03,005
AUDIENCE: And since you're
taking the integral together,

890
00:51:03,005 --> 00:51:04,830
it just makes a
very large positive.

891
00:51:04,830 --> 00:51:06,130
MICHALE FEE: Exactly.

892
00:51:06,130 --> 00:51:08,590
All of those positive
times positive

893
00:51:08,590 --> 00:51:12,430
add up to the negative times
negative, which is positive.

894
00:51:12,430 --> 00:51:15,010
And all of that
adds up to give you

895
00:51:15,010 --> 00:51:16,780
that positive peak right there.

896
00:51:16,780 --> 00:51:21,420
But when they're shifted, all
of those magical alignments

897
00:51:21,420 --> 00:51:24,820
of positive with positive and
negative with negative go away.

898
00:51:24,820 --> 00:51:28,330
And it just becomes, on
average, just random.

899
00:51:28,330 --> 00:51:33,430
And random things have zero
correlation with each other.

900
00:51:38,320 --> 00:51:42,320
So this is actually
a really powerful way

901
00:51:42,320 --> 00:51:47,220
to discover the relation
between two different signals.

902
00:51:52,570 --> 00:51:57,070
And in fact, it
gives you a kernel

903
00:51:57,070 --> 00:51:59,110
that you can actually
use to predict

904
00:51:59,110 --> 00:52:01,090
one signal from another signal.

905
00:52:01,090 --> 00:52:05,350
Now, if you were to take
x and convolve it with k,

906
00:52:05,350 --> 00:52:07,870
you would get an estimate of y.

907
00:52:07,870 --> 00:52:11,050
We'll talk more
about that later.

908
00:52:11,050 --> 00:52:11,920
Pretty cool, right?

909
00:52:19,290 --> 00:52:22,350
So they're mathematically
very similar.

910
00:52:22,350 --> 00:52:23,310
They look similar.

911
00:52:23,310 --> 00:52:25,960
But they're used
in different ways.

912
00:52:25,960 --> 00:52:28,680
So the way we think
about convolution is--

913
00:52:28,680 --> 00:52:32,670
what it's used for is to
take an input signal x,

914
00:52:32,670 --> 00:52:38,700
and convolve it with a kernel,
k, to get an output signal, y.

915
00:52:38,700 --> 00:52:43,830
And we usually think of x
as being very long vectors,

916
00:52:43,830 --> 00:52:46,130
long signals.

917
00:52:46,130 --> 00:52:48,660
K here, kappa, is a kernel.

918
00:52:48,660 --> 00:52:51,870
It's just a short
little thing in time.

919
00:52:51,870 --> 00:52:54,510
And you're going to convolve
it with a long signal

920
00:52:54,510 --> 00:52:56,190
to get another long signal.

921
00:52:56,190 --> 00:52:59,250
Does that makes sense?

922
00:52:59,250 --> 00:53:04,140
In cross-correlation, we
have two signals, x and y.

923
00:53:04,140 --> 00:53:06,660
x and y are the inputs.

924
00:53:06,660 --> 00:53:09,810
And we cross-correlate
it to extract

925
00:53:09,810 --> 00:53:14,910
a short signal that captures
the temporal relation between x

926
00:53:14,910 --> 00:53:17,680
and y.

927
00:53:17,680 --> 00:53:20,770
All right, so x and
y are long signals.

928
00:53:20,770 --> 00:53:22,550
K is a short vector.

929
00:53:22,550 --> 00:53:27,710
And in this case, we're
convolving a long signal

930
00:53:27,710 --> 00:53:31,310
with a short kernel to get
another long signal, which

931
00:53:31,310 --> 00:53:33,540
is the response of the system.

932
00:53:33,540 --> 00:53:37,250
In this case, we take,
let's say, the input

933
00:53:37,250 --> 00:53:39,620
to a system and the
output of this system,

934
00:53:39,620 --> 00:53:42,560
and doing a cross-correlation
to extract the kernel.

935
00:53:46,710 --> 00:53:48,830
All right, any
questions about that?

936
00:53:48,830 --> 00:53:51,660
They're both
super-powerful methods.

937
00:53:51,660 --> 00:53:52,620
Yes, [INAUDIBLE].

938
00:53:52,620 --> 00:53:54,370
AUDIENCE: How does the
cross-correlation--

939
00:53:54,370 --> 00:53:57,150
mathematically, how does it
give a short vector [INAUDIBLE]??

940
00:53:57,150 --> 00:54:05,740
MICHALE FEE: You just do this
for a small number of taus.

941
00:54:05,740 --> 00:54:08,200
Because usually
signals that have

942
00:54:08,200 --> 00:54:10,300
some relation between
them, that relation

943
00:54:10,300 --> 00:54:12,610
has a short time extent.

944
00:54:12,610 --> 00:54:16,240
This signal here, in a
real physical system,

945
00:54:16,240 --> 00:54:21,040
doesn't depend on what x was
doing a month ago, or maybe

946
00:54:21,040 --> 00:54:21,970
a few seconds ago.

947
00:54:21,970 --> 00:54:26,020
These signals might be 10 or 20
seconds long, or an hour long,

948
00:54:26,020 --> 00:54:29,320
but this signal, y,
doesn't depend on what

949
00:54:29,320 --> 00:54:31,150
x was doing an hour ago.

950
00:54:31,150 --> 00:54:32,980
It only depends on
what x was doing

951
00:54:32,980 --> 00:54:36,340
maybe a few tens of
milliseconds or a second ago.

952
00:54:36,340 --> 00:54:40,210
So that's why x and y
can be long signals.

953
00:54:40,210 --> 00:54:47,770
K is a short vector that
represents the kernel.

954
00:54:47,770 --> 00:54:49,060
Any more questions about that?

955
00:54:53,110 --> 00:54:55,580
OK, these are very
powerful methods.

956
00:54:55,580 --> 00:54:57,170
We use them all the time.

957
00:55:00,960 --> 00:55:06,140
I talked about the relation to
the spike-triggered average.

958
00:55:06,140 --> 00:55:09,440
The autocorrelation is nothing
more than a cross-correlation

959
00:55:09,440 --> 00:55:10,720
of a signal with itself.

960
00:55:15,180 --> 00:55:17,570
So let's see how that's useful.

961
00:55:17,570 --> 00:55:19,340
So an autocorrelation
is a good way

962
00:55:19,340 --> 00:55:23,810
to examine a temporal
structure within a signal.

963
00:55:23,810 --> 00:55:28,640
So if we take a signal,
x, and we calculate

964
00:55:28,640 --> 00:55:32,013
the cross-correlation of
that signal with itself,

965
00:55:32,013 --> 00:55:33,180
here's what that looks like.

966
00:55:33,180 --> 00:55:36,500
So let's say we have a
signal that looks like this.

967
00:55:36,500 --> 00:55:40,730
And this signal kind of
has slowish fluctuations

968
00:55:40,730 --> 00:55:45,790
that are, let's say, on a 50
or 100 millisecond timescale.

969
00:55:45,790 --> 00:55:49,660
If we take that signal and
we multiply it by itself

970
00:55:49,660 --> 00:55:54,320
with zero time lag, what do
you think that will look like?

971
00:55:54,320 --> 00:55:58,330
So positive lines up with
positive, negative lines

972
00:55:58,330 --> 00:56:00,040
up with negative.

973
00:56:00,040 --> 00:56:03,580
That thing should do what?

974
00:56:03,580 --> 00:56:05,740
It should be a maximum, right?

975
00:56:05,740 --> 00:56:09,760
Autocorrelations are always
a maximum at zero lag.

976
00:56:12,862 --> 00:56:15,320
And then what we do is we're
just going to take that signal

977
00:56:15,320 --> 00:56:16,805
and shift it a little bit.

978
00:56:16,805 --> 00:56:18,680
And we'll shift it
a little bit more,

979
00:56:18,680 --> 00:56:21,890
do that product and
integral, shift that product

980
00:56:21,890 --> 00:56:23,150
and integral.

981
00:56:23,150 --> 00:56:29,370
Now what's going to happen as
we shift one of those signals

982
00:56:29,370 --> 00:56:31,500
sideways?

983
00:56:31,500 --> 00:56:35,960
And then multiply and integrate.

984
00:56:35,960 --> 00:56:37,250
Sammy, you got this one.

985
00:56:37,250 --> 00:56:41,540
AUDIENCE: Oh, at first,
[INAUDIBLE] zero [INAUDIBLE]

986
00:56:41,540 --> 00:56:44,180
point where the plus
and minuses cancel out.

987
00:56:44,180 --> 00:56:46,195
[INAUDIBLE] this.

988
00:56:46,195 --> 00:56:49,165
If you [INAUDIBLE]
maybe [INAUDIBLE]

989
00:56:49,165 --> 00:56:54,115
where the pluses
overlap the second time.

990
00:56:54,115 --> 00:56:55,990
MICHALE FEE: Yeah, so
if you shift it enough,

991
00:56:55,990 --> 00:56:59,240
it's possible that it might
overlap again somewhere else.

992
00:56:59,240 --> 00:57:04,388
What kind of signal
would that happen for?

993
00:57:04,388 --> 00:57:05,430
AUDIENCE: Like, cyclical.

994
00:57:05,430 --> 00:57:07,320
MICHALE FEE: Yeah,
a periodic signal.

995
00:57:07,320 --> 00:57:08,400
Exactly.

996
00:57:08,400 --> 00:57:15,330
So an autocorrelation first
of all has a peak at zero lag.

997
00:57:15,330 --> 00:57:20,570
That peak drops off when
these fluctuations here.

998
00:57:20,570 --> 00:57:23,750
So the positive lines up
with positive, negative lines

999
00:57:23,750 --> 00:57:24,470
up with negative.

1000
00:57:24,470 --> 00:57:27,710
As you shift one of them,
those positive and negatives

1001
00:57:27,710 --> 00:57:29,280
no longer overlap
with each other,

1002
00:57:29,280 --> 00:57:32,270
and you start getting positives
lining up with negatives.

1003
00:57:32,270 --> 00:57:34,940
And so the
autocorrelation drops off.

1004
00:57:34,940 --> 00:57:40,320
And then it can actually
go back and indicate--

1005
00:57:40,320 --> 00:57:42,450
it can go back up if
there's periodic structure.

1006
00:57:42,450 --> 00:57:44,200
So let's look at what
this one looks like.

1007
00:57:44,200 --> 00:57:46,530
So in this case,
it kind of looked

1008
00:57:46,530 --> 00:57:48,180
like there might be
periodic structure,

1009
00:57:48,180 --> 00:57:49,597
but there wasn't,
because this was

1010
00:57:49,597 --> 00:57:52,380
just low-pass-filtered noise.

1011
00:57:52,380 --> 00:57:55,260
And you can see that
if you compute the--

1012
00:57:55,260 --> 00:57:57,960
there's that Matlab
function, xcorr.

1013
00:57:57,960 --> 00:58:00,840
So you use it to calculate
the autocorrelation.

1014
00:58:00,840 --> 00:58:02,860
You can see that that
autocorrelation is peaked

1015
00:58:02,860 --> 00:58:08,940
at zero lag, drops off, and
the lag at which it drops off

1016
00:58:08,940 --> 00:58:12,060
depends on how smoothly
varying that function is.

1017
00:58:12,060 --> 00:58:13,800
If the function varies--

1018
00:58:13,800 --> 00:58:16,568
if it's changing very
slowly, the autocorrelation

1019
00:58:16,568 --> 00:58:17,610
is going to be very wide.

1020
00:58:17,610 --> 00:58:19,890
Because you have to
shift it a lot in order

1021
00:58:19,890 --> 00:58:24,630
to get the positive peaks
and the negative peaks

1022
00:58:24,630 --> 00:58:27,480
misaligned from each other.

1023
00:58:27,480 --> 00:58:29,970
Now, if you have a
fast signal like this,

1024
00:58:29,970 --> 00:58:33,180
with fast fluctuations, and
you do the autocorrelation,

1025
00:58:33,180 --> 00:58:34,870
what's going to happen?

1026
00:58:34,870 --> 00:58:40,420
So first of all, at zero
lag, it's going to be peak.

1027
00:58:40,420 --> 00:58:42,870
And then what's going to happen?

1028
00:58:42,870 --> 00:58:46,180
It's going to drop
off more quickly.

1029
00:58:46,180 --> 00:58:48,100
So that's exactly what happens.

1030
00:58:48,100 --> 00:58:51,070
So here's the autocorrelation
of this slow function.

1031
00:58:51,070 --> 00:58:53,830
Here's the autocorrelation
of this fast function.

1032
00:58:53,830 --> 00:58:56,400
And you can see both of
these are just noise.

1033
00:58:56,400 --> 00:58:57,780
But I've smoothed this one.

1034
00:58:57,780 --> 00:58:59,580
I've low-pass-filtered
this with kind

1035
00:58:59,580 --> 00:59:03,720
of a 50-millisecond-wide
kernel to give

1036
00:59:03,720 --> 00:59:06,220
very slowly-varying structure.

1037
00:59:06,220 --> 00:59:10,770
This one I smoothed with
a very narrow kernel

1038
00:59:10,770 --> 00:59:12,510
to leave fast fluctuations.

1039
00:59:12,510 --> 00:59:15,630
And you can see that the
autocorrelation shows

1040
00:59:15,630 --> 00:59:21,780
that the width of the smoothing
of this signal is very narrow.

1041
00:59:21,780 --> 00:59:25,800
And the width of the smoothing
for this signal was broad.

1042
00:59:25,800 --> 00:59:28,710
In fact what you can see
is that this signal looks

1043
00:59:28,710 --> 00:59:32,040
like noise that's been
convolved with this,

1044
00:59:32,040 --> 00:59:33,780
and this signal looks
like noise that's

1045
00:59:33,780 --> 00:59:35,130
been convolved with that.

1046
00:59:38,860 --> 00:59:41,500
And here is actually
a demonstration

1047
00:59:41,500 --> 00:59:43,360
of what Sammy was
just talking about.

1048
00:59:43,360 --> 00:59:45,110
If you take a look
at this signal,

1049
00:59:45,110 --> 00:59:47,620
so the autocorrelation can
be a very powerful method.

1050
00:59:50,140 --> 00:59:51,550
It's actually not that powerful.

1051
00:59:51,550 --> 00:59:55,100
It's a method for extracting
periodic structure.

1052
00:59:55,100 --> 00:59:57,310
And we're going to
turn now, very shortly,

1053
00:59:57,310 --> 01:00:00,100
to a method that really is
very powerful for extracting

1054
01:00:00,100 --> 01:00:01,240
periodic structure.

1055
01:00:01,240 --> 01:00:06,440
But I just want to show you
how this method can be used.

1056
01:00:06,440 --> 01:00:08,687
And so if you look at
that signal right there,

1057
01:00:08,687 --> 01:00:09,520
it looks like noise.

1058
01:00:13,580 --> 01:00:17,000
But there's actually
structure embedded in there

1059
01:00:17,000 --> 01:00:20,810
that we can see if we do the
autocorrelation of this signal.

1060
01:00:20,810 --> 01:00:22,500
And here's what that looks like.

1061
01:00:22,500 --> 01:00:25,450
So again, autocorrelation
has peaked.

1062
01:00:25,450 --> 01:00:27,410
The peak is very
narrow, because that's

1063
01:00:27,410 --> 01:00:29,390
a very noisy-looking signal.

1064
01:00:29,390 --> 01:00:32,300
But you can see that,
buried under there,

1065
01:00:32,300 --> 01:00:34,910
is this periodic fluctuation.

1066
01:00:34,910 --> 01:00:37,730
What that says is that if I
take a copy of that signal

1067
01:00:37,730 --> 01:00:42,540
and shift it with respect to
itself every 100 milliseconds,

1068
01:00:42,540 --> 01:00:45,710
something in there
starts lining up again.

1069
01:00:45,710 --> 01:00:48,020
And that's why you
have these little peaks

1070
01:00:48,020 --> 01:00:49,710
in the autocorrelation function.

1071
01:00:49,710 --> 01:00:53,260
And what do you think
that is buried in there?

1072
01:00:53,260 --> 01:00:55,340
The sine wave.

1073
01:00:55,340 --> 01:01:01,400
So this data is random,
with a normal distribution,

1074
01:01:01,400 --> 01:01:08,780
plus 0.1 times cosine that
gives you a 10 hertz wiggle.

1075
01:01:11,820 --> 01:01:15,743
So you can't see
that in the data.

1076
01:01:15,743 --> 01:01:17,160
But if you do the
autocorrelation,

1077
01:01:17,160 --> 01:01:19,950
all of a sudden you can see
that it's buried in there.

1078
01:01:19,950 --> 01:01:27,260
All right, so
cross-correlation is a way

1079
01:01:27,260 --> 01:01:31,940
to extract the temporal relation
between different signals.

1080
01:01:31,940 --> 01:01:34,760
Autocorrelation is a way to
use the same method essentially

1081
01:01:34,760 --> 01:01:39,020
to extract the temporal
relation between a signal

1082
01:01:39,020 --> 01:01:41,200
and itself at different times.

1083
01:01:46,230 --> 01:01:50,700
And that method, it's
actually quite commonly used

1084
01:01:50,700 --> 01:01:52,885
to extract structure
and spike trains.

1085
01:01:56,390 --> 01:01:58,730
But there are much
more powerful methods

1086
01:01:58,730 --> 01:02:01,610
for extracting
periodic structure.

1087
01:02:01,610 --> 01:02:04,850
And that's what we're going
to start talking about now.

1088
01:02:04,850 --> 01:02:06,365
OK, any questions?

1089
01:02:10,460 --> 01:02:14,740
Let's start on the topic
of spectral analysis, which

1090
01:02:14,740 --> 01:02:20,600
is the right way to pull out the
periodic structure of signals.

1091
01:02:20,600 --> 01:02:22,810
Here's that the spectrogram
that I was actually

1092
01:02:22,810 --> 01:02:24,520
trying to show you last time.

1093
01:02:24,520 --> 01:02:29,530
So what is a spectrogram?

1094
01:02:29,530 --> 01:02:31,150
So if we have a sound--

1095
01:02:31,150 --> 01:02:34,530
we record a sound
with a microphone,

1096
01:02:34,530 --> 01:02:36,860
microphones pick up
pressure fluctuations.

1097
01:02:36,860 --> 01:02:38,960
So in this case, this
is a bird singing.

1098
01:02:38,960 --> 01:02:42,790
The vocal cords are vibrating
with air flowing through them

1099
01:02:42,790 --> 01:02:45,640
that produce very large
pressure fluctuations

1100
01:02:45,640 --> 01:02:47,330
in the vocal tract.

1101
01:02:47,330 --> 01:02:50,020
And those are transmitted out
through the beak, into the air.

1102
01:02:50,020 --> 01:02:52,540
And that produces
pressure fluctuations

1103
01:02:52,540 --> 01:02:54,690
that propagate through
the air at about

1104
01:02:54,690 --> 01:02:56,440
a foot per millisecond.

1105
01:02:56,440 --> 01:02:59,050
They reach your ear, and
they vibrate your eardrum.

1106
01:03:01,570 --> 01:03:03,820
And if you have a
microphone there,

1107
01:03:03,820 --> 01:03:07,060
you can actually record
those pressure fluctuations.

1108
01:03:07,060 --> 01:03:10,350
And if you look at it, it
just looks like fast wiggles

1109
01:03:10,350 --> 01:03:11,410
in the pressure.

1110
01:03:11,410 --> 01:03:16,480
But somehow your ear is able
to magically transform that

1111
01:03:16,480 --> 01:03:25,470
into this neural representation
of what that sound is.

1112
01:03:25,470 --> 01:03:27,310
And what your ear
is actually doing

1113
01:03:27,310 --> 01:03:30,520
is it's doing a spectral
analysis of the sound.

1114
01:03:30,520 --> 01:03:32,710
And then your brain is
doing a bunch of processing

1115
01:03:32,710 --> 01:03:35,260
that helps you identify
what that thing is

1116
01:03:35,260 --> 01:03:37,480
that's making that sound.

1117
01:03:37,480 --> 01:03:43,840
So this is a spectral
analysis of this bit

1118
01:03:43,840 --> 01:03:46,600
of birdsong, canary song.

1119
01:03:46,600 --> 01:03:50,390
And what it is, it does very
much what your eardrum does--

1120
01:03:50,390 --> 01:03:51,970
or what your cochlea does.

1121
01:03:51,970 --> 01:03:52,600
Sorry.

1122
01:03:52,600 --> 01:03:55,960
It calculates how
much power there

1123
01:03:55,960 --> 01:04:00,640
is at different
frequencies of the sound

1124
01:04:00,640 --> 01:04:03,640
and at different times.

1125
01:04:03,640 --> 01:04:05,530
So what this says
is that there's

1126
01:04:05,530 --> 01:04:09,410
a lot of power in this sound
at 5 kilohertz at this time,

1127
01:04:09,410 --> 01:04:12,340
but at this time, there's a lot
of power at 3 kilohertz or a 2

1128
01:04:12,340 --> 01:04:14,230
kilohertz and so on.

1129
01:04:14,230 --> 01:04:18,460
So it's a graphical way of
describing what the sound is.

1130
01:04:18,460 --> 01:04:21,558
And here's what that looks like.

1131
01:04:21,558 --> 01:04:23,052
[DESCENDING WHISTLING BIRDSONG]

1132
01:04:23,052 --> 01:04:24,546
[FULL-THROATED CHIRP]

1133
01:04:24,546 --> 01:04:26,538
[RAPID CHIRPS]

1134
01:04:28,530 --> 01:04:31,020
[SIREN-LIKE CHIRPS]

1135
01:04:31,020 --> 01:04:32,514
[STUDENTS LAUGH]

1136
01:04:34,200 --> 01:04:37,740
So you can see visually
what's happening.

1137
01:04:37,740 --> 01:04:40,020
Even though if you were
to look at those patterns

1138
01:04:40,020 --> 01:04:42,690
on an oscilloscope or
printed out on the computer,

1139
01:04:42,690 --> 01:04:45,190
it would just be a
bunch of wiggles.

1140
01:04:45,190 --> 01:04:47,470
You wouldn't be able
to see any of that.

1141
01:04:47,470 --> 01:04:49,300
Here's another example.

1142
01:04:49,300 --> 01:04:51,090
This is a baby bird babbling.

1143
01:04:51,090 --> 01:04:53,400
And here's an example of
what those signals actually

1144
01:04:53,400 --> 01:04:54,570
look like--

1145
01:04:54,570 --> 01:04:56,550
just a bunch of wiggles.

1146
01:04:56,550 --> 01:04:59,790
It's almost completely
uninterpretable.

1147
01:04:59,790 --> 01:05:02,910
But again, your brain does
this spectral analysis.

1148
01:05:02,910 --> 01:05:04,560
And here I'm showing
a spectrogram.

1149
01:05:04,560 --> 01:05:06,835
Again, this is
frequency versus time.

1150
01:05:06,835 --> 01:05:09,810
It's much more
cluttered visually.

1151
01:05:09,810 --> 01:05:13,180
And it's a little bit
harder to interpret.

1152
01:05:13,180 --> 01:05:16,542
But your brain actually does a
pretty good job figuring out--

1153
01:05:16,542 --> 01:05:19,680
[RANDOM SQUEAKY CHIRPING]

1154
01:05:19,680 --> 01:05:21,750
--what's going on there.

1155
01:05:21,750 --> 01:05:24,580
We can also do spectral
analysis of neural signals.

1156
01:05:24,580 --> 01:05:27,360
So one of the really cool things
that happens in the cortex

1157
01:05:27,360 --> 01:05:30,510
is that neural circuits
produce oscillations.

1158
01:05:30,510 --> 01:05:33,150
And they produce oscillations
at different frequencies

1159
01:05:33,150 --> 01:05:34,285
at different times.

1160
01:05:34,285 --> 01:05:35,910
If you close your
eyes-- everybody just

1161
01:05:35,910 --> 01:05:37,830
close your eyes for a second.

1162
01:05:37,830 --> 01:05:42,190
As soon as you close your
eyes, the back of your cortex

1163
01:05:42,190 --> 01:05:47,170
starts generating a big
10 hertz oscillation.

1164
01:05:47,170 --> 01:05:48,122
It's wild.

1165
01:05:48,122 --> 01:05:50,080
You just close your eyes,
and it starts going--

1166
01:05:50,080 --> 01:05:51,250
[MAKES OSCILLATING SOUND WITH
 MOUTH]

1167
01:05:51,250 --> 01:05:51,940
--at 10 hertz.

1168
01:05:55,580 --> 01:05:58,370
This is a rhythm that's
produced by the hippocampus.

1169
01:05:58,370 --> 01:06:03,290
So whenever you start
walking, your hippocampus

1170
01:06:03,290 --> 01:06:05,600
starts generating
a 10 hertz rhythm.

1171
01:06:05,600 --> 01:06:09,170
When you stop and you're
thinking about something

1172
01:06:09,170 --> 01:06:12,150
or eating something, it stops.

1173
01:06:12,150 --> 01:06:13,400
As soon as you start walking--

1174
01:06:13,400 --> 01:06:14,942
[MAKES OSCILLATING SOUND WITH
 MOUTH]

1175
01:06:14,942 --> 01:06:17,690
--10 hertz rhythm.

1176
01:06:17,690 --> 01:06:24,710
And you can see that rhythm
often in neural signals.

1177
01:06:24,710 --> 01:06:26,910
Here you can see
this 10 Hertz rhythm.

1178
01:06:26,910 --> 01:06:29,730
It has a period of
about 100 milliseconds.

1179
01:06:29,730 --> 01:06:32,280
But on top of that, there
are much faster rhythms.

1180
01:06:32,280 --> 01:06:35,360
It's not always so obvious in
the brain what the rhythms are.

1181
01:06:35,360 --> 01:06:39,350
And you need spectral analysis
techniques to help pull out

1182
01:06:39,350 --> 01:06:42,800
that structure.

1183
01:06:42,800 --> 01:06:45,890
You can see here,
here is the frequency

1184
01:06:45,890 --> 01:06:47,400
as a function of time.

1185
01:06:47,400 --> 01:06:48,860
I haven't labeled the axis here.

1186
01:06:48,860 --> 01:06:52,850
But this bright band right here
corresponds to this 10 hertz

1187
01:06:52,850 --> 01:06:55,640
oscillation.

1188
01:06:55,640 --> 01:06:59,180
So we're going to take up a
little bit of a detour into how

1189
01:06:59,180 --> 01:07:03,680
to actually carry out
state-of-the-art spectral

1190
01:07:03,680 --> 01:07:10,070
analysis like this to allow
you to detect very subtle,

1191
01:07:10,070 --> 01:07:15,560
small signals in neural
signals, or sound signals,

1192
01:07:15,560 --> 01:07:19,800
or any kind of signal that
you're interested in studying.

1193
01:07:19,800 --> 01:07:20,610
Jasmine.

1194
01:07:20,610 --> 01:07:22,256
AUDIENCE: [INAUDIBLE]

1195
01:07:24,750 --> 01:07:29,210
MICHALE FEE: Yeah, OK, so
this is called a color map.

1196
01:07:29,210 --> 01:07:32,010
I didn't put that
on the side here.

1197
01:07:32,010 --> 01:07:37,070
But basically dark
here means no power.

1198
01:07:37,070 --> 01:07:41,930
And light blue to
green is more power.

1199
01:07:41,930 --> 01:07:44,270
Yellow to red is even more.

1200
01:07:44,270 --> 01:07:45,230
Same here.

1201
01:07:45,230 --> 01:07:47,992
So red is most power.

1202
01:07:47,992 --> 01:07:49,170
AUDIENCE: [INAUDIBLE]

1203
01:07:49,170 --> 01:07:49,878
MICHALE FEE: Yes.

1204
01:07:49,878 --> 01:07:53,280
So it's how much energy there
is at different frequencies

1205
01:07:53,280 --> 01:07:55,800
in the signal as a
function of time.

1206
01:07:55,800 --> 01:07:57,900
So you're going to
know how to do this.

1207
01:07:57,900 --> 01:07:58,410
Don't worry.

1208
01:08:01,010 --> 01:08:04,190
you're going to be world
experts at how to do this right.

1209
01:08:04,190 --> 01:08:05,001
Yes.

1210
01:08:05,001 --> 01:08:08,022
AUDIENCE: [INAUDIBLE]

1211
01:08:08,022 --> 01:08:08,730
MICHALE FEE: Yes.

1212
01:08:08,730 --> 01:08:13,612
AUDIENCE: This is very
similar to [INAUDIBLE]..

1213
01:08:13,612 --> 01:08:14,320
MICHALE FEE: Yes.

1214
01:08:14,320 --> 01:08:14,823
I'm sorry.

1215
01:08:14,823 --> 01:08:16,240
I should have been
clear-- this is

1216
01:08:16,240 --> 01:08:18,850
recording from an electrode
in the hippocampus.

1217
01:08:18,850 --> 01:08:21,365
And these oscillations here
are the local field potentials.

1218
01:08:21,365 --> 01:08:22,240
AUDIENCE: [INAUDIBLE]

1219
01:08:22,240 --> 01:08:22,948
MICHALE FEE: Yes.

1220
01:08:22,948 --> 01:08:24,920
That's exactly right.

1221
01:08:24,920 --> 01:08:25,420
Thank you.

1222
01:08:25,420 --> 01:08:27,128
I should have been
more clear about that.

1223
01:08:29,890 --> 01:08:34,120
OK, all right, so in
order to understand

1224
01:08:34,120 --> 01:08:37,779
how to really do this,
you have to understand

1225
01:08:37,779 --> 01:08:40,359
Fourier decomposition.

1226
01:08:40,359 --> 01:08:44,649
And once you understand that,
the rest is pretty easy.

1227
01:08:44,649 --> 01:08:47,819
So I'm going to take
you very slowly--

1228
01:08:47,819 --> 01:08:51,930
and it may feel a little
grueling at first.

1229
01:08:51,930 --> 01:08:55,859
But if you understand
this, the rest is simple.

1230
01:08:55,859 --> 01:08:58,050
So let's just get started.

1231
01:09:00,729 --> 01:09:03,149
All right, so Fourier series--

1232
01:09:03,149 --> 01:09:07,490
it's a way of decomposing
periodic signals

1233
01:09:07,490 --> 01:09:11,330
by applying filters to them.

1234
01:09:11,330 --> 01:09:15,710
We're going to take a signal
that's a function of time,

1235
01:09:15,710 --> 01:09:20,930
and we're going to make
different receptive fields.

1236
01:09:20,930 --> 01:09:24,140
We're going to make
neurons that have--

1237
01:09:24,140 --> 01:09:26,990
sensitive to
different frequencies.

1238
01:09:26,990 --> 01:09:32,540
And we're going to apply those
different filters to extract

1239
01:09:32,540 --> 01:09:36,290
what different frequencies
there are in that signal.

1240
01:09:36,290 --> 01:09:39,319
So we're going to take
this periodic signal

1241
01:09:39,319 --> 01:09:40,250
as a function of time.

1242
01:09:40,250 --> 01:09:41,420
It's a square wave.

1243
01:09:41,420 --> 01:09:46,260
It has a period capital T.
And what we're going to do

1244
01:09:46,260 --> 01:09:49,200
is we're going to
approximate that square wave

1245
01:09:49,200 --> 01:09:53,350
as a sum of a bunch of
different sine waves.

1246
01:09:53,350 --> 01:09:57,135
So the first thing we can do
is approximate it as a cosine.

1247
01:09:57,135 --> 01:09:59,010
You can see the square
wave has a peak there.

1248
01:09:59,010 --> 01:10:00,270
It has a valley there.

1249
01:10:00,270 --> 01:10:03,270
So the sine wave approximation
is going to have a peak there

1250
01:10:03,270 --> 01:10:04,190
and a valley there.

1251
01:10:06,960 --> 01:10:09,510
We're going to approximate
it as a cosine wave

1252
01:10:09,510 --> 01:10:14,950
of the same period and
the same amplitude.

1253
01:10:14,950 --> 01:10:18,820
Now, we might say, OK, that's
not a very good approximation.

1254
01:10:18,820 --> 01:10:24,320
What could we add to it to
make a better approximation?

1255
01:10:24,320 --> 01:10:26,250
AUDIENCE: [INAUDIBLE]

1256
01:10:26,250 --> 01:10:29,370
MICHALE FEE:
Another cosine wave,

1257
01:10:29,370 --> 01:10:31,865
which is what we're going
to do in just a second.

1258
01:10:31,865 --> 01:10:33,240
Because apparently
there's more I

1259
01:10:33,240 --> 01:10:34,900
wanted to tell you about this.

1260
01:10:34,900 --> 01:10:38,640
So we're going to approximate
this as a cosine wave that has

1261
01:10:38,640 --> 01:10:40,650
a coefficient in front of it.

1262
01:10:40,650 --> 01:10:43,110
We have to approximate
this is a cosine that

1263
01:10:43,110 --> 01:10:48,900
has some amplitude a1, and
it has some frequency, f0.

1264
01:10:52,380 --> 01:10:55,845
So a cosine wave
with a frequency f0

1265
01:10:55,845 --> 01:11:03,570
is this-- cosine 2 pi f0 T,
where f0 is 1 over the period.

1266
01:11:06,520 --> 01:11:08,580
And you can also write--

1267
01:11:08,580 --> 01:11:11,130
so f0 is the
oscillation frequency.

1268
01:11:11,130 --> 01:11:13,320
It's cycles per second.

1269
01:11:13,320 --> 01:11:18,370
There is an important quantity
called the angular frequency,

1270
01:11:18,370 --> 01:11:23,310
which is just 2 pi times
f0, or 2 pi over T.

1271
01:11:23,310 --> 01:11:28,830
And the reason is because if we
write this as cosine omega-0 T,

1272
01:11:28,830 --> 01:11:34,550
then this thing
just gives us 2 pi

1273
01:11:34,550 --> 01:11:38,730
change in the phase over
this interval T, which

1274
01:11:38,730 --> 01:11:42,600
means that the cosine
comes back to where it was.

1275
01:11:42,600 --> 01:11:46,430
So if we want to make
a better approximation,

1276
01:11:46,430 --> 01:11:49,970
we can add more sine
waves or cosine waves.

1277
01:11:53,490 --> 01:11:57,990
And it turns out that we can
approximate any periodic signal

1278
01:11:57,990 --> 01:12:02,220
by adding more cosine
waves that are multiples

1279
01:12:02,220 --> 01:12:06,330
of this frequency, omega-0.

1280
01:12:06,330 --> 01:12:07,830
Why is that?

1281
01:12:07,830 --> 01:12:12,470
Why can we get away
with just adding

1282
01:12:12,470 --> 01:12:16,430
more cosines that are integer
multiples of this frequency,

1283
01:12:16,430 --> 01:12:18,990
omega-0?

1284
01:12:18,990 --> 01:12:19,490
Any idea?

1285
01:12:23,470 --> 01:12:27,130
Why is it not
important to consider

1286
01:12:27,130 --> 01:12:34,222
1.5 times omega-0, or 2.7?

1287
01:12:34,222 --> 01:12:36,597
AUDIENCE: Does it have something
to do with [INAUDIBLE]??

1288
01:12:39,700 --> 01:12:42,466
MICHALE FEE: It's close,
but too complicated.

1289
01:12:42,466 --> 01:12:46,272
AUDIENCE: [INAUDIBLE]
sum just over the period

1290
01:12:46,272 --> 01:12:48,778
of their natural wave, right?

1291
01:12:48,778 --> 01:12:51,676
So if you add
non-integer [INAUDIBLE],,

1292
01:12:51,676 --> 01:12:53,268
you lose that [INAUDIBLE].

1293
01:12:53,268 --> 01:12:54,060
MICHALE FEE: Right.

1294
01:12:54,060 --> 01:12:56,340
This signal that
we're trying to model

1295
01:12:56,340 --> 01:13:01,790
is periodic, with
frequency omega-0.

1296
01:13:01,790 --> 01:13:05,690
And any integer
multiple of omega-0

1297
01:13:05,690 --> 01:13:09,350
is also periodic at
frequency omega-0.

1298
01:13:09,350 --> 01:13:16,460
So notice that this signal
that's cosine 2 omega-0

1299
01:13:16,460 --> 01:13:22,912
is still periodic
over this interval, t.

1300
01:13:22,912 --> 01:13:25,650
Does that make sense?

1301
01:13:25,650 --> 01:13:30,590
So any integer multiple
cosine integer omega 0

1302
01:13:30,590 --> 01:13:35,800
is also periodic
with period T. OK?

1303
01:13:35,800 --> 01:13:41,490
And those are the
only frequencies that

1304
01:13:41,490 --> 01:13:49,310
are periodic with period T.

1305
01:13:49,310 --> 01:13:52,550
So we can restrict ourselves to
including only frequencies that

1306
01:13:52,550 --> 01:13:54,830
are integer
multiples of omega-0,

1307
01:13:54,830 --> 01:13:58,160
because those are the only
frequencies that are also

1308
01:13:58,160 --> 01:14:05,550
periodic with period T.

1309
01:14:05,550 --> 01:14:10,200
We can write down-- we can
approximate this square wave

1310
01:14:10,200 --> 01:14:16,310
as a sum of cosine of
different frequencies.

1311
01:14:16,310 --> 01:14:18,670
And the frequencies
that we consider

1312
01:14:18,670 --> 01:14:21,370
are just the integer
multiples of omega-0.

1313
01:14:23,928 --> 01:14:24,970
Any questions about that?

1314
01:14:24,970 --> 01:14:28,370
That's almost like
the crux of it.

1315
01:14:28,370 --> 01:14:30,280
There's just some
more math to do.

1316
01:14:32,900 --> 01:14:34,470
So here's why this works.

1317
01:14:34,470 --> 01:14:38,980
So here's the square wave
we're trying to approximate.

1318
01:14:38,980 --> 01:14:42,310
We can approximate that
square wave as a cosine.

1319
01:14:42,310 --> 01:14:44,980
And then there's
the approximation.

1320
01:14:44,980 --> 01:14:49,330
Now, if we add a component
that's some constant times

1321
01:14:49,330 --> 01:14:53,770
cosine 3 omega-0, you can see
that those two peaks there kind

1322
01:14:53,770 --> 01:14:57,583
of square out those round
edges of that cosine.

1323
01:14:57,583 --> 01:14:59,500
And you can see it starts
looking a little bit

1324
01:14:59,500 --> 01:15:01,190
more square.

1325
01:15:01,190 --> 01:15:06,410
And if you add constant
times cosine 5 omega-T,

1326
01:15:06,410 --> 01:15:07,710
it gets even more square.

1327
01:15:07,710 --> 01:15:10,070
And you keep adding
more of these things

1328
01:15:10,070 --> 01:15:12,630
until it almost looks
just like a square wave.

1329
01:15:16,510 --> 01:15:17,800
Here's another function.

1330
01:15:17,800 --> 01:15:21,310
We're going to approximate
a bunch of pulses

1331
01:15:21,310 --> 01:15:27,400
that have a period of 1 by
adding up a bunch of cosines.

1332
01:15:27,400 --> 01:15:29,470
So here's the first
approximation--

1333
01:15:29,470 --> 01:15:31,690
cosine, omega-0.

1334
01:15:31,690 --> 01:15:33,340
So there's your
first approximation

1335
01:15:33,340 --> 01:15:35,830
to this train of pulses.

1336
01:15:35,830 --> 01:15:40,810
Now we add to that
a constant times

1337
01:15:40,810 --> 01:15:45,190
cosine 2 omega-T. See that
peak gets a little sharper.

1338
01:15:45,190 --> 01:15:49,680
Add a constant times
cosine 3 omega-T.

1339
01:15:49,680 --> 01:15:52,142
And you keep adding
more and more terms,

1340
01:15:52,142 --> 01:15:54,100
and it gets sharper and
sharper, and looks more

1341
01:15:54,100 --> 01:15:56,590
like a bunch of pulses.

1342
01:15:56,590 --> 01:15:57,920
Why is that?

1343
01:15:57,920 --> 01:16:01,450
It's because all of
those different cosines

1344
01:16:01,450 --> 01:16:07,520
add up consecutively
right here at 0.

1345
01:16:07,520 --> 01:16:09,180
And so those things all add up.

1346
01:16:09,180 --> 01:16:16,440
And this peak stays, because
the peak of those cosines

1347
01:16:16,440 --> 01:16:19,740
is always at 0.

1348
01:16:19,740 --> 01:16:24,270
Over here, though, right
next door, all of those,

1349
01:16:24,270 --> 01:16:26,940
you can see that that cosine
is canceling that one.

1350
01:16:26,940 --> 01:16:28,470
It's canceling that one.

1351
01:16:28,470 --> 01:16:30,360
Those two are canceling.

1352
01:16:30,360 --> 01:16:33,870
You can see all these peaks
here are canceling each other.

1353
01:16:33,870 --> 01:16:38,790
And so that goes to 0 in there.

1354
01:16:38,790 --> 01:16:42,990
Now of course all these cosines
are periodic with a period T.

1355
01:16:42,990 --> 01:16:45,990
So if you go one T
over, all of those peaks

1356
01:16:45,990 --> 01:16:49,890
add up again and
interfere constructively.

1357
01:16:54,310 --> 01:16:55,470
So that's it.

1358
01:16:55,470 --> 01:16:59,650
It's basically a way of
taking any periodic signal

1359
01:16:59,650 --> 01:17:06,040
and figuring out a bunch of
cosines such that the parts you

1360
01:17:06,040 --> 01:17:08,500
want to keep add
up constructively

1361
01:17:08,500 --> 01:17:13,240
and the parts that aren't
there in your signal

1362
01:17:13,240 --> 01:17:16,740
add up destructively.

1363
01:17:16,740 --> 01:17:21,720
And there's very simple
sort of mathematical tools--

1364
01:17:21,720 --> 01:17:25,490
basically it's a correlation--

1365
01:17:25,490 --> 01:17:29,030
to extract the coefficients
that go in front

1366
01:17:29,030 --> 01:17:33,650
of each one of these cosines.

1367
01:17:33,650 --> 01:17:36,440
And then one more thing--

1368
01:17:36,440 --> 01:17:41,210
we use cosines to model or to
approximate functions that are

1369
01:17:41,210 --> 01:17:42,950
symmetric around the original.

1370
01:17:42,950 --> 01:17:46,680
Because the cosine
function is symmetric.

1371
01:17:46,680 --> 01:17:49,140
Other functions
are anti-symmetric.

1372
01:17:49,140 --> 01:17:53,670
They'll look more
like a sine wave.

1373
01:17:53,670 --> 01:17:56,430
They'll be negative
here, and positive there.

1374
01:17:56,430 --> 01:17:59,970
And we use sines to model those.

1375
01:17:59,970 --> 01:18:02,940
And then the one
last trick we need

1376
01:18:02,940 --> 01:18:09,540
is we can model arbitrary
functions by combining

1377
01:18:09,540 --> 01:18:13,080
sines and cosines into
complex exponentials.

1378
01:18:13,080 --> 01:18:14,770
And we'll talk about
that next time.

1379
01:18:14,770 --> 01:18:17,460
And once we do that,
then you can basically

1380
01:18:17,460 --> 01:18:26,190
model not just periodic
signals, but arbitrary signals.

1381
01:18:26,190 --> 01:18:30,440
And then you're
all set to analyze

1382
01:18:30,440 --> 01:18:38,180
any kind of periodic signal
in arbitrary signals.

1383
01:18:38,180 --> 01:18:41,480
So it's a powerful way of
extracting periodic structure

1384
01:18:41,480 --> 01:18:43,640
from any signal.

1385
01:18:43,640 --> 01:18:46,720
So we'll continue
that next time.